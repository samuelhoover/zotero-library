Chemical Engineering Journal 444 (2022) 136669
Available online 29 April 2022 1385-8947/© 2022 Elsevier B.V. All rights reserved.
Deep learning to catalyze inverse molecular design
Abdulelah S. Alshehri a,b, Fengqi You a,*
a Robert Frederick Smith School of Chemical and Biomolecular Engineering, Cornell University, Ithaca, NY 14853, USA
b Department of Chemical Engineering, College of Engineering, King Saud University, Riyadh 11421, Saudi Arabia
ARTICLE INFO
Keywords:
Inverse molecular design Computational molecular design Deep learning Representation learning Property prediction Molecular optimization
ABSTRACT
The discovery of superior molecular solutions through computational methods is critical for innovative technologies and their role in addressing pressing resources, health, and environmental issues. Despite its short timespan, the synergetic application of deep learning to inverse molecular design has outpaced decades of theoretical efforts, bearing promise to transform current molecular design paradigms. Herein, we provide an overview of the element of computational inverse molecular design and offer our views on current limitations and outstanding challenges. In our perspective, three main directions are identified for each element and analyzed in terms of their merits and relevant novel deep learning developments. For the molecular representations element, Graph Neural Networks (GNNs), grids, and knowledge graphs (KGs) are discussed for enhancing the expressivity, complexity, descriptivity of relevant molecular information, respectively. Second, chemical text mining, accelerated quantum chemical calculations, and transfer learning are explored to augment the size and the accuracy of current property data and predictive models. Last, emerging trends in design methods including generative modeling, reinforcement learning (RL), and active learning (AL) are examined for optimizing not only computational costs, but also experimental and simulation efforts. The presented discussions are aimed at catalyzing progress and interdisciplinary collaborations toward general-purpose inverse design frameworks.
1. Introduction
Chemicals play a key role in present economies and have the potential to trigger significant technological, environmental, and scientific advances. As such, interdisciplinary efforts have long focused on the computational and experimental design of molecules to enhance the functional performance of their respective applications [1,2]. Conventional computational approaches have been limited to known classes of small molecules with a fairly simple mathematical structure for approximating the underlying thermodynamic behavior [3,4]. As for experimental efforts, decades of experimentation and testing have only probed an infinitesimal fraction of the so-called chemical space [5]. Due to the recent exponential growth in computing power, computational molecular screening has increasingly gained prominence to explore the vast space of chemicals [6]. Ultimately, the advent of deep learning and the availability of big data have transformed inverse molecular design by delivering quantum leaps, surpassing decades of experimentation and theorization in synthesis planning [7], protein folding [8], and metal–organic framework design [9]. The trend continues to catalyze the efficiency and complexity of molecular screening at pace with the
unremitting progress in deep learning. Deep learning has proven to outperform traditional AI algorithms on a variety of demanding tasks, including computer vision (CV) and natural language processing (NLP) [10]. Pioneering applications in molecular design sought to leverage three useful characteristics of deep learning. The first characteristic eliminates the need for handcrafted representations by the capability to handle unstructured representations of molecules such as characters (e.g. SMILES [11]) and graphs. Second, deep learning offers powerful feature learning that reveals intricate relationships that would otherwise be hidden from conventional regression methods and theoretical explanations. Finally, deep learning can leverage data and self-improving algorithms to intelligently guide the search for promising molecular candidates. Given these compelling capabilities and performances, deep learning applications in molecular sciences have bourgeoned for a variety of tasks, including molecular representation learning [12], property prediction [13], synthesis planning [7], and inverse design [9]. Despite the remarkable progress in deep learning-based inverse molecular design, many challenges persist in molecular representations, the breadth and scale of physicochemical properties and information,
* Corresponding author. E-mail address: fengqi.you@cornell.edu (F. You).
Contents lists available at ScienceDirect
Chemical Engineering Journal
journal homepage: www.elsevier.com/locate/cej
https://doi.org/10.1016/j.cej.2022.136669 Received 20 January 2022; Received in revised form 5 April 2022; Accepted 26 April 2022


Chemical Engineering Journal 444 (2022) 136669
2
design methods, among others. For instance, in typical character-based representation, the loss of bond distance, charge, and conformational information limits the capability of deep learning methods to generalize well across a wide array of molecular classes [6]. Integrating chemistry theory and methods in representations and predictive deep learning models has the potential to not only boost the confidence in deep learning output, but also offer explanatory insights constructed from experimental data [14]. Current promising advances in deep learning research, particularly in geometric deep learning [15], inverse design methods [16], and explainable deep learning [17], offer transformative implications to inverse molecular design. As such, we highlight these advances and their potential in relevant aspects within molecular representations, property prediction, and inverse design approaches. It is noteworthy, however, that successful applications of deep learning go beyond merely learning from data, which results in many challenges and limitations. Such applications incorporate substantial domain expertise and knowledge of the inner workings of relevant deep learning methods to allow for discovery of novel insights and the application of explainable deep learning. Herein, we first offer a compact overview and discussion of the main components of inverse molecular design along with current challenges. Drawing from the first section, the perspective section lays out current trends in deep learning and open research lines related to resolving outstanding challenges and improving on existing benchmarks. Despite the abundance of opportunities for deep learning in inverse molecular design, the perspective section is focused on three fronts: developing expressive representations, enhancing property data and models, and advancing design methods. The paper concludes with summarizing conclusions, distilling urgent needs, and promising directions to transformative and impactful outcomes.
2. Overview of inverse molecular design
In principle, inverse molecular design may be broken down into three components, each of which embodies a decision or modeling method. These components include the selection of suitable molecular representation, relevant property data and models, and design methods for the search for candidate molecules. Summaries of the main components are given in this section. Respective advances in these components are also examined in terms of leading applications and major drawbacks. For more extensive reviews, we refer interested readers to more elaborate reviews on representation learning [5,18], property prediction [19], synthesis planning [20,21], and molecular design [3,22]. The first component, molecular representation, refers to the machine-readable encoding of molecular structures using different 2D or 3D representations. Selecting an appropriate molecular representation necessitates domain knowledge of the given problem along with knowledge of applicable deep learning techniques [23]. 2D representations have been remarkably successful and popular even before the deep learning era. In deep learning applications, character embedding and representation techniques from NLP have catalyzed the use of the most popular representation by far, SMILES [5,11]. The SMILES representation is a series of characters (1D) that expresses molecules based on graph theory, resulting in a representation that can be converted backward and forward to and from a 2D drawing of molecules [11]. Yet, due to the losses of bonding and conformational information entailed in 2D representations, 3D representations are gaining growing attention in molecular design [24]. Despite the high dimensionality and complexity of 3D representations, GNNs have shown the ability to interpret results and synthesize new knowledge in chemical reaction planning [25]. In the perspective section, we offer the merits and downsides of GNNs for 3D representations, molecular grids representations for complex structures and phenomena, and KGs for augmenting molecular representations. The central second component of molecular design is property prediction models that describe the inherent structural, thermodynamic,
and kinetic behavior of molecules. These models are motivated by the vastness of the chemical space where experimental or theoretical calculations are expensive to perform for exploration tasks. Thus, these models reduce the time and cost of molecular screening and uncover complex relationships for which theoretical explanations are not available. On this front, deep learning techniques have made a great impact on creating highly accurate property prediction models under a diverse array of chemical representations [26–28]. Also, deep learning demonstrated the capability to reduce the knowledge generated from complex multi-step synthesis planning into synthetic accessibility scores and success probabilities [29,30]. However, the major limitation within this component is the scarcity of property data, which limits the exploratory capabilities of design methods. To tackle this limitation, we discuss the use of chemical text mining techniques, quantum chemistry (QC) calculations, and transfer learning for expanding the open-source libraries and datasets of property data in the perspective section. The last component is design methods, which integrate molecular representations, property models, synthesis planning models, among other design considerations, to search for molecules satisfying all requirements. For the majority of the development of computational molecular design, mathematical optimization and metaheuristics (e.g. genetic algorithms) were the methods of choice [31]. Hybrid and deep learning design methods have emerged to develop more expressive molecular representations and integrate more complex property models and design considerations [32]. Two main data-driven design methods are widely applied in molecular design including generative modeling and RL. Generative models seek to jointly learn molecular representations and molecular properties to capture the probability distribution of desired molecules [5]. Alternatively, RL uses a systematic trial-and-error mechanism to find an approximate function (policy) that maximizes the objectives of the molecular design problem [33]. Although it is possible to integrate generative models into RL frameworks, RL applications tend to have a predefined molecular representation to ease the computational burden and the training process [34]. Even so, the sequential application of both techniques can be a fruitful avenue to combine representation expressivity and capacity for complexity from both approaches. In the perspective section, we examine the merits, drawbacks, and trends of both design methods. There, we also introduce AL as a special strategy within machine learning that allows learning algorithms to sequentially select experiments and computations to strike a balance between cost minimization and information gain.
3. Perspectives
3.1. Developing expressive representations
In this subsection, three major directions are identified and analyzed for improving and augmenting current molecular representations. GNNs, grid learning, and KGs are schematically illustrated in Fig. 1 and their merits and demerits are discussed in the following subsections. Developing expressive representations requires the most domain knowledge as well as an understanding of the inner workings of applicable deep learning methods. While all discussed directions entail applying considerable domain knowledge, it is viewed that constructing KGs is the component that requires a substantial understanding of chemical information and dependencies at play.
3.1.1. Graph neural network for 3D representations
Structural graphs provide a natural way to express molecules in a machine-readable format. Molecular graphs are constituted of vertices and edges that represent atoms and their bonds respectively. A special type of deep learning architecture that works with graphs as input is called GNNs. Among GNNs, message-passing networks stand as the state-of-the-art approach for graph-based molecular design [15]. This class of GNNs has been extensively applied to the property prediction of small organic molecules, showing significant accuracy and offering
A.S. Alshehri and F. You


Chemical Engineering Journal 444 (2022) 136669
3
interpretability in predictions at the structure level [35]. Such a feature allows for intuitive and chemist-intelligible explanations of subgraphs contributing to a given property [36]. More recently, the range of applications of GNNs has extended to more complex tasks such as 3D conformer ensemble generation [37], and inverse design [38]. However, the application of message-passing GNNs entails the loss of radial and angular information, making these networks inadequate to differentiate between many non-isomorphic graphs. A solution to this issue is to utilize 3D coordinates of graphs in the equivariant message-passing GNNs [39]. Yet, such networks currently have limited scalability in handling the size of typical molecules in molecular design. As such, the resolution of this issue will increase the capacity of GNNs in handling more complex molecular structures such as proteins and polymers. As it stands, future developments in algorithms that allow for including charge, bonding, atomistic and interaction information and offering explainability in GNNs would likely establish their prevalence as the most superior method for modeling molecular graphs.
3.1.2. Grids for surface interactions
Molecular structures can also be represented as 2D or 3D grids with evenly spaced intervals. The power of such representation is best demonstrated by successes in CV applications using convolutional neural networks (CNNs), which specializes in learning from data with grid-like topology [40]. In CV, for instance, grids represent 2D and 3D images as arrays or voxels at regular intervals [41]. Advances in CV along with grids properties, including identical neighborhood structure and fixed ordering, render such representation immediately useful with higher scalability and strong geometric priors [15]. Furthermore, representing molecules as grids allows for leveraging exploit the extensive array of CNN explainability and interpretability methods developed for CV applications [42]. For instance, using molecular grids as input to 3D CNNs has proven effective for dealing with macromolecules as proteins
[43]. Also, grid-based learning allows for incorporating geometrical features and intermolecular interactions within the representation [44]. Such a property renders grid representations ideal for interpreting molecular properties and interfacial interactions on molecular surfaces. Furthermore, given the considerable number of works studying the inner workings and decisions made by CNNs [45], leveraging these methods to study the bulk and interfacial properties of materials remains an unexploited opportunity in molecular design.
3.1.3. Knowledge graphs for Chemistry-Informed learning
Despite the superior ability of deep learning methods in modeling implicit correlations in chemical data, these methods are still unable to incorporate explicit inference as input [46]. Such an issue leaves much of the accumulated chemical data and known relations untapped. This challenge can be tackled by neural symbolic reasoning methods known as KGs, which have been used to express relations such as interactions between drugs and unstructured information [46,47]. These KG-based methods have shown state-of-the-art capability in avoiding reactivity conflicts in chemical synthesis [48], and predicting drug-drug interactions [49]. Nonetheless, applying KGs to aid molecular discovery is a promising direction that also presents challenges and limitations. Besides the high memory and expert annotation requirements, the quality of KGs is a major concern when it comes to constructing datasets from the literature or fusing data from different existing datasets. This concern is further exacerbated by the absence of practical evaluation methods for assessing the quality of KGs. Even so, KGs offer the possibility of end-to-end reasoning and explainable results and enriching design decisions with the accumulated wealth of chemical textual data [46,50].
Fig. 1. Illustrative schematic of three promising routes to improving current molecular representations, showing compact descriptions of their representation and utility.
A.S. Alshehri and F. You


Chemical Engineering Journal 444 (2022) 136669
4
3.2. Enhancing property data and models
Enlarging the volume of property data and boosting the performance of current models are challenging tasks that stand as major obstacles. We narrow down the list of conceivable methods for bypassing such difficulties into chemical text mining, QC calculations, and transfer learning. Diagrammatic descriptions of these methods are shown in Fig. 2 and indepth discussions are provided below.
3.2.1. Chemical text mining
The development of property prediction models, which are the basis for molecular design, is hampered by the paucity of property data in a structured format [3]. Despite recently published datasets [51], and established chemical information resources such as PubChem [52], only an infinitesimal fraction (<0.1%) of listed chemicals are provided with measured properties. Yet, the recent substantial progress in NLP has enabled the automatic transformation of unstructured data from digital text documents, known as text mining, into structured data used to derive insights across many disciplines [53]. Current deep NLP methods have the capability to overcome common limitations of handcrafted methods such as nonuniversal naming conventions, tabular data, and different document formats [54]. This capability for building information extraction pipelines has been showcased in several deep learningbased applications to biomedical data [55]. These methods have also been extended to collect data for the design of magnetic materials using classical machine learning-based text mining tools [56]. The main challenge, however, in this domain of application lies in collecting, labeling, and curating large sets of textual data in order to sufficiently learn relations and chemical entities using deep learning [54]. Nonetheless, building on recent advances in NLP with attention-based learning [57], we identify the use of deep learning to expand libraries of measured property data as an attainable and worthwhile target for
enhancing the exploration of the vast chemical space.
3.2.2. Deep Learning-Accelerated quantum chemistry
QC tackles the chemistry and physics of molecular systems, which are governed by quantum mechanics to quantify physicochemical properties with acceptable accuracy. In principle, such quantification can be achieved through solving the computationally expensive Schr ̈odinger equation, which governs the chemical and physical behavior of molecular systems. Yet, the computational burden of such an exact quantum chemical description increases with the number of electrons present in the system, rendering the computational cost impractical for most molecules and systems of interest [58]. This limitation led QC researchers to develop approximate, yet accurate, QCbased methods such as semiempirical QC and ab initio such as density functional theory [59]. However, the computational effort associated with these approximate methods tends to rapidly become prohibitively expensive when exploring the design space [31]. Generally, machine learning has been extensively applied to QC for a variety of tasks that mainly include predicting wave functions, the Hamiltonian, and energetic, electronic, and geometrical properties [59]. While some large datasets of relevant properties exist [60], molecular design also requires thermodynamic and kinetic quantities. Yet, these properties can be predicted with QC-predicted properties to statistical thermodynamics and correlations methods [61]. However, the effective application of QC methods to deep learning relevant applications is hindered by several challenges including sampling large and diverse training data, incorporating QC terms in loss functions, and expressing all relevant QC information [59]. Still, the interplay between deep learning and QC methods poses an attractive alternative that can be leveraged to extend and expand molecular design methods and libraries.
Fig. 2. High-level diagrammatic description of opportunities to expand the library and datasets of property data and boost the performance and capabilities of property prediction models.
A.S. Alshehri and F. You


Chemical Engineering Journal 444 (2022) 136669
5
3.2.3. Transfer learning and correlations between properties
To deal with the problem of limited data, transfer learning is a machine learning technique that was proposed to ameliorate performance through exploiting patterns and knowledge in related datasets [62]. While many strong correlations have been empirically and theoretically established [51], such correlations have yet to be exploited with transfer learning to improve property models used in molecular design. To demonstrate the potential of transfer learning, a recent study showed the capability of this approach to accurately predict outcomes of QC calculations at comparable accuracy and billions of times faster than QC calculations [63]. Thus, retraining and fusing knowledge from multiple molecular design data sources has the potential of boosting the accuracy of property models. As seen, much challenging empirical and theoretical work is needed for a cross-property framework in building a network of correlated properties, analyzing the effect of training order, and fusing data from multiple computational and experimental sources.
3.3. Advancing inverse design methods
In this subsection, recent developments in design methods based on deep learning are described in terms of their potential to ameliorate current shortcomings. Namely, two design methods, generative modeling and RL, along with their recent advances are examined in detail in the following subsections. AL is also introduced as a method for optimizing the selection of experiments and intensive computations. These three deep learning-based design methods are illustrated in Fig. 3.
3.3.1. Generative modelling for novel structures
The straightforwardness, efficacy, and variety of generative modeling methods have significantly contributed to their immense popularity in the literature. This family of methods seeks to convert raw molecular representations (e.g., characters and graphs) into continuous vectors in which atomistic and bonding information, as well as molecular similarity, are embedded [5]. These methods have shown promising performance in reducing computational cost by 10-fold for optimizing binding affinities in drug design [64]. However, a key challenge lies in the fact that generative models may face contradicting and overlapping objectives regarding their ability to learn molecular validity rules and generate unique, novel, and diverse molecules. To provide an unbiased performance evaluation across all objectives, specialized benchmarking platforms have been developed [65,66], showing current implementations to be far from robust and reliable. Also, to improve on such issues in current, new developments in deep generative modeling offer innovative promising routes such as self-supervised learning and factorized embedding. First, self-supervised learning allows for the concurrent learning of different molecular representations for the same molecules (e.g., learning from graph and grid representations for cycloserine) while minimizing the difference between the two resulting vectors representing the same molecule [67]. Indeed, this learning paradigm has demonstrated improved pattern recognition and feature extraction, achieving state-of-the-art performance on molecular property prediction [9]. Another effective approach is factorized embedding, which offers the possibility to organize the chemical spaces in accordance with theory. For instance, esters and amides are both carboxylic acid derivatives and should be in close proximity within the vector space. It is
Fig. 3. Diagrammatic overview of recent impactful developments in deep learning-assisted design methods in terms of their applicability to inverse molecular design.
A.S. Alshehri and F. You


Chemical Engineering Journal 444 (2022) 136669
6
noteworthy that this factorizing method has generated improved representations of RNA sequences and novel insights into genes expression organization [68]. Despite the considerable progress in domain-specific generative models recently [9,69], advances in learning and factorizing methods for generative models are projected to yield leading discoveries in the near future.
3.3.2. Reinforcement learning for complex tasks
As molecules are often optimized as a part of processes and products [70,71], RL is a learning paradigm that is suitable for optimizing tasks involving multiple facets. Also, this design method can better handle complexity in terms of the number of predicted physicochemical properties, uncertainty analysis, and synthetic accessibility. Furthermore, unlike generative models that tend to focus on exploitation in sampling solutions, RL offers the ability to control the search process and strike a balance between exploitation and exploration [23]. Indeed, RL methods have been able to outperform commercial solvers by significant margins in combinatorial optimization problems, which possess mathematical structures similar to that of molecular design problems [72]. Noteworthy trends in RL include incorporating human feedback in the design decision loop [73], and integrating dynamic objectives and uncertainty estimation to drive efficient exploration [74,75]. Yet, RL poses the unique difficulty of gradually building molecular structures and guaranteeing their validity in each iteration. This challenging task is exacerbated when the choice of the dynamic objective function is factored in. In such a case, RL becomes extremely computationally intensive to explore large swaths of the chemical space. Despite these challenges, there are recent advances in RL as a major paradigm for incorporating considerations such as product and process design requirements [31], QC calculations [76], and uncertainty estimations [75].
3.3.3. Active learning for optimizing experiments
Given that molecular systems are remarkably intricate, the number of candidate molecular experiments and computations grows exponentially with the increase of varying parameters. For instance, in an experiment/computation that requires ten trials for analyzing the interplay between 5 parameters, the number of candidate experiments/
computations exceeds 105. A data-driven solution route for this combinatorial explosion lies in AL, a branch of machine learning that offers a systematic approach to pinpoint the best experiments/computation to be executed next to optimize a predefined objective. This approach of iterating between experiments and machine learning has demonstrated its efficacy in material design by reducing the exploration time by several orders of magnitude [77]. Further, the potential of AL sampling in reducing the need for experimental and simulation data is displayed in reaction outcomes prediction, reducing the amount of data required to achieve the same performance by 30% to 60% [78]. One major challenge, however, is in the selection of methods that samples the next experiment/computation based on a variety of factors including uncertainty, density, similarity, among others [79]. While it has been argued that uncertainty-based (Bayesian) functions are a natural choice for inverse molecular design [77], selection strategies tend to be taskdependent. Thus, we identify hybrid selection strategies combining multiple factors, including uncertainty and diversity, as a potential solution route in deep AL applications [79]. As viewed, the synergetic coupling of AL and many elements in molecular design (e.g. QC calculations) is a valuable tool for maximizing information gain and aiding theoretical selection. The adoption of AL as a pillar in experimental and computational efforts will likely accelerate the pace and expand the scale of exploration in molecular design and beyond.
4. Conclusions
Developments in deep learning architectures and algorithms, coupled with the accessibility of chemical datasets, have enabled transformative progress in inverse molecular design. The rapid pace of
progress in deep learning opens up new directions and opportunities to be explored in order to resolve outstanding challenges related to chemical and molecular engineering. In this perspective, we discussed research directions and new algorithmic developments toward developing more expressive representations, enhancing property data and models, and advancing inverse design methods. First, transcending the limitations of 2D molecular representations was discussed in view of developments in GNNs and CNNs for expressing graphs and 3D grids. Enriching such representations with KGs has also been analyzed to incorporate existing information and explicit relationships from chemistry. Second, in light of the paucity of property data, chemical text mining and quantum chemical calculations are examined to supplement existing datasets with experimental and computed data. Transfer learning was surveyed as a strategy to leverage patterns from correlated properties and transfer implicit knowledge across them. Finally, we highlight the merits, pitfalls, and advances of generative models and RL to improve representation learning and better manage the complexity of integrating other design considerations. In addition, the need for using AL is underlined to reduce the costs of experimental and computational operations in molecular design. Emerging deep learning progress in geometry-aware methods, symbolic representation and reasoning, and uncertainty estimation are well-positioned to catalyze inverse molecular design. Meanwhile, domain knowledge and collaborative problemsolving are essential to catalyze transformative progress in inverse molecular design.
Declaration of Competing Interest
The authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper.
Acknowledgments
Figures are created with BioRender.com.
References
[1] L. He, L. Bai, D.D. Dionysiou, Z. Wei, R. Spinney, C. Chu, Z. Lin, R. Xiao, Applications of computational chemistry, artificial intelligence, and machine learning in aquatic chemistry research, Chem. Eng. J. 426 (2021), 131810, https:// doi.org/10.1016/j.cej.2021.131810. [2] J. Jawad, A.H. Hawari, S. Javaid Zaidi, Artificial neural network modeling of wastewater treatment and desalination using membrane processes: A review, Chem. Eng. J. 419 (2021), 129540, https://doi.org/10.1016/j.cej.2021.129540. [3] A.S. Alshehri, R. Gani, F. You, Deep learning and knowledge-based methods for computer-aided molecular design—toward a unified approach: State-of-the-art and future directions, Comput Chem Eng 141 (2020), 107005, https://doi.org/ 10.1016/j.compchemeng.2020.107005. [4] R. Gani, Computer-aided methods and tools for chemical product design, Chem. Eng. Res. Des. 82 (11) (2004) 1494–1504, https://doi.org/10.1205/ cerd.82.11.1494.52032. [5] B. Sanchez-Lengeling, A. Aspuru-Guzik, Inverse molecular design using machine learning: Generative models for matter engineering, Science 361 (6400) (2018) 360–365, https://doi.org/10.1126/science.aat2663. [6] G.B. Goh, N.O. Hodas, A. Vishnu, Deep learning for computational chemistry, J. Comput. Chem. 38 (16) (2017) 1291–1307, https://doi.org/10.1002/jcc.24764. [7] C.W. Coley, R. Barzilay, T.S. Jaakkola, W.H. Green, K.F. Jensen, Prediction of organic reaction outcomes using machine learning, ACS Cent. Sci. 3 (5) (2017) 434–443, https://doi.org/10.1021/acscentsci.7b00064. [8] J. Jumper, R. Evans, A. Pritzel, T. Green, M. Figurnov, O. Ronneberger,
K. Tunyasuvunakool, R. Bates, A. Zˇídek, A. Potapenko, A. Bridgland, C. Meyer, S.A. A. Kohl, A.J. Ballard, A. Cowie, B. Romera-Paredes, S. Nikolov, R. Jain, J. Adler, T. Back, S. Petersen, D. Reiman, E. Clancy, M. Zielinski, M. Steinegger, M. Pacholska, T. Berghammer, S. Bodenstein, D. Silver, O. Vinyals, A.W. Senior, K. Kavukcuoglu, P. Kohli, D. Hassabis, Highly accurate protein structure prediction with AlphaFold, Nature 596 (7873) (2021) 583–589, https://doi.org/10.1038/ s41586-021-03819-2. [9] Z. Yao, B. S ́anchez-Lengeling, N.S. Bobbitt, B.J. Bucior, S.G.H. Kumar, S.P. Collins, T. Burns, T.K. Woo, O.K. Farha, R.Q. Snurr, A. Aspuru-Guzik, Inverse design of nanoporous crystalline reticular materials with deep generative models, Nature Machine Intelligence 3 (1) (2021) 76–86, https://doi.org/10.1038/s42256-02000271-1.
A.S. Alshehri and F. You


Chemical Engineering Journal 444 (2022) 136669
7
[10] Y. Lecun, Y. Bengio, G. Hinton, Deep learning, Nature 521 (2015) 436–444, https://doi.org/10.1038/nature14539. [11] D. Weininger, Smiles, a chemical language and information system. 1. Introduction to methodology and encoding rules, Journal of Chemical Information and Modeling 28 (1) (1988) 31–36, https://doi.org/10.1021/ci00057a005. [12] R. Gomez-Bombarelli, J.N. Wei, D. Duvenaud, J.M. Hernandez-Lobato, B. SanchezLengeling, D. Sheberla, J. Aguilera-Iparraguirre, T.D. Hirzel, R.P. Adams, A. Aspuru-Guzik, Automatic chemical design using a data-driven continuous representation of molecules, ACS Cent. Sci. 4 (2) (2018) 268–276, https://doi.org/ 10.1021/acscentsci.7b00572. [13] Y. Rong, Y. Bian, T. Xu, W. Xie, Y. Wei, W. Huang, J. Huang, Self-supervised graph transformer on large-scale molecular data, Advances in Neural Information Processing Systems 33 (2020). [14] K.T. Schütt, F. Arbabzadah, S. Chmiela, K.R. Müller, A. Tkatchenko, Quantumchemical insights from deep tensor neural networks, Nat. Commun. 8 (1) (2017) 1–8, https://doi.org/10.1038/ncomms13890. [15] K. Atz, F. Grisoni, G. Schneider, Geometric deep learning on molecular representations, Nature Machine Intelligence 3 (12) (2021) 1023–1032, https:// doi.org/10.1038/s42256-021-00418-8. [16] L. Ardizzone, J. Kruse, S. Wirkert, D. Rahner, E.W. Pellegrini, R.S. Klessen, L. Maier-Hein, C. Rother, U. K ̈othe, Analyzing inverse problems with invertible neural networks, ArXiv (2018). [17] N. Xie, G. Ras, M. van Gerven, D. Doran, Explainable deep learning: A field guide for the uninitiated, ArXiv (2020). [18] Y. Cheng, Y. Gong, Y. Liu, B. Song, Q. Zou, Molecular design in drug discovery: a comprehensive review of deep generative models, Briefings Bioinf. 22 (6) (2021), https://doi.org/10.1093/bib/bbab344. [19] W.P. Walters, R. Barzilay, Applications of deep learning in molecule generation and molecular property prediction, Acc. Chem. Res. 54 (2) (2021) 263–270. [20] C.W. Coley, W.H. Green, K.F. Jensen, Machine learning in computer-aided synthesis planning, Acc. Chem. Res. 51 (5) (2018) 1281–1289, https://doi.org/ 10.1021/acs.accounts.8b00087. [21] J. Dong, M. Zhao, Y. Liu, Y. Su, X. Zeng, Deep learning in retrosynthesis planning: datasets, models and tools, Briefings Bioinf. 23 (1) (2021), https://doi.org/ 10.1093/bib/bbab391. [22] X. Pan, X. Lin, D. Cao, X. Zeng, P.S. Yu, L. He, R. Nussinov, F. Cheng, Deep learning for drug repurposing: Methods, databases, and applications, in: WIREs Computational Molecular Science, e1597, 2022. [23] A.S. Alshehri, F. You, Paradigm Shift: the promise of deep learning in molecular systems engineering and design, Frontiers in Chemical Engineering 3 (2021) 26, https://doi.org/10.3389/fceng.2021.700717. [24] J. Zhou, G. Cui, S. Hu, Z. Zhang, C. Yang, Z. Liu, L. Wang, C. Li, M. Sun, Graph neural networks: A review of methods and applications, AI Open 1 (2020) 57–81, https://doi.org/10.1016/j.aiopen.2021.01.001. [25] H. Dai, C. Li, C.W. Coley, B. Dai, L. Song, Retrosynthesis prediction with conditional graph logic network, ArXiv (2020). [26] H. Wen, Y. Su, Z. Wang, S. Jin, J. Ren, W. Shen, M. Eden, A systematic modeling methodology of deep neural network-based structure-property relationship for rapid and reliable prediction on flashpoints 68 (1) (2022), e17402, https://doi. org/10.1002/aic.17402. [27] K.K. Yalamanchi, V.C.O. van Oudenhoven, F. Tutino, M. Monge-Palacios, A. Alshehri, X. Gao, S.M. Sarathy, Machine learning to predict standard enthalpy of formation of hydrocarbons, J Phys Chem A 123 (38) (2019) 8305–8313, https:// doi.org/10.1021/acs.jpca.9b04771. [28] Y. Li, P. Li, X. Yang, C.-Y. Hsieh, S. Zhang, X. Wang, R. Lu, H. Liu, X. Yao, Introducing block design in graph neural networks for molecular properties prediction, Chem. Eng. J. 414 (2021), 128817, https://doi.org/10.1016/j. cej.2021.128817. [29] A. Thakkar, V. Chadimov ́a, E.J. Bjerrum, O. Engkvist, J.-L. Reymond, Retrosynthetic accessibility score (RAscore) – rapid machine learned synthesizability classification from AI driven retrosynthetic planning, Chem. Sci. 12 (9) (2021) 3339–3349, https://doi.org/10.1039/D0SC05401A. [30] J. Li, T. Chen, K. Lim, L. Chen, S.A. Khan, J. Xie, X. Wang, Deep Learning Accelerated Gold Nanocluster Synthesis, 1(3) (2019) 1900029. https://doi.org/ https://doi.org/10.1002/aisy.201900029. [31] A.S. Alshehri, F. You, Machine learning for multiscale modeling in computational molecular design, Curr. Opin. Chem. Eng. 36 (2022), 100752, https://doi.org/ 10.1016/j.coche.2021.100752. [32] N.A. Jose, M. Kovalev, E. Bradford, A.M. Schweidtmann, H. Chun Zeng, A. A. Lapkin, Pushing nanomaterials up to the kilogram scale – An accelerated approach for synthesizing antimicrobial ZnO with high shear reactors, machine learning and high-throughput analysis, Chemical Engineering Journal 426 (2021), 131345, https://doi.org/10.1016/j.cej.2021.131345. [33] R. Nian, J. Liu, B. Huang, A review on reinforcement learning: Introduction and applications in industrial process control, Comput. Chem. Eng. 139 (2020) 106886, https://doi.org/10.1016/j.compchemeng.2020.106886. [34] S.K. Gottipati, B. Sattarov, S. Niu, Y. Pathak, H. Wei, S. Liu, S. Liu, S. Blackburn, K. Thomas, C. Coley, J. Tang, S. Chandar, Y. Bengio, Learning to Navigate The Synthetically Accessible Chemical Space Using Reinforcement Learning, in: D. Hal, III, S. Aarti (Eds.) Proceedings of the 37th International Conference on Machine Learning, PMLR, Proceedings of Machine Learning Research, 2020, pp. 36683679. [35] P.W. Battaglia, J.B. Hamrick, V. Bapst, A. Sanchez-Gonzalez, V. Zambaldi, M. Malinowski, A. Tacchetti, D. Raposo, A. Santoro, R. Faulkner, Relational inductive biases, deep learning, and graph networks, ArXiv (2018).
[36] H. Yuan, H. Yu, J. Wang, K. Li, S. Ji, On explainability of graph neural networks via subgraph explorations, Int. Conference on Machine Learning, PMLR (2021) 12241–12252. [37] O. Ganea, L. Pattanaik, C. Coley, R. Barzilay, K. Jensen, W. Green, T. Jaakkola, Geomol: Torsional geometric generation of molecular 3d conformer ensembles, ArXiv (2021). [38] N.W.A. Gebauer, M. Gastegger, S.S.P. Hessmann, K.-R. Müller, K.T. Schütt, Inverse design of 3d molecular structures with conditional generative neural networks, Nat. Commun. 13 (1) (2022) 973, https://doi.org/10.1038/s41467-022-28526-y. [39] V.G. Satorras, E. Hoogeboom, M. Welling, E (n) equivariant graph neural networks, ArXiv (2021). [40] A. Khan, A. Sohail, U. Zahoora, A.S. Qureshi, A survey of the recent architectures of deep convolutional neural networks, Artif. Intell. Rev. 53 (8) (2020) 5455–5516, https://doi.org/10.1007/s10462-020-09825-6. [41] I. Goodfellow, Y. Bengio, A. Courville, Deep Learning, MIT Press, Cambridge, 2016. [42] H.J. Escalante, S. Escalera, I. Guyon, X. Bar ́o, Y. Güçlütürk, U. Güçlü, M. van Gerven, R. van Lier, Explainable and interpretable models in computer vision and machine learning, Springer, 2018.
[43] J. Jim ́enez, M. ˇSkaliˇc, G. Martínez-Rosell, G. De Fabritiis, KDEEP: Protein-ligand absolute binding affinity prediction via 3d-convolutional neural networks, J. Chem. Inf. Model. 58 (2) (2018) 287–296, https://doi.org/10.1021/acs. jcim.7b00650. [44] E. Ahmed, A. Saint, A.E.R. Shabayek, K. Cherenkova, R. Das, G. Gusev, D. Aouada, B. Ottersten, A survey on deep learning advances on different 3D data representations, ArXiv (2018). [45] Q.-S. Zhang, S.-C. Zhu, Visual interpretability for deep learning: a survey, Frontiers Inf Technol Electronic Eng 19 (1) (2018) 27–39. [46] J. Zhang, B. Chen, L. Zhang, X. Ke, H. Ding, Neural, symbolic and neural-symbolic reasoning on knowledge graphs, AI Open 2 (2021) 14–35, https://doi.org/ 10.1016/j.aiopen.2021.03.001. [47] X. Zeng, X. Tu, Y. Liu, X. Fu, Y. Su, Toward better drug discovery with knowledge graph, Curr. Opin. Struct. Biol. 72 (2022) 114–126, https://doi.org/10.1016/j. sbi.2021.09.003. [48] M.H. Segler, M. Preuss, M.P. Waller, Planning chemical syntheses with deep neural networks and symbolic AI, Nature 555 (7698) (2018) 604–610, https://doi.org/ 10.1038/nature25978. [49] A. Feeney, R. Gupta, V. Thost, R. Angell, G. Chandu, Y. Adhikari, T.J.a.p.a. Ma, Relation Matters in Sampling: A Scalable Multi-Relational Graph Neural Network for Drug-Drug Interaction Prediction, (2021). [50] B. Kang, J. Lijffijt, T De Bie, An approach for explaining network embedding-based link predictions, ArXiv, Explaine, 2019. [51] A.S. Alshehri, A.K. Tula, F. You, R. Gani, Next generation pure component property estimation models: with and without machine learning techniques, AIChE J. (2022), e17469, https://doi.org/10.1002/aic.17469. [52] S. Kim, J. Chen, T. Cheng, A. Gindulyte, J. He, S. He, Q. Li, B.A. Shoemaker, P. A. Thiessen, B.o. Yu, L. Zaslavsky, J. Zhang, E.E. Bolton, PubChem in 2021: new data content and improved web interfaces, Nucleic Acids Res. 49 (D1) (2021). D1388 D1395.
[53] G. Nguyen, S. Dlugolinsky, M. Bob ́ak, V. Tran, A ́. L ́opez García, I. Heredia, P. Malík, L. Hluchý, Machine Learning and Deep Learning frameworks and libraries for large-scale data mining: a survey, Artif Intell Rev 52 (1) (2019) 77–124. [54] H. Gurulingappa, A. Mudi, L. Toldo, M. Hofmann-Apitius, J. Bhate, Challenges in mining the literature for chemical information, RSC Adv. 3 (37) (2013) 16194–16211, https://doi.org/10.1039/C3RA40787J. [55] L. Weber, M. Sa ̈nger, J. Münchmeyer, M. Habibi, U. Leser, A. Akbik, J. Wren, HunFlair: an easy-to-use tool for state-of-the-art biomedical named entity recognition, Bioinformatics 37 (17) (2021) 2792–2794. [56] C.J. Court, A. Jain, J.M. Cole, Inverse design of materials that exhibit the magnetocaloric effect by text-mining of the scientific literature and generative deep learning, Chem. Mater. 33 (18) (2021) 7217–7231, https://doi.org/10.1021/ acs.chemmater.1c01368. [57] T.B. Brown, B. Mann, N. Ryder, M. Subbiah, J. Kaplan, P. Dhariwal, A. Neelakantan, P. Shyam, G. Sastry, A. Askell, Language models are few-shot learners, ArXiv (2020). [58] J. Hermann, Z. Sch ̈atzle, F. No ́e, Deep-neural-network solution of the electronic Schr ̈odinger equation, Nat. Chem. 12 (10) (2020) 891–897, https://doi.org/ 10.1038/s41557-020-0544-y. [59] P.O. Dral, Quantum chemistry in the age of machine learning, J. Phys. Chem. Letters 11 (6) (2020) 2336–2347, https://doi.org/10.1021/acs.jpclett.9b03664. [60] R. Ramakrishnan, P.O. Dral, M. Rupp, O.A. von Lilienfeld, Quantum chemistry structures and properties of 134 kilo molecules, Sci. Data 1 (1) (2014), 140022, https://doi.org/10.1038/sdata.2014.22. [61] C. Gertig, K. Leonhard, A. Bardow, Computer-aided molecular and processes design based on quantum chemistry: current status and future prospects, Curr. Opin. Chem. Eng. 27 (2020) 89–97, https://doi.org/10.1016/j.coche.2019.11.007. [62] C. Cai, S. Wang, Y. Xu, W. Zhang, K. Tang, Q. Ouyang, L. Lai, J. Pei, Transfer learning for drug discovery, J. Med. Chem. 63 (16) (2020) 8683–8694, https://doi. org/10.1021/acs.jmedchem.9b02147. [63] J.S. Smith, B.T. Nebgen, R. Zubatyuk, N. Lubbers, C. Devereux, K. Barros, S. Tretiak, O. Isayev, A.E. Roitberg, Approaching coupled cluster accuracy with a general-purpose neural network potential through transfer learning, Nat. Commun. 10 (1) (2019) 2903, https://doi.org/10.1038/s41467-019-10827-4. [64] J. Boitreaud, V. Mallet, C. Oliver, J. Waldispühl, OptiMol: optimization of binding affinities in chemical space for drug discovery, J. Chem. Inf. Model. 60 (12) (2020) 5658–5666, https://doi.org/10.1021/acs.jcim.0c00833.
A.S. Alshehri and F. You


Chemical Engineering Journal 444 (2022) 136669
8
[65] N. Brown, M. Fiscato, M.H.S. Segler, A.C. Vaucher, GuacaMol: benchmarking models for de novo molecular design, J. Chem. Inf. Model. 59 (3) (2019) 1096–1108, https://doi.org/10.1021/acs.jcim.8b00839. [66] D. Polykovskiy, A. Zhebrak, B. Sanchez-Lengeling, S. Golovanov, O. Tatanov, S. Belyaev, R. Kurbanov, A. Artamonov, V. Aladinskiy, M. Veselov, A. Kadurin, S. Johansson, H. Chen, S. Nikolenko, A. Aspuru-Guzik, A. Zhavoronkov, Molecular Sets (MOSES): A Benchmarking Platform for Molecular Generation Models 11 (1931) (2020), https://doi.org/10.3389/fphar.2020.565644. [67] X. Liu, F. Zhang, Z. Hou, L. Mian, Z. Wang, J. Zhang, J. Tang, Self-supervised learning: generative or contrastive, 1 1, IEEE Trans. Knowl. Data Eng. (2021), https://doi.org/10.1109/TKDE.2021.3090866. [68] A. Trofimov, J.P. Cohen, Y. Bengio, C. Perreault, S. Lemieux, Factorized embeddings learns rich and biologically meaningful embedding spaces using factorized tensor decomposition, Bioinformatics 36 (Supplement_1) (2020) i417–i426, https://doi.org/10.1093/bioinformatics/btaa488. [69] J. Noh, J. Kim, H.S. Stein, B. Sanchez-Lengeling, J.M. Gregoire, A. Aspuru-Guzik, Y. Jung, Inverse design of solid-state materials via a continuous representation, Matter 1 (5) (2019) 1370–1384, https://doi.org/10.1016/j.matt.2019.08.017. [70] L. Zhang, H. Mao, Q. Liu, R. Gani, Chemical product design – recent advances and perspectives, Curr. Opin. Chem. Eng. 27 (2020) 22–34. [71] A. Khan, A. Lapkin, Searching for optimal process routes: A reinforcement learning approach, Comput Chem Eng 141 (2020), 107027, https://doi.org/10.1016/j. compchemeng.2020.107027. [72] N. Mazyavkina, S. Sviridov, S. Ivanov, E. Burnaev, Reinforcement learning for combinatorial optimization: A survey, Comput. Oper. Res. 134 (2021), 105400, https://doi.org/10.1016/j.cor.2021.105400.
[73] N. Stiennon, L. Ouyang, J. Wu, D.M. Ziegler, R. Lowe, C. Voss, A. Radford, D. Amodei, P. Christiano, Learning to summarize from human feedback, ArXiv (2020). [74] A. Abels, D. Roijers, T. Lenaerts, A. Nowe ́, D. Steckelmacher, Dynamic Weights in Multi-Objective Deep Reinforcement Learning, in: C. Kamalika, S. Ruslan (Eds.), Proceedings of the 36th International Conference on Machine Learning, PMLR, Proceedings of Machine Learning Research, 2019, pp. 11–20. [75] B. O’Donoghue, I. Osband, C. Ionescu, Making sense of reinforcement learning and probabilistic inference, ArXiv (2020). [76] G. Simm, R. Pinsler, J.M. Hernandez-Lobato, Reinforcement Learning for Molecular Design Guided by Quantum Mechanics, in: D. Hal, S. Aarti (Eds.), Proceedings of the 37th International Conference on Machine Learning, PMLR, Proceedings of Machine Learning Research, 2020, pp. 8959–8969. [77] A.G. Kusne, H. Yu, C. Wu, H. Zhang, J. Hattrick-Simpers, B. DeCost, S. Sarker, C. Oses, C. Toher, S. Curtarolo, A.V. Davydov, R. Agarwal, L.A. Bendersky, M. Li, A. Mehta, I. Takeuchi, On-the-fly closed-loop materials discovery via Bayesian active learning, Nat. Commun. 11 (1) (2020) 5966, https://doi.org/10.1038/ s41467-020-19597-w. [78] Y. Gong, D. Xue, G. Chuai, J. Yu, Q. Liu, DeepReac+: deep active learning for quantitative modeling of organic chemical reactions, Chem. Sci. 12 (43) (2021) 14459–14472, https://doi.org/10.1039/D1SC02087K. [79] P. Ren, Y. Xiao, X. Chang, P.-Y. Huang, Z. Li, B.B. Gupta, X. Chen, X. Wang, A survey of deep active learning, ACM Comput. Surv. 54 (9) (2022) 1–40.
A.S. Alshehri and F. You