This Week’s Citation Classic

NUMBER 15 APRIL 9, 1979

Nelder J A & Mead R. A simplex method for function minimization. Comput. J. 7:30813, 1965.

A function of n variables is minimised by comparing its values at the (n + 1) vertices of a general simplex, and replacing the vertex with the highest value by another point. The simplex adapts itself to the local landscape, and ontracts on to the final minimum. [The SCI® indicates that this paper has been cited over 485 times since 1965.]
J. A. Nelder Statistics Department Rothamsted Experimental Station Harpenden, Hertfordshire AL5 2JQ
England
February 3, 1978
“To me a scientific meeting is a success if I come away from it with one useful new idea. To ask for two is too much, and all too often the score is zero. However, in Cambridge in 1963 I heard Dr. Spendley of Imperial Chemical Industries speak on the use of simplex designs in optimising industrial chemical systems. The simplices he described were of points in a space of controllable factors, and they moved by reflexion of one point (the worst one) in the plane defined by the others., A suitable strategy caused the simplex to settle near the optimum, i.e. that producing the highest yield of the process. I came back with the idea of adapting this procedure to the minimisation of mathematical functions, and so my colleague Roger Mead and I evolved the procedure described in this paper. We realised that, for a general minimisation procedure, the simplex would

have to adapt itself to the local landscape, for example by elongating itself to move down long gentle slopes, or by contracting on to the finaf minimum. We thus augmented the original action of reflexion by two others, expansion and contraction, and so the algorithm was born. Its development benefitted considerably from each of us being able to try out the ideas of the previous evening on the other the following morning. When compared with other algorithms of the time it did well, and seemed remarkably robust. Its appearance surprised some professional optimisers (we, the authors, were statisticians), some of whom had convinced themselves that directsearch methods (to which the simplex method belongs) were basically unpromising. Our address (National Vegetable Research Station) also caused surprise in one famous US laboratory, whose staff clearly doubted if turnipbashers could be numerate.
“Early on, Mead and I were frustrated in all our attempts to refine our original algorithm, and others have also had very limited success. In particular the value 2, our original and quite arbitrary choice for the rates of both expansion and contraction, seems to be optimal. Further developments in optimisation theory have produced better algorithms, at least for certain problems, so the future of our simplex method is not at all clear. Why then the frequent citations? I am both proud and baffled. It may be because the underlying ideas are extremely simple— you do not have to know what a Hessian matrix is to understand them; also perhaps because you can do a two-dimensional optimisation with pencil and paper, drawing triangles on a set of contours. Whatever the reason, I often wish I knew of all the problems that the adaptive simplices have helped to solve. I wish I knew too how to find the meeting that will supply the next useful idea.”

22

