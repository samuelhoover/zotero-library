Journal of Artificial Intelligence Research 12 (2000) 149‚Äì198 Submitted 11/99; published 3/00
A Model of Inductive Bias Learning
Jonathan Baxter JONATHAN.BAXTER@ANU.EDU.AU Research School of Information Sciences and Engineering Australian National University, Canberra 0200, Australia
Abstract
A major problem in machine learning is that of inductive bias: how to choose a learner‚Äôs hypothesis space so that it is large enough to contain a solution to the problem being learnt, yet small enough to ensure reliable generalization from reasonably-sized training sets. Typically such bias is supplied by hand through the skill and insights of experts. In this paper a model for automatically learning bias is investigated. The central assumption of the model is that the learner is embedded within an environment of related learning tasks. Within such an environment the learner can sample from multiple tasks, and hence it can search for a hypothesis space that contains good solutions to many of the problems in the environment. Under certain restrictions on the set of all hypothesis spaces available to the learner, we show that a hypothesis space that performs well on a sufficiently large number of training tasks will also perform well when learning novel tasks in the same environment. Explicit bounds are also derived demonstrating that learning multiple tasks within an environment of related tasks can potentially give much better generalization than learning a single task.
1. Introduction
Often the hardest problem in any machine learning task is the initial choice of hypothesis space; it has to be large enough to contain a solution to the problem at hand, yet small enough to ensure good generalization from a small number of examples (Mitchell, 1991). Once a suitable bias has been found, the actual learning task is often straightforward. Existing methods of bias generally require the input of a human expert in the form of heuristics and domain knowledge (for example, through the selection of an appropriate set of features). Despite their successes, such methods are clearly limited by the accuracy and reliability of the expert‚Äôs knowledge and also by the extent to which that knowledge can be transferred to the learner. Thus it is natural to search for methods for automatically learning the bias.
In this paper we introduce and analyze a formal model of bias learning that builds upon the PAC model of machine learning and its variants (Vapnik, 1982; Valiant, 1984; Blumer, Ehrenfeucht, Haussler, & Warmuth, 1989; Haussler, 1992). These models typically take the following general form: the learner is supplied with a hypothesis space and training data
    drawn independently according to some underlying distribution 
on !" . Based on the information contained in  , the learner‚Äôs goal is to select a hypothesis
#%$ '&(" from minimizing some measure )*+  #  of expected loss with respect to  (for ex
ample,inthecaseofsquaredloss )*+  #  $-,/.103246587 +  #  9;:<=?> ). Insuchmodelsthelearner‚Äôs
bias is represented by the choice of ; if does not contain a good solution to the problem, then, regardless of how much data the learner receives, it cannot learn.
Of course, the best way to bias the learner is to supply it with an containing just a single optimal hypothesis. But finding such a hypothesis is precisely the original learning problem, so in the
@ c 2000 AI Access Foundation and Morgan Kaufmann Publishers. All rights reserved.


BAXTER
PAC model there is no distinction between bias learning and ordinary learning. Or put differently, the PAC model does not model the process of inductive bias, it simply takes the hypothesis space as given and proceeds from there. To overcome this problem, in this paper we assume that instead of being faced with just a single learning task, the learner is embedded within an environment of
related learning tasks. The learner is supplied with a family of hypothesis spaces A B  , and its
goal is to find a bias (i.e. hypothesis space DC A ) that is appropriate for the entire environment.
A simple example is the problem of handwritten character recognition. A preprocessing stage that identifies and removes any (small) rotations, dilations and translations of an image of a character will be advantageous for recognizing all characters. If the set of all individual character recognition problems is viewed as an environment of learning problems (that is, the set of all problems of the form ‚Äúdistinguish ‚ÄòA‚Äô from all other characters‚Äù, ‚Äúdistinguish ‚ÄòB‚Äô from all other characters‚Äù, and so on), this preprocessor represents a bias that is appropriate for all problems in the environment. It is likely that there are many other currently unknown biases that are also appropriate for this environment. We would like to be able to learn these automatically.
There are many other examples of learning problems that can be viewed as belonging to environments of related problems. For example, each individual face recognition problem belongs to an (essentially infinite) set of related learning problems (all the other individual face recognition problems); the set of all individual spoken word recognition problems forms another large environment, as does the set of all fingerprint recognition problems, printed Chinese and Japanese character recognition problems, stock price prediction problems and so on. Even medical diagnostic and prognostic problems, where a multitude of diseases are predicted from the same pathology tests, constitute an environment of related learning problems.
In many cases these ‚Äúenvironments‚Äù are not normally modeled as such; instead they are treated as single, multiple category learning problems. For example, recognizing a group of faces would normally be viewed as a single learning problem with multiple class labels (one for each face in the group), not as multiple individual learning problems. However, if a reliable classifier for each individual face in the group can be constructed then they can easily be combined to produce a classifier for the whole group. Furthermore, by viewing the faces as an environment of related learning problems, the results presented here show that bias can be learnt that will be good for learning novel faces, a claim that cannot be made for the traditional approach.
This point goes to the heart of our model: we are not not concerned with adjusting a learner‚Äôs bias so it performs better on some fixed set of learning problems. Such a process is in fact just ordinary learning but with a richer hypothesis space in which some components labelled ‚Äúbias‚Äù are also able to be varied. Instead, we suppose the learner is faced with a (potentially infinite) stream of tasks, and that by adjusting its bias on some subset of the tasks it improves its learning performance on future, as yet unseen tasks.
Bias that is appropriate for all problems in an environment must be learnt by sampling from many tasks. If only a single task is learnt then the bias extracted is likely to be specific to that task. In the rest of this paper, a general theory of bias learning is developed based upon the idea of learning multiple related tasks. Loosely speaking (formal results are stated in Section 2), there are two main conclusions of the theory presented here:
E
Learning multiple related tasks reduces the sampling burden required for good generalization, at least on a number-of-examples-required-per-task basis.
150


A MODEL OF INDUCTIVE BIAS LEARNING
E
Bias that is learnt on sufficiently many training tasks is likely to be good for learning novel tasks drawn from the same environment.
The second point shows that a form of meta-generalization is possible in bias learning. Ordinarily, we say a learner generalizes well if, after seeing sufficiently many training examples, it produces a hypothesis that with high probability will perform well on future examples of the same task. However, a bias learner generalizes well if, after seeing sufficiently many training tasks it produces a hypothesis space that with high probability contains good solutions to novel tasks. Another term that has been used for this process is Learning to Learn (Thrun & Pratt, 1997).
Our main theorems are stated in an agnostic setting (that is, A does not necessarily contain a
hypothesis space with solutions to all the problems in the environment), but we also give improved bounds in the realizable case. The sample complexity bounds appearing in these results are stated
in terms of combinatorial parameters related to the complexity of the set of all hypothesis spaces A
available to the bias learner. For Boolean learning problems (pattern classification) these parameters are the bias learning analogue of the Vapnik-Chervonenkis dimension (Vapnik, 1982; Blumer et al., 1989). As an application of the general theory, the problem of learning an appropriate set of neuralnetwork features for an environment of related tasks is formulated as a bias learning problem. In the case of continuous neural-network features we are able to prove upper bounds on the number of training tasks and number of examples of each training task required to ensure a set of features that works well for the training tasks will, with high probability, work well on novel tasks drawn
from the same environment. The upper bound on the number of tasks scales as F HG where G is
a measure of the complexity of the possible feature sets available to the learner, while the upper
bound on the number of examples of each task scales as F JILKMGONPQ where F JIR is the number
of examples required to learn a task if the ‚Äútrue‚Äù set of features (that is, the correct bias) is already
known, and P is the number of tasks. Thus, in this case we see that as the number of related tasks
learnt increases, the number of examples required of each task for good generalization decays to the minimum possible. For Boolean neural-network feature maps we are able to show a matching lower bound on the number of examples required per task of the same form.
1.1 Related Work
There is a large body of previous algorithmic and experimental work in the machine learning and statistics literature addressing the problems of inductive bias learning and improving generalization through multiple task learning. Some of these approaches can be seen as special cases of, or at least closely aligned with, the model described here, while others are more orthogonal. Without being completely exhaustive, in this section we present an overview of the main contributions. See Thrun and Pratt (1997, chapter 1) for a more comprehensive treatment.
E
Hierarchical Bayes. The earliest approaches to bias learning come from Hierarchical Bayesian methods in statistics (Berger, 1985; Good, 1980; Gelman, Carlin, Stern, & Rubim, 1995). In contrast to the Bayesian methodology, the present paper takes an essentially empirical process approach to modeling the problem of bias learning. However, a model using a mixture of hierarchical Bayesian and information-theoretic ideas was presented in Baxter (1997a), with similar conclusions to those found here. An empirical study showing the utility of the hierarchical Bayes approach in a domain containing a large number of related tasks was given in Heskes (1998).
151


BAXTER
E
Early machine learning work. In Rendell, Seshu, and Tcheng (1987) ‚ÄúVBMS‚Äù or Variable Bias Management System was introduced as a mechanism for selecting amongst different learning algorithms when tackling a new learning problem. ‚ÄúSTABB‚Äù or Shift To a Better Bias (Utgoff, 1986) was another early scheme for adjusting bias, but unlike VBMS, STABB was not primarily focussed on searching for bias applicable to large problem domains. Our use of an ‚Äúenvironment of related tasks‚Äù in this paper may also be interpreted as an ‚Äúenvironment of analogous tasks‚Äù in the sense that conclusions about one task can be arrived at by analogy with (sufficiently many of) the other tasks. For an early discussion of analogy in this context, see Russell (1989, S4.3), in particular the observation that for analogous problems the sampling burden per task can be reduced.
E
Metric-based approaches. The metric used in nearest-neighbour classification, and in vector quantization to determine the nearest code-book vector, represents a form of inductive bias. Using the model of the present paper, and under some extra assumptions on the tasks in the environment (specifically, that their marginal input-space distributions are identical and they only differ in the conditional probabilities they assign to class labels), it can be shown that there is an optimal metric or distance measure to use for vector quantization and onenearest-neighbour classification (Baxter, 1995a, 1997b; Baxter & Bartlett, 1998). This metric can be learnt by sampling from a subset of tasks from the environment, and then used as a distance measure when learning novel tasks drawn from the same environment. Bounds on the number of tasks and examples of each task required to ensure good performance on novel tasks were given in Baxter and Bartlett (1998), along with an experiment in which a metric was successfully trained on examples of a subset of 400 Japanese characters and then used as a fixed distance measure when learning 2600 as yet unseen characters.
A similar approach is described in Thrun and Mitchell (1995), Thrun (1996), in which a neural network‚Äôs output was trained to match labels on a novel task, while simultaneously being forced to match its gradient to derivative information generated from a distance metric trained on previous, related tasks. Performance on the novel tasks improved substantially with the use of the derivative information.
Note that there are many other adaptive metric techniques used in machine learning, but these all focus exclusively on adjusting the metric for a fixed set of problems rather than learning a metric suitable for learning novel, related tasks (bias learning).
E
Feature learning or learning internal representations. As with adaptive metric techniques, there are many approaches to feature learning that focus on adapting features for a fixed task rather than learning features to be used in novel tasks. One of the few cases where features have been learnt on a subset of tasks with the explicit aim of using them on novel tasks was Intrator and Edelman (1996) in which a low-dimensional representation was learnt for a set of multiple related image-recognition tasks and then used to successfully learn novel tasks of the same kind. The experiments reported in Baxter (1995a, chapter 4) and Baxter (1995b), Baxter and Bartlett (1998) are also of this nature.
E
Bias learning in Inductive Logic Programming (ILP). Predicate invention refers to the process in ILP whereby new predicates thought to be useful for the classification task at hand are added to the learner‚Äôs domain knowledge. By using the new predicates as background domain knowledge when learning novel tasks, predicate invention may be viewed as a form of
152


A MODEL OF INDUCTIVE BIAS LEARNING
inductive bias learning. Preliminary results with this approach on a chess domain are reported in Khan, Muggleton, and Parson (1998).
E
Improving performance on a fixed reference task. ‚ÄúMulti-task learning‚Äù (Caruana, 1997) trains extra neural network outputs to match related tasks in order to improve generalization performance on a fixed reference task. Although this approach does not explicitly identify the extra bias generated by the related tasks in a way that can be used to learn novel tasks, it is an example of exploiting the bias provided by a set of related tasks to improve generalization performance. Other similar approaches include Suddarth and Kergosien (1990), Suddarth and Holden (1991), Abu-Mostafa (1993).
E
Bias as computational complexity. In this paper we consider inductive bias from a samplecomplexity perspective: how does the learnt bias decrease the number of examples required of novel tasks for good generalization? A natural alternative line of enquiry is how the runningtime or computational complexity of a learning algorithm may be improved by training on related tasks. Some early algorithms for neural networks in this vein are contained in Sharkey and Sharkey (1993), Pratt (1992).
E
Reinforcement Learning. Many control tasks can appropriately be viewed as elements of sets of related tasks, such as learning to navigate to different goal states, or learning a set of complex motor control tasks. A number of papers in the reinforcement learning literature have proposed algorithms for both sharing the information in related tasks to improve average generalization performance across those tasks Singh (1992), Ring (1995), or learning bias from a set of tasks to improve performance on future tasks Sutton (1992), Thrun and Schwartz (1995).
1.2 Overview of the Paper
In Section 2 the bias learning model is formally defined, and the main sample complexity results are given showing the utility of learning multiple related tasks and the feasibility of bias learning. These results show that the sample complexity is controlled by the size of certain covering numbers associated with the set of all hypothesis spaces available to the bias learner, in much the same way as the sample complexity in learning Boolean functions is controlled by the Vapnik-Chervonenkis dimension (Vapnik, 1982; Blumer et al., 1989). The results of Section 2 are upper bounds on the sample complexity required for good generalization when learning multiple tasks and learning inductive bias.
The general results of Section 2 are specialized to the case of feature learning with neural networks in Section 3, where an algorithm for training features by gradient descent is also presented. For this special case we are able to show matching lower bounds for the sample complexity of multiple task learning. In Section 4 we present some concluding remarks and directions for future research. Many of the proofs are quite lengthy and have been moved to the appendices so as not to interrupt the flow of the main text.
The following tables contain a glossary of the mathematical symbols used in the paper.
153


BAXTER
Symbol Description First Referenced

Input Space 155
"
Output Space 155

Distribution on ST" (learning task) 155
U
Loss function 155 Hypothesis Space 155
#
Hypothesis 155
)* +  #  Error of hypothesis # on distribution  156

Training set 156
V
Learning Algorithm 156
)W*X  #  Empirical error of # on training set  156
Y
Set of all learning tasks  157
Z
Distribution over learning tasks 157
A
Family of hypothesis spaces 157
)*[   Loss of hypothesis space on environment Z 158
\ P]^_ -sample 158
)W*a`   Empiricallossof on \ 158
V
Bias learning algorithm 159
#b Function induced by # and U 159
b
Set of #b 159
# #Rc b Averageof# 2b# c 2b 159
dQb Sameas# #Rc b 159
cb Setof# #=c b 159
A cb Setof cb 159
Te Function on probability distributions 160
A e Set of e 160
fg Pseudo-metric on cb 160
f [ Pseudo-metric on A e 160
h Jij A e f [  Coveringnumberof A e 160
k Jij A e  CapacityofA e 160
h Jij A cb flg  CoveringnumberofA cb 160
m Jij A cb  CapacityofA cb 160
d
SequenceofP hypotheses  #  #=c  163
n
SequenceofP distributions     c  163
)* g  d  Averagelossof d on n 164
)W* `  d  Averagelossof d on \ 164
o
Set of feature maps 166
p
Output class composed with feature maps q 166
psr q Hypothesis space associated with q 166
p b Loss function class associated with p 166
h Jij p b f +  Coveringnumberofp b 166
k Hij p b  Capacityofp b 166
ft+ 2uvxw  q qzy Pseudo-metriconfeaturemapsq qzy 166
h Jij o f=t+ 2uv{w Coveringnumberofo 166
154


A MODEL OF INDUCTIVE BIAS LEARNING
Symbol Description First Referenced
h Jij o f t+ 2uv{w8 Coveringnumberofo 166
k uv Jij o  Capacityofo 166
}| Neural network hypothesis space 167
~0 restricted to vector  172
¬Ä¬Ç¬Å  ^_ Growth function of 172
¬É¬Ç¬Ñ¬Ü¬Ö¬á¬â¬à   Vapnik-Chervonenkis dimension of 172
~¬ä restricted to matrix ¬ã 173
A ~¬ä A restricted to matrix ¬ã 173
¬Ä¬ç¬å  P]^_ Growthfunctionof A 173
f ¬å  PQ Dimension function of A 173
f  A  Upper dimension function of A 173
f  A  Lower dimension function of A 173
¬é¬è=¬ê g  A c  Optimalperformanceof A c on n 175
f¬ë Metricon¬í¬î¬ì 179
# /¬ï¬ó¬ñ¬ñ¬ñ¬ò¬ï #=c Averageof# , ,#Rc 179
¬ô¬ï¬ö¬ñ¬ñ¬ñ3¬ï c Setof# /¬ï¬ó¬ñ¬ñ¬ñ¬ò¬ï #=c 180
¬õ . >  2c 5 Permutations on integer pairs 182
\j¬ú Permuted \ 182
f `  d d y  Empirical U metric on functions d 182
)W* g   Optimal average error of on n 185
2. The Bias Learning Model
In this section the bias learning model is formally introduced. To motivate the definitions, we first describe the main features of ordinary (single-task) supervised learning models.
2.1 Single-Task Learning
Computational learning theory models of supervised learning usually include the following ingre
dienE ts:An input space  and an output space " ,
E
a probability distribution  on Ss" ,
E
alossfunctionU¬ò$ "¬ùs"¬û&D¬í , and
E
a hypothesis space which is a set of hypotheses or functions #¬ü$  &¬°" .
As an example, if the problem is to learn to recognize images of Mary‚Äôs face using a neural network,
then  would be the set of all images (typically represented as a subset of ¬í]¬¢ where each component
is a pixel intensity), " would be the set ¬£ ¬§¬ò , and the distribution  would be peaked over images
of different faces and the correct class labels. The learner‚Äôs hypothesis space would be a class of
neural networks mapping the input space ¬í ¬¢ to ¬£ ¬§¬ò . The loss in this case would be discrete loss:
Uzy $¬¶¬• ¬§ if¬ß¬óy
¬£
ifL¬ó y (1)
155


BAXTER
Using the loss function allows us to present a unified treatment of both pattern recognition (" 
¬£ ¬§¬ò , U as above), and real-valued function learning (e.g. regression) in which "  ¬í and usually
U   Ãà y ]¬© L:a y  > .
The goal of the learner is to select a hypothesis # CT with minimum expected loss:
)*+ #  $B¬´¬¨¬Æ¬∞ ÃÑ U# ¬±=f QR (2)
Of course, the learner does not know  and so it cannot search through for an # minimizing
)* +  #  . In practice, the learner samples repeatedly from 23" according to the distribution  to
generateatrainingset  $¬û      j (3)
Based on the information contained in  the learner produces a hypothesis # CT . Hence, in general
a learner is simply a map V from the set of all training samples to the hypothesis space :
V $¬ó ÃÅ¬üŒº¬∂DT"  &
(stochastic learner‚Äôs can be treated by assuming a distribution-valued V .)
Many algorithms seek to minimize the empirical loss of # on  , where this is defined by:
)W*X#  $ ^¬§ ¬∑ Ãß¬â1 U#   Ãß Ãß (4)
Of course, there are more intelligent things to do with the data than simply minimizing empirical error‚Äîfor example one can add regularisation terms to avoid over-fitting.
However the learner chooses its hypothesis # , if we have a uniform bound (over all # C ) on
the probability of large deviation between )W*X  #  and )*+  #  , then we can bound the learner‚Äôs gen
eralization error )*+  #  as a function of its empirical loss on the training set )W*X  #  . Whether such
a bound holds depends upon the ‚Äúrichness‚Äù of . The conditions ensuring convergence between
)W* X  #  and )* +  #  arebynowwellunderstood;forBooleanfunctionlearning(" B¬£ ¬§¬ò , discrete
loss), convergence is controlled by the VC-dimension1 of :
Theorem 1. Let  be any probability distribution on  ¬£ ¬§¬ò and suppose  
 6¬ç isgeneratedbysampling^ timesfromo ¬£ ¬§¬ò accordingto . Let
f¬ª$  ¬É¬Ç¬Ñ¬Ü¬Ö=¬á¬â¬à   . Then with probability at least ¬§¬Æ:1‚ÅÑ21‚ÅÑ4 (over the choice of the training set  ), all
# C3‚ÅÑ4 will satisfy
)*+ # ¬Ü¬ø )W*X#  K AÃÄOAÃÅ^AÃÇ AÃÉfAÃäAÃà¬é√Ü AÃÇCÃßf^ K AÃà¬é√ÜEÃÅEÃÄ1‚ÅÑ4¬±EÃÇ¬üEÃà IÃÅIÃÄ> (5)
Proofs of this result may be found in Vapnik (1982), Blumer et al. (1989), and will not be reproduced here.
1. The VC dimension of a class of Boolean functions IÃÇ is the largest integer IÃà such that there exists a subset √ê¬ªNÃÉ OÃÄ
OÃÅaOÃÇOÃÉ√óOÃà√ó√ò√ó√ò√ó√òOÃàJOÃÇ3UÃÄUÃÅAÃäUÃÇYÃÅUÃà suchthattherestrictionofIÃÇ to√ê containsall√û UÃÄ Booleanfunctionson√ê .
156


A MODEL OF INDUCTIVE BIAS LEARNING
Theorem 1 only provides conditions under which the deviation between )*+  #  and )W*X  #  is
likely to be small, it does not guarantee that the true error )*+  #  will actually be small. This is
governed by the choice of . If contains a solution with small error and the learner minimizes
error on the training set, then with high probability )*+  #  will be small. However, a bad choice of
will mean there is no hope of achieving small error. Thus, the bias of the learner in this model2 is represented by the choice of hypothesis space .
2.2 The Bias Learning Model
The main extra assumption of the bias learning model introduced here is that the learner is embedded in an environment of related tasks, and can sample from the environment to generate multiple training sets belonging to multiple different tasks. In the above model of ordinary (single-task)
learning, a learning task is represented by a distribution  on √ü√†" . So in the bias learning
model, an environment of learning problems is represented by a pair  Y Z  where Y is the set of
all probability distributions on √°¬Æ" (i.e., Y is the set of all possible learning problems), and Z is a
distribution on Y . Z controls which learning problems the learner is likely to see3. For example, if
the learner is in a face recognition environment, Z will be highly peaked over face-recognition-type
problems, whereas if the learner is in a character recognition environment Z will be peaked over
character-recognition-type problems (here, as in the introduction, we view these environments as sets of individual classification problems, rather than single, multiple class classification problems). Recall from the last paragraph of the previous section that the learner‚Äôs bias is represented by its choice of hypothesis space . So to enable the learner to learn the bias, we supply it with a family
or set of hypothesis spaces A $ √¢  .
Putting all this together, formally a learning to learn or bias learning problem consists of:
E
an input space  and an output space " (both of which are separable metric spaces),
E
alossfunctionU¬ò$ "¬ùs"¬û&D¬í ,
E
an environment  Y Z  where Y is the set of all probability distributions on D3" and Z is
a distribution on Y ,
E
a hypothesis space family A √¢  where each aÃÉC A is a set of functions #%$  &2" .
From now on we will assume the loss function U has range √§ ¬£ ¬§6aÃä , or equivalently, with rescaling,
we assume that U is bounded.
2. The bias is also governed by how the learner uses the hypothesis space. For example, under some circumstances the
learner may choose not to use the full power of IÃÇ (a neural network example is early-stopping). For simplicity in
this paper we abstract away from such features of the algorithm √¶ and assume that it uses the entire hypothesis space
IÃÇ
.
3. √ß ‚Äôs domain is a √® -algebra of subsets of √© . A suitable one for our purposes is the Borel √® -algebra √™Q√´√¨√©AÃä√≠ generated
by the topology of weak convergence on √© . If we assume that UÃà and √Æ are separable metric spaces, then √© is also
a separable metric space in the Prohorov metric (which metrizes the topology of weak convergence) (Parthasarathy,
1967), so there is no problem with the existence of measures on √™¬ô√´√¨√©AÃä√≠ . See Appendix D for further discussion,
particularly the proof of part 5 in Lemma 32.
157


BAXTER
We define the goal of a bias learner to be to find a hypothesis space √üC A minimizing the
following loss:
)*6[   $ ¬´√Ø ¬á¬â√∞=√±
√≤√≥¬Å )*+ #  f Z   (6)
 ¬´√Ø ¬á¬â√∞=√±
√≤√≥¬Å ¬´¬¨EÃÅ¬∞ ÃÑ U# ¬±=f ¬ô=fZ  
The only way )*[   can be small is if, with high Z -probability, contains a good solution # to
any problem  drawn at random according to Z . In this sense )*[   measures how appropriate
the bias embodied by is for the environment  Y Z  .
In general the learner will not know Z , so it will not be able to find an minimizing )*[  
directly. However, the learner can sample from the environment in the following way:
E
Sample P times from Y according to Z to yield:
  c.
E
Sample ^ times from S3" according to each   Ãß to yield:
 Ãß B Ãß  Ãß  Ãà Ãß  Ãß .
E
The resulting P training sets‚Äîhenceforth called an  P]^_ -sample if they are generated by the
above process‚Äîare supplied to the learner. In the sequel, an  P]^_ -sample will be denoted
by\ andwrittenasamatrix:   ¬ñ¬ñ¬ñ  √¥¬ç√¥oÃÉ ¬öj
\ $  ... ... ... ...
 c c  ¬ñ¬ñ¬ñ  c c !¬öc (7)
An  P]^_ -sample is simply P training sets  a c sampled from P different learning tasks
   c , where each task is selected according to the environmental probability distribution Z .
The size of each training set is kept the same primarily to facilitate the analysis.
Based on the information contained in \ , the learner must choose a hypothesis space 'C A .
One way to do this would be for the learner to find an minimizing the empirical loss on \ , where
thisisdefinedby: )W* `   $ P¬§ ¬∑ Ãß√¨1c ¬á¬â√∞R√±
√≤3√≥¬Å )W*X?√∂#  (8)
Note that )W *a`   is simply the average of the best possible empirical error achievable on each
training set   Ãß , using a function from . It is a biased estimate of )*6[   . An unbiased esti
mate of )* [   would require choosing an with minimal average error over the P distributions
   c ,wherethisisdefinedbycEÃÅ√∑ c Ãß¬â1 ¬á¬â√∞R√±√≤3√≥ ¬Å )*+√∂# .
As with ordinary learning, it is likely there are more intelligent things to do with the training data
\
than minimizing (8). Denoting the set of all  P]^_ -samples by  Ss"  . c 2 5 , a general ‚Äúbias
learner‚Äù is a map V that takes  P]^_ -samples as input and produces hypothesis spaces SC A as
output: V $ c ÃÅŒº¬∂
¬üŒº¬∂ Ds" .c2 5 &'A  (9)
158


A MODEL OF INDUCTIVE BIAS LEARNING
(as stated, V is a deterministic bias learner, however it is trivial to extend our results to stochastic
learners). Note that in this paper we are concerned only with the sample complexity properties of a bias
learner V ; we do not discuss issues of the computability of V .
Since V is searching for entire hypothesis spaces within a family of such hypothesis spaces
A
, there is an extra representational question in our model of bias learning that is not present in
ordinary learning, and that is how the family A is represented and searched by V . We defer this
discussion until Section 2.5, after the main sample complexity results for this model of bias learning have been introduced. For the specific case of learning a set of features suitable for an environment of related learning problems, see Section 3. Regardless of how the learner chooses its hypothesis space , if we have a uniform bound (over
all aÃÉC A ) on the probability of large deviation between )W*`   and )*6[   , and we can compute
an upper bound on )W *a`   , then we can bound the bias learner‚Äôs ‚Äúgeneralization error‚Äù )*[   .
With this view, the question of generalization within our bias learning model becomes: how many
tasks (P ) and how many examples of each task (^ ) are required to ensure that )W*`   and )*[  
are close with high probability, uniformly over all C A ? Or, informally, how many tasks and how
many examples of each task are required to ensure that a hypothesis space with good solutions to all the training tasks will contain good solutions to novel tasks drawn from the same environment? It turns out that this kind of uniform convergence for bias learning is controlled by the ‚Äúsize‚Äù
of certain function classes derived from the hypothesis space family A , in much the same way as
the VC-dimension of a hypothesis space controls uniform convergence in the case of Boolean function learning (Theorem 1). These ‚Äúsize‚Äù measures and other auxiliary definitions needed to state the main theorem are introduced in the following subsection.
2.3 Covering Numbers
Definition1. Foranyhypothesis#%$ √∏&D" ,define#=b$ √π3"¬û&(√§¬£ ¬§6aÃä by
#b¬ô= $ U# 9R (10)
For any hypothesis space in the hypothesis space family A , define
b $B#=b$# CT j (11)
ForanysequenceofP hypotheses#  # c ,define#  # c b$ DT" c &(√§¬£ ¬§6aÃä by
# #Rcb   c c $ P¬§ ¬∑ Ãß√¨1c U# Ãß  Ãß Ãß (12)
We will also use d¬ôb to denote  #  #=c  b . For any in the hypothesis space family A , define
cb $B# # c b$ Ãà# # c CT j (13)
Define
A cb $ ¬Å ÃÅ√≥ ¬å cb  (14)
159


BAXTER
In the first part of the definition above, hypotheses #¬ü$  & " are turned into functions #b
mapping √∏YÃÅ"¬©&(√§ ¬£ ¬§6aÃä by composition with the loss function. b is then just the collection of all
such functions where the original hypotheses come from . b is often called a loss-function class.
In our case we are interested in the average loss across P tasks, where each of the P hypotheses
is chosen from a fixed hypothesis space . This motivates the definition of d¬ôb and cb . Finally,
A cb is the collection of all  #  # c  b , with the restriction that all #  # c belong to a single
hypothesis space C A .
Definition2. ForeachaÃÉC A ,defineTe $ Y &(√§¬£ ¬§6aÃä by
e  $ ¬á¬â√∞R√±
√≤3√≥¬Å )*+ #  (15)
For the hypothesis space family A , deAfinee $ B e $ C A j (16)
It is the ‚Äúsize‚Äù of A cb and A e that controls how large the  P]^_ -sample \ must be to ensure
)W*a`   and )*6[   are close uniformly over all √∫C A . Their size will be defined in terms of
certain covering numbers, and for this we need to define how to measure the distance between
elements of A cb and also between elements of A e .
Definition 3. Let n ¬©    c  be any sequence of P probability distributions on DT" . For
anyd¬ôb d yb C A cb ,define
flg dQb d yb $M¬´.¬¨¬Æ¬∞ ÃÑ 5¬â√ªoÃÉ√ºd¬ôb  cc;: d yb  cc√º
f    Ãàf c  c c  (17)
Similarly, for any distribution Z on Y and any e >e C A e , define
f[  e >e $ ¬´√Ø √º e ;: >e √º f Z   (18)
It is easily verified that fg and f [ are pseudo-metrics4 on A cb and A e respectively.
Definition4. An i -cover of  A e f [  is a set  Te  TyÃÅe  such that for all 3‚ÅÑ4eDC A e ,
f [  Te 3‚ÅÑ4 Ãße T¬ø√æi for some yÃà 2¬§; . Note that we do not require the T Ãße to be contained in
A e , just that they be measurable functions on Y . Let h Jij A e f [  denote the size of the smallest
such cover. Define the capacity of A e by
k JilA e $[¬è h JilA e f[  (19)
where the supremum is over all probability measures on Y . h Jij A cb f g  is defined in a similar
way, using fg in place of f [ . Define the capacity of A cb by:
k JijA cb $g¬è h JilA cb fg  (20)
where now the supremum is over all sequences of P probability measures on S3" .
4. Apseudo-metric IÃà isametricwithouttheconditionthatIÃà√´ OÃÇ¬∞OÃà √≠ROÃÄ  OÃÇ OÃÄ  .
160


A MODEL OF INDUCTIVE BIAS LEARNING
2.4 Uniform Convergence for Bias Learners
Now we have enough machinery to state the main theorem. In the theorem the hypothesis space family is required to be permissible. Permissibility is discussed in detail in Appendix D, but note that it is a weak measure-theoretic condition satisfied by almost all ‚Äúreal-world‚Äù hypothesis space
families. All logarithms are to base CÃß .
Theorem 2. Suppose  and " are separable metric spaces and let Z be any probability distri
bution on Y , the set of all distributions on  ¬ª" . Suppose \ is an  P]^_ -sample generated by
sampling P times from Y according to Z to give    c , and then sampling ^ times from each
  Ãß togenerate  Ãß    Ãß   Ãß   Ãß   Ãß  ,yÃà  ¬§3P . LetA    beanypermissible
hypothesis space family. If the number of tasks P satisfies
P ¬à  AÃÇi> AÃà¬é√Ük> A e
1‚ÅÑ4 iEÃÄ>  (21)
and the number of examples ^ of each task satisfies
^! ¬à ¬•EÃÅAÃÇ
Pi> AÃà¬é√Ü k > A cb
1‚ÅÑ4 "iEÃÄ>$# (22)
then with probability at least ¬§¬ü:1‚ÅÑ4 (over the  P]^_ -sample \ ), all C A will satisfy
)*[  %¬ø )W*a` 9K i (23)
Proof. See Appendix A.
There are several important points to note about Theorem 2:
1. Provided the capacities k Jij A e  and k Jij A cb  are finite, the theorem shows that any bias
learner that selects hypothesis spaces from A can bound its generalisation error )* [   in
terms of )W*a`   for sufficiently large  P]^_ -samples \ . Most bias learner‚Äôs will not find the
exact value of )W *a`   because it involves finding the smallest error of any hypothesis # Cs
on each of the P training sets in \ . But any upper bound on )W *`   (found, for example
by gradient descent on some error function) will still give an upper bound on )*O[   . See
Section 3.3.1 for a brief discussion on how this can be achieved in a feature learning setting.
2. In order to learn bias (in the sense that )*[   and )W*a`   are close uniformly over all
C A ), both the number of tasks P and the number of examples of each task ^ must
be sufficiently large. This is intuitively reasonable because the bias learner must see both sufficiently many tasks to be confident of the nature of the environment, and sufficiently many examples of each task to be confident of the nature of each task.
3. Once the learner has found an √∫C A with a small value of )W * `   , it can then use to
learn novel tasks  drawn according to Z . One then has the following theorem bounding the
sample complexity required for good generalisation when learning with (the proof is very
similar to the proof of the bound on ^ in Theorem 2).
161


BAXTER
Theorem3. Let √¢         beatrainingsetgeneratedbysamplingfrom
¬°" according to some distribution  . Let be a permissible hypothesis space. For all
il1‚ÅÑ4 with ¬£% ij1‚ÅÑ4&%M¬§ ,if the numberoftraining examples ^ satisfies
^! ¬à  iEÃÄ> AÃà¬é√Ü EÃÄk ')( b
1‚ÅÑ4 ¬§i >  (24)
then with probability at least ¬§%: 1‚ÅÑ4 , all # CT will satisfy
)*+ #%¬ø )W*X#¬ôK ij
The capacity k Jil  appearing in equation (24) is defined in an analogous fashion to the
capacities in Definition 4 (we just use the pseudo-metric f +  #b # yb  $+* ¬¨¬Æ¬∞ ÃÑ √º#b  ¬ô=¬Ç:
# yb  QR √º f   ¬ô= ). The important thing to note about Theorem 3 is that the number of ex
amples required for good generalisation when learning novel tasks is proportional to the logarithm of the capacity of the learnt hypothesis space . In contrast, if the learner does not
do any bias learning, it will have no reason to select one hypothesis space ¬°C A over any
other and consequently it would have to view as a candidate solution any hypothesis in any
of the hypothesis spaces C A . Thus, its sample complexity will be proportional to the
capacity of , ¬Å √≥ ¬å  b ¬Æ A b , which in general will be considerably larger than the capacity
of any individual aÃÉC A . So by learning the learner has learnt to learn in the environment
 Y Z  in the sense that it needs far smaller training sets to learn novel tasks.
4. Having learnt a hypothesis space with a small value of )W *a`   , Theorem 2 tells us that
with probability at least ¬§ :_1‚ÅÑ4 , the expectedvalue of ¬á¬â√∞=√± √≤√≥ ¬Å )*+  #  on a novel task  will be
less than )W *a`   K i . Of course, this does not rule out really bad performance on some tasks

. However, the probability of generating such ‚Äúbad‚Äù tasks can be bounded. In particular,
note that )*[   is just the expected value of the function e over Y , and so by Markov‚Äôs
inequality, for -/. ¬£ ,
0 * ¬•  $ ¬á√∞R√±
√≤3√≥¬Å )*+ #1 - #  0 * $ e  - 
¬ø32 [ e

 )*6[  

¬ø )W*` 9K√†i

(with probability ¬§%:1‚ÅÑ4 ).
5. Keeping the accuracy and confidence parameters ij1‚ÅÑ4 fixed, note that the number of examples
required of each task for good generalisation obeys
^  F AÃÉ P¬§ AÃà¬é√Ü k √¥ijA cb EÃÇ  (25)
So provided AÃà ¬é√Ü k Jil A cb  increases sublinearly with P , the upper bound on the number of
examples required of each task will decrease as the number of tasks increases. This shows that for suitably constructed hypothesis space families it is possible to share information between tasks. This is discussed further after Theorem 4 below.
162


A MODEL OF INDUCTIVE BIAS LEARNING
2.5 Choosing the Hypothesis Space Family A .
Theorem 2 only provides conditions under which )W * `   and )* [   are close, it does not guaran
tee that )*[   is actually small. This is governed by the choice of A . If A contains a hypothesis
space with a small value of )*[   and the learner is able to find an C A minimizing error on
the  P]^_ sample \ (i.e., minimizing )W*a`   ), then, for sufficiently large P and ^ , Theorem 2 en
sures that with high probability )*[   will be small. However, a bad choice of A will mean there
is no hope of finding an with small error. In this sense the choice of A represents the hyper-bias
of the learner.
Note that from a sample complexity point of view, the optimal hypothesis space family to choose is one containing a single, minimal hypothesis space that contains good solutions to all of the
problems in the environment (or at least a set of problems with high Z -probability), and no more.
For then there is no bias learning to do (because there is no choice to be made between hypothesis spaces), the output of the bias learning algorithm is guaranteed to be a good hypothesis space for the environment, and since the hypothesis space is minimal, learning any problem within the environment using will require the smallest possible number of examples. However, this scenario is analagous to the trivial scenario in ordinary learning in which the learning algorithm contains a single, optimal hypothesis for the problem being learnt. In that case there is no learning to be done, just as there is no bias learning to be done if the correct hypothesis space is already known.
At the other extreme, if A contains a single hypothesis space consisting of all possible func
tions from  & " then bias learning is impossible because the bias learner cannot produce a
restricted hypothesis space as output, and hence cannot produce a hypothesis space with improved sample complexity requirements on as yet unseen tasks.
Focussing on these two extremes highlights the minimal requirements on A for successful bias
learning to occur: the hypothesis spaces C A must be strictly smaller than the space of all
functions '&√ü" , but not so small or so ‚Äúskewed‚Äù that none of them contain good solutions to a
large majority of the problems in the environment.
It may seem that we have simply replaced the problem of selecting the right bias (i.e., selecting the right hypothesis space ) with the equally difficult problem of selecting the right hyper-bias (i.e.,
the right hypothesis space family A ). However, in many cases selecting the right hyper-bias is far
easier than selecting the right bias. For example, in Section 3 we will see how the feature selection problem may be viewed as a bias selection problem. Selecting the right features can be extremely difficult if one knows little about the environment, with intelligent trial-and-error typically the best one can do. However, in a bias learning scenario, one only has to specify that a set of features should exist, find a loosely parameterised set of features (for example neural networks), and then learn the features by sampling from multiple related tasks.
2.6 Learning Multiple Tasks
It may be that the learner is not interested in learning to learn, but just wants to learn a fixed set
of P tasks from the environment  Y Z  . As in the previous section, we assume the learner starts
out with a hypothesis space family A , and also that it receives an  P]^_ -sample \ generated from
the P distributions    c . This time, however, the learner is simply looking for P hypotheses
 #  #Rc  , all contained in the same hypothesis space , such that the average generalization
error of the P hypothesesis minimal. Denoting  #  #=c  by d and writing n      c  ,
163


BAXTER
this error is given by:
)*g d  $ P¬§ ¬∑ Ãß√¨1c )*+√∂#  Ãß (26)
 P¬§ ¬∑ Ãß√¨1c ¬´¬¨EÃÅ¬∞ ÃÑ U# Ãß¬±=f  Ãß¬ô=
and the empirical loss of d on \ is
)W*a`d  $ P¬§ ¬∑ Ãß¬â1c )W*X?√∂#  Ãß (27)
 P¬§ ¬∑ Ãß¬â1c ^¬§ 4¬∑1 U# Ãß Ãß4 Ãß4
As before, regardless of how the learner chooses  #  #=c  , if we can prove a uniform bound on
the probability of large deviation between )W* `  d  and )* g  d  then any  #  # c  that perform
well on the training sets \ will with high probability perform well on future examples of the same
tasks.
Theorem4. Letn ¬©    c  beP probabilitydistributionson¬ù¬ç" andlet\ bean  P]^_ 
sample generated by sampling ^ times from oa" according to each   Ãß . Let A    be any
permissible hypothesis space family. If the number of examples ^ of each task satisfies
^! ¬à ¬•5PiEÃÄ> AÃà¬é√Ü EÃÄk)( A cb
1‚ÅÑ4 ¬§i > # (28)
then with probability at least ¬§¬ü:1‚ÅÑ4 (over the choice of \ ), any d C A c will satisfy
)*g d %¬ø )W*a`d  K i (29)
(recall Definition 4 for the meaning of k Jil A cb  ).
Proof. Omitted (follow the proof of the bound on ^ in Theorem 2).
The bound on ^ in Theorem 4 is virtually identical to the bound on ^ in Theorem 2, and note
again that it depends inversely on the number of tasks P (assuming that the first part of the ‚Äúmax‚Äù
expression is the dominate one). Whether this helps depends on the rate of growth of k  )( A cb  as
a function of P . The following Lemma shows that this growth is always small enough to ensure that
we never do worse by learning multiple tasks (at least in terms of the upper bound on the number of examples required per task).
Lemma 5. For any hypothesis space family A ,
k ilA b ¬ø k HilA cb¬Ü¬ø k ilA bc  (30)
164


A MODEL OF INDUCTIVE BIAS LEARNING
Proof. Let 6 denote the set of all functions  #  #Rc  b where each #  Ãß can be a member of any
hypothesis space !C A (recall Definition 1). Then A cb87 6 and so k Hij A cb  ¬ø k Jij 6  . By
Lemma 29 in Appendix B, k Hij 6 ¬Ü¬ø k  il A b  c and so the right hand inequality follows.
For the first inequality, let  be any probability measure on √ü " and let n be the mea
sure on  !<"  c obtained by using  on the first copy of  <" in the product, and ignoring
all other elements of the product. Let be an i -cover for  A cb flg  . Pick any #b C A b and
let :9 ;9 c b C besuchthatfg # # # b:9 ;9 c b¬ø i . Butbyconstruction,
flg # # 3 # b:9 ;9 c b¬î f + # :9 b,whichestablishesthefirstinequality.
ByLemma5 AÃà¬é√Ü k ijA b ¬ø AÃà¬é√Ü k JijA cb ¬Ü¬ø√†P AÃà¬é√Ü k ijA b  (31)
So keeping the accuracy parameters i and 1‚ÅÑ4 fixed, and plugging (31) into (28), we see that the upper
bound on the number of examples required of each task never increases with the number of tasks,
and at best decreases as F √ó¬§NPQ . Although only an upper bound, this provides a strong hint that
learning multiple related tasks should be advantageous on a ‚Äúnumber of examples required per task‚Äù basis. In Section 3 it will be shown that for feature learning all types of behavior are possible, from
no advantage at all to F √ó¬§NPQ decrease.
2.7 Dependence on i
In Theorems 2, 3 and 4 the bounds on sample complexity all scale as ¬§N¬òi > . This behavior can be
improved to ¬§N¬òi if the empirical loss is always guaranteed to be zero (i.e., we are in the realizable
case). The same behavior results if we are interested in relative deviation between empirical and true loss, rather than absolute deviation. Formal theorems along these lines are stated in Appendix A.3.
3. Feature Learning
The use of restricted feature sets is nearly ubiquitous as a method of encoding bias in many areas of machine learning and statistics, including classification, regression and density estimation. In this section we show how the problem of choosing a set of features for an environment of
related tasks can be recast as a bias learning problem. Explicit bounds on k  A e ai3 and k  A cb ai3
are calculated for general feature classes in Section 3.2. These bounds are applied to the problem of learning a neural network feature set in Section 3.3.
3.1 The Feature Learning Model
Consider the following quote from Vapnik (1996):
The classical approach to estimating multidimensional functional dependencies is based on the following belief:
Real-life problems are such that there exists a small number of ‚Äústrong features,‚Äù simple functions of which (say linear combinations) approximate well the unknown function. Therefore, it is necessary to carefully choose a low-dimensional feature space and then to use regular statistical techniques to construct an approximation.
165


BAXTER
In general a set of ‚Äústrong features‚Äù may be viewed as a function q $ √∏&+< mapping the input
space  into some (typically lower) dimensional space < . Let o √æ q  be a set of such feature
maps (each q may be viewed as a set of features  q  q>=  if <  ¬í = ). It is the q that must be
‚Äúcarefully chosen‚Äù in the above quote. In general, the ‚Äúsimple functions of the features‚Äù may be
represented as a class of functions p mapping < to " . If for each q C_o we define the hypothesis
space pTr q $B?9 r q $ 9 C p  , thenwehavethehypothesisspacefamily A
A $¬ûpsr q $ q C3‚ÅÑ4o j (32)
Now the problem of ‚Äúcarefully choosing‚Äù the right features q is equivalent to the bias learning
problem ‚Äúfind the right hypothesis space C A ‚Äù. Hence, provided the learner is embedded within
an environment of related tasks, and the capacities k  A e ai¬ò and k  A cb ai¬ò are finite, Theorem 2 tells
us that the feature set q can be learnt rather than carefully chosen. This represents an important
simplification, as choosing a set of features is often the most difficult part of any machine learning problem.
In Section 3.2 we give a theorem bounding k  A e ai¬ò and k  A cb ai3 for general feature classes.
The theorem is specialized to neural network classes in Section 3.3.
Note that we have forced the function class p to be the same for all feature maps q , although
this is not necessary. Indeed variants of the results to follow can be obtained if p is allowed to vary
with q .
3.2 Capacity Bounds for General Feature Classes
Notationally it is easier to view the feature maps q as mapping from √πs" to <√°s" by  ¬ô=A@&
 q  ¬±= , and also to absorb the loss function U into the definition of p by viewing each 9 C p as a
mapfrom<√¢ " into √§¬£ ¬§6aÃä via CB ÃàRA&@ U :9¬±CB= . Previouslythislatterfunctionwouldhavebeen
denoted 9 b but in what follows we will drop the subscript U where this does not cause confusion. The
class to which 9 b belongs will still be denoted by p b .
With the above definitionslet p b r o $¬¶?9 r q $ 9 C p b q Cao  . Define the capacityof p b in
theusualway, k Jilp b $DE+ ¬è h Jilp b f + 
wherethesupremumisoverallprobabilitymeasureson<√°3" ,andf + :9;9 y $ *GF ¬∞ ÃÑ √º9zCB ÃàR¬î:
9 y CB= √º f  CB= . To define the capacity of o we first define a pseudo-metric f t+ 2uvxw on o by
‚Äúpulling back‚Äù the H metric on ¬í through p b as follows:
ft+2uvwq qy $ ¬´¬∞¬¨EÃÅ¬∞ ÃÑ ¬è
I√≥uv√º9 r q ¬ô=;:/9 r q yQR√ºf ¬ô= (33)
It is easily verified that f=t+ 2uvxw is a pseudo-metric. Note that for ft+ 2uv w to be well defined the supre
mum over p b in the integrand must be measurable. This is guaranteed if the hypothesis space family
A   p b r q $ q C o  is permissible (Lemma 32, part 4). Now defineh Jil o f t+ 2uv{w8 to be the
smallest i -cover of the pseudo-metric space  o f t+ 2u v w  and the i -capacity of o (with respect to p b )
as kuvJilo  $D+¬è h Jilo ft+2uv{w
where the supremum is over all probability measures on -oÃÉ" . Now we can state the main theorem
of this section.
166


A MODEL OF INDUCTIVE BIAS LEARNING
Theorem 6. Let A be a hypothesis space family as in equation (32). Then for all ijai ai > . ¬£ with
i¬Æ¬öi K i>, k JilA cb¬Ü¬ø k Hi p bc k uv Ji> o  (34)
k JijA e¬Ü¬ø k uv Hilo  (35)
Proof. See Appendix B.
3.3 Learning Neural Network Features
In general, a set of features may be viewed as a map from the (typically high-dimensional) input
space ¬í ¬¢ to a much smaller dimensional space ¬í = (JLK f ). In this section we consider approximat
ing such a feature map by a one-hidden-layer neural network with f input nodes and J output nodes
(Figure1). WedenotethesetofallsuchfeaturemapsbyM | ¬©ON | 2 N | 2=  $QP CR  where
R
is a bounded subset of ¬íTS (U is the number of weights (parameters) in the first two layers).
This set is the o of the previous section.
EachfeatureN | 2 Ãß $ ¬í ¬¢ & √§¬£ ¬§6aÃä,yÃà ¬©¬§3 J isdefinedby
N| 2 Ãß9 $VWX 4¬∑1b B Ãß4#4¬±¬ôKYB Ãßb¬ì Z[ (36)
where # 4  ¬± is the output of the \^] # node in the first hidden layer, CB  Ãß _B  Ãß b¬ì  are the output
node parameters for the yÃà th feature and V is a ‚Äúsigmoid‚Äù squashing function V $ ¬í√°& √§ ¬£ ¬§6aÃä . Each
firstlayerhiddennode#  Ãß $ ¬í ¬¢ &S¬í , yÃà ¬û¬§3 U,computes
# Ãß9 $V WX 4¬∑1¬¢a` Ãß44 K ` Ãß¬¢¬ì Z[ (37)
where  `  Ãß  `  Ãß ¬¢¬ì  are the hidden node‚Äôs parameters. We assume V is Lipschitz.5 The weight
vector for the entire feature map is thus
P ¬©`` ¬¢¬ì `b `b¬¢¬ì _B_B b¬ì _B= _B=b¬ì 
andthetotalnumberoffeatureparameters U  U  f K¬ö¬§ K J  U K ¬§ .
For argument‚Äôs sake, assume the ‚Äúsimple functions‚Äù of the features (the class p of the previous
section) are squashed affine maps using the same sigmoid function V above (in keeping with the
‚Äúneural network‚Äù flavor of the features). Thus, each setting of the feature weights P generates a
hypothesis space:
YÃÅ| $  Vcb¬∑ Ãß¬â1=ed  ÃßN| 2 ÃßK d =¬ì f $ d  d =¬ì  C R y (38)
where R y is a bounded subset of ¬í = ¬ì . The set of all such hypothesis spaces,
A $B | $QP CR  (39)
5.√® isLipschitzifthereexistsaconstantg suchthath√® Ãà√´OÃÇ √≠ji¬ç√®√´OÃÇ>k√≠;h?lmgnhOÃÇ i OÃÇ>khforallOÃÇ¬∞OÃàHOÃÇkporq .
167


BAXTER
k
n
l
d
Feature
Map
Input
Multiple Output Classes
Figure 1: Neural network for feature learning. The feature map is implemented by the first two
hidden layers. The P output nodes correspond to the P different tasks in the  P]^_ 
sample \ . Each node in the network computes a squashed linear function of the nodes in
the previous layer.
is a hypothesis space family. The restrictions on the output layer weights  d  d = ¬ì  and feature
weights P , and the restriction to a Lipschitz squashing function are needed to obtain finite upper
bounds on the covering numbers in Theorem 2.
Finding a good set of features for the environment  Y Z  is equivalent to finding a good hy
pothesis space | C A , which in turn means finding a good set of feature map parameters P .
As in Theorem 2, the correct set of features may be learnt by finding a hypothesis space with
small error on a sufficiently large  P]^_ -sample \ . Specializing to squared loss, in the present
framework the empirical loss of | on \ (equation (8)) is given by
)W*` | AÃä P¬§ ¬∑ Ãß¬â1c ¬á√∞R√±
.tsu62sOÃÉ2wvwvwv2s^x65√≥>yk^¬§ 4¬∑1{zVYb¬∑b1= dbN|2b Ãß49K d¬∂f :< Ãß4}|> (40)
Since our sigmoid function V only has range √§ ¬£ ¬§6aÃä , we also restrict the outputs " to this range.
3.3.1 ALGORITHMS FOR FINDING A GOOD SET OF FEATURES
Provided the squashing function V is differentiable, gradient descent (with a small variation on
backpropagation to compute the derivatives) can be used to find feature weights P minimizing (40)
(or at least a local minimum of (40)). The only extra difficulty over and above ordinary gradient
descent is the appearance of ‚Äú¬á¬â√∞R√± ‚Äù in the definition of )W * `  YÃÅ|  . The solution is to perform gradient
descent over both the output parameters  d ¬∂  d =  for each node and the feature weights P . For
more details see Baxter (1995b) and Baxter (1995a, chapter 4), where empirical results supporting the theoretical results presented here are also given.
168


A MODEL OF INDUCTIVE BIAS LEARNING
3.3.2 SAMPLE COMPLEXITY BOUNDS FOR NEURAL-NETWORK FEATURE LEARNING
The size of \ ensuring that the resulting features will be good for learning novel tasks from the same
environment is given by Theorem 2. All we have to do is compute the logarithm of the covering
numbersk Jij A cb  andk Jij A e .
Theorem 7. Let A 3~ YÃÅ| $aP C ¬í S5 be a hypothesis space family where each }| is of the form
YÃÅ| $  V b¬∑ Ãß¬â1=¬Äd ÃßN|2 Ãß¬ñ¬ôK d¬∂f $d  d= C ¬í =
where M |  ON | 2  N | 2=  isaneural networkwith U weightsmapping from ¬í ¬¢ to ¬í = . Ifthe
feature weights P and the output weights d ¬∂3 d  d = are bounded, the squashing function V is
Lipschitz, U is squared loss, and the output space "  √§ ¬£ ¬§6aÃä (any bounded subset of ¬í will do), then
there exist constants ¬Å ¬Å=y (independent of il U and J ) such that for all i . ¬£ ,
AÃà¬é√Ü k JijA cb ¬ø AÃÇ J K¬ö¬§IÃÅP}K U AÃà¬é√Ü ¬Åi (41)
AÃà¬é√Ü k JijA e ¬ø AÃÇU AÃà¬é√Ü ¬ÅiRy (42)
(recall that we have specialized to squared loss here).
Proof. See Appendix B.
Noting that our neural network hypothesis space family A is permissible, plugging (41) and (42)
into Theorem 2 gives the following theorem.
Theorem 8. Let A   |  be a hypothesis space family where each hypothesis space | is a
set of squashed linear maps composed with a neural network feature map, as above. Suppose the
number of features is J , and the total number of feature weights is W. Assume all feature weights and
output weights are bounded, and the squashing function V is Lipschitz. Let \ be an  P]^_ -sample
generated from the environment  Y Z  . If
P F AÃÉ i¬§> AÃÄU AÃà¬é√Ü i¬§ K AÃà¬é√Ü 1‚ÅÑ4¬§=EÃàREÃÇ (43)
and
^! F AÃÉ i¬§> AÃÄAÃÉ J K¬ö¬§ K UP EÃÇ AÃà¬é√Ü i¬§ K P¬§ AÃà¬é√Ü 1‚ÅÑ4¬§EÃàREÃÇ (44)
then with probability at least ¬§¬ü:1‚ÅÑ4 any | C A will satisfy
)*[ }| ¬Ü¬ø )W*`}| 9K il (45)
169


BAXTER
3.3.3 DISCUSSION
1. Keeping the accuracy and confidence parameters i and 1‚ÅÑ4 fixed, the upper bound on the number
of examples required of each task behaves like F  J K U NPQ . If the learner is simply learning
P
fixed tasks (rather than learning to learn), then the same upper bound also applies (recall Theorem 4).
2. Note that if we do away with the feature map altogether then U ¬ö¬£ and the upper bound on
^
becomes F  J  , independent of P (apart from the less important 1‚ÅÑ4 term). So in terms of the
upper bound, learning P tasks becomes just as hard as learning one task. At the other extreme,
if we fix the output weights then effectively J ¬¶¬£ and the number of examples required of
each task decreases as F  U NPQ . Thus a range of behavior in the number of examples required
of each task is possible: from no improvement at all to an F √ó¬§NPQ decrease as the number of
tasks P increases (recall the discussion at the end of Section 2.6).
3. Once the feature map is learnt (which can be achieved using the techniques outlined in Baxter, 1995b; Baxter & Bartlett, 1998; Baxter, 1995a, chapter 4), only the output weights have to be estimated to learn a novel task. Again keeping the accuracy parameters fixed, this requires no
more that F  J  examples. Thus, as the number of tasks learnt increases, the upper bound on
the number of examples required of each task decays to the minimum possible, F  J  .
4. If the ‚Äúsmall number of strong features‚Äù assumption is correct, then J will be small. However,
typically we will have very little idea of what the features are, so to be confident that the neural network is capable of implementing a good feature set it will need to be very large, implying
U¬É¬Ç¬ÑJ . F  J K U NPQ decreasesmostrapidlywithincreasingP when U¬É¬Ç¬ÑJ ,soatleastin
terms of the upper bound on the number of examples required per task, learning small feature sets is an ideal application for bias learning. However, the upper bound on the number of
tasks does not fare so well as it scales as F  U  .
3.3.4 COMPARISON WITH TRADITIONAL MULTIPLE-CLASS CLASSIFICATION
A special case of this multi-task framework is one in which the marginal distribution on the input
space   Ãß ~¬¨ is the same for each task yÃà ¬û¬§3P , and all that varies between tasks is the conditional
distribution over the output space " . An example would be a multi-class problem such as face
recognition, in which " Sl¬§3P; where P is the number of faces to be recognized and the
marginal distribution on  is simply the ‚Äúnatural‚Äù distribution over images of those faces. In that
case, if for every example   Ãß 4 we have‚Äîin addition to the sample   Ãß 4 from the yÃà th task‚Äôs conditional
distribution on " ‚Äîsamples from the remaining P: ¬§ conditional distributions on " , then we can
view the P training sets containing ^ examples each as one large training set for the multi-class
problem with ^TP examples altogether. The bound on ^ in Theorem 8 states that ^TP should be
F  P J K U  , or proportional to the total number of parameters in the network, a result we would
expect from6 (Haussler, 1992). So when specialized to the traditional multiple-class, single task framework, Theorem 8 is consistent with the bounds already known. However, as we have already argued, problems such as face recognition are not really single-task, multiple-class problems. They are more appropriately viewed
6. If each example can be classified with a ‚Äúlarge margin‚Äù then naive parameter counting can be improved upon (Bartlett, 1998).
170


A MODEL OF INDUCTIVE BIAS LEARNING
as a (potentially infinite) collection of distinct binary classification problems. In that case, the goal
of bias learning is not to find a single P -output network that can classify some subset of P faces
well. It is to learn a set of features that can reliably be used as a fixed preprocessing for distinguishing any single face from other faces. This is the new thing provided by Theorem 8: it tells us that
provided we have trained our P -output neural network on sufficiently many examples of sufficiently
many tasks, we can be confident that the common feature map learnt for those P tasks will be good
for learning any new, as yet unseen task, provided the new task is drawn from the same distribution
that generated the training tasks. In addition, learning the new task only requires estimating the J
output node parameters for that task, a vastly easier problem than estimating the parameters of the entire network, from both a sample and computational complexity perspective. Also, since we have high confidence that the learnt features will be good for learning novel tasks drawn from the same environment, those features are themselves a candidate for further study to learn more about the nature of the environment. The same claim could not be made if the features had been learnt on too small a set of tasks to guarantee generalization to novel tasks, for then it is likely that the features would implement idiosyncrasies specific to those tasks, rather than ‚Äúinvariances‚Äù that apply across all tasks.
When viewed from a bias (or feature) learning perspective, rather than a traditional P -class
classification perspective, the bound ^ on the number of examples required of each task takes on
a somewhat different meaning. It tells us that provided P is large (i.e., we are collecting examples
of a large number tasks), then we really only need to collect a few more examples than we would
otherwise have to collect if the feature map was already known (J K U NP examples vs. J examples).
So it tells us that the burden imposed by feature learning can be made negligibly small, at least when viewed from the perspective of the sampling burden required of each task.
3.4 Learning Multiple Tasks with Boolean Feature Maps
Ignoring the accuracy and confidence parameters i and 1‚ÅÑ4 , Theorem 8 shows that the number of
examples required of each task when learning P tasks with a common neural-network feature map
is bounded above by F  J K U NPQ , where J is the number of features and U is the number of
adjustable parameters in the feature map. Since F  J  examples are required to learn a single task
once the true features are known, this shows that the upper bound on the number of examples
required of each task decays (in order) to the minimum possible as the number of tasks P increases.
This suggests that learning multiple tasks is advantageous, but to be truly convincing we need to
prove a lower bound of the same form. Proving lower bounds in a real-valued setting ("  ¬í )
is complicated by the fact that a single example can convey an infinite amount of information, so
one typically has to make extra assumptions, such as that the targets  C " are corrupted by a
noise process. Rather than concern ourselves with such complications, in this section we restrict
our attention to Boolean hypothesis space families (meaning each hypothesis # C A maps to
"  ¬Ö ¬§¬ò andwemeasureerrorbydiscretelossU# 9R¬Æ√æ¬§ if# ¬±}¬ß- andU# 9RoÃÉ¬¶¬£
otherwise).
We show that the sample complexity for learning P tasks with a Boolean hypothesis space family
A
is controlled by a ‚ÄúVC dimension‚Äù type parameter f=¬å  PQ (that is, we give nearly matching upper
and lower bounds involving f ¬å  PQ ). We then derive bounds on f ¬å  PQ for the hypothesis space
family considered in the previous section with the Lipschitz sigmoid function V replaced by a hard
threshold (linear threshold networks).
171


BAXTER
As well as the bound on the number of examples required per task for good generalization across
those tasks, Theorem 8 also shows that features performing well on F  U  tasks will generalize well
to novel tasks, where U is the number of parameters in the feature map. Given that for many feature
learning problems U is likely to be quite large (recall Note 4 in Section 3.3.3), it would be useful
to know that F  U  tasks are in fact necessary without further restrictions on the environmental
distributions Z generating the tasks. Unfortunately, we have not yet been able to show such a lower
bound. There is some empirical evidence suggesting that in practice the upper bound on the number of tasks may be very weak. For example, in Baxter and Bartlett (1998) we reported experiments in which a set of neural network features learnt on a subset of only 400 Japanese characters turned out to be good enough for classifying some 2600 unseen characters, even though the features contained several hundred thousand parameters. Similar results may be found in Intrator and Edelman (1996) and in the experiments reported in Thrun (1996) and Thrun and Pratt (1997, chapter 8). While this gap between experiment and theory may be just another example of the looseness inherent in general bounds, it may also be that the analysis can be tightened. In particular, the bound on the
number of tasks is insensitive to the size of the class of output functions (the class p in Section 3.1),
which may be where the looseness has arisen.
3.4.1 UPPER AND LOWER BOUNDS FOR LEARNING ¬Ü TASKS WITH BOOLEAN HYPOTHESIS
SPACE FAMILIES
First we recall some concepts from the theory of Boolean function learning. Let be a class of
Booleanfunctionson andT¬©     C   . ~0 isthesetofallbinaryvectorsobtainable
byapplyingfunctionsin to ~:0 $B#   #    $ Ãà# CT j
Clearly √º ~0 √º ¬ø AÃÇ  . If √º ~0 √º  AÃÇ  we say shatters  . The growth function of is defined by
¬Ä ¬Å ^_ $ ¬àL
0√≥¬¨¬à¬á/¬â¬â ~0¬â¬â
The Vapnik-Chervonenkis dimension ¬É¬Ç¬Ñ¬Ü¬Ö¬á¬â¬à   is the size of the largest set shattered by :
¬É¬Ç¬Ñ¬Ü¬Ö=¬á¬â¬à   $ ¬à^ $¬Ä¬Ç¬Å ^_¬î AÃÇ j
An important result in the theory of learning Boolean functions is Sauer‚Äôs Lemma (Sauer, 1972), of which we will also make use.
Lemma 9 (Sauer‚Äôs Lemma). For a Boolean function class with ¬É¬Ç¬Ñ¬Ü¬Ö¬á¬â¬à  AÃä f ,
¬Ä ¬Å ^_¬Ü¬ø ¬∑ Ãß¬â1¬¢¬∂ AÃÉ^yÃàEÃÇ ¬ø¬ã¬äCÃßf^¬å¬¢
for all positive integers ^ .
We now generalize these concepts to learning P tasks with a Boolean hypothesis space family.
172


A MODEL OF INDUCTIVE BIAS LEARNING
Definition 5. Let A be a Boolean hypothesis space family. Denote the P ^ matrices over the
input space  by  . c 2 5 . For each ¬ã C  . c 2 5 and ¬°C A , define ~¬ä to be the set of (binary)
matrices, _~¬ä $ ¬è¬ç¬é¬é¬ê ¬ë¬í¬ì #   ¬ñ¬ñ¬ñ #  √¥ 
... . . . ...
#=cc  ¬ñ¬ñ¬ñ #Rcc ¬î¬ñt¬ï $z#  #c CT¬ò¬ó¬ö¬é¬ô¬é 
Define A ~¬ä}$ ¬Å ÃÅ√≥ ¬å ~¬ä 
NowforeachP . ¬£^ . ¬£ ,define¬Ä ¬å P]^_ by
¬Ä¬ç¬å P]^_ $ ¬àL
¬ä√≥¬¨¬ú¬õ√ª¬û¬ù¬á¬ü¬â¬âA ~¬ä¬â¬â
Notethat¬Ä ¬å P]^_%¬ø AÃÇ c  .If ¬â¬âA ~¬ä ¬â¬â  AÃÇ c  wesayA shattersthematrix¬ã .ForeachP . ¬£ let
f¬å PQ $ ¬à^ $¬Ä ¬å P]^_¬î AÃÇc j
Define f A  $  ¬É¬Ç¬Ñ¬Ü¬Ö=¬á¬à A  and
fA  $ ¬à
¬Å √≥¬å ¬É¬Ç¬Ñ¬Ü¬Ö=¬á¬â¬à  
Lemma10. f  A  f  A 
f¬å PQ ¬à ¬•¬¢¬°fA 
P ¬£ fA # AÃÇ¬§ AÃÉ ¬°fA 
P ¬£K fAEÃÇ
Proof. The first inequality is trivial from the definitions. To get the second term in the maximum
in the second inequality, choose an C A with ¬É¬Ç¬Ñ¬Ü¬Ö=¬á¬â¬à  a f  A  and construct a matrix
¬ã C  . c 2 5 whose rows are of length f  A  and are shattered by . Then clearly A shatters ¬ã . For
the firstterm inthe maximum take asequence T¬©   ¬¢ . ¬å 5  shattered by A (the hypothesis
space consisting of the union over all hypothesis spaces from A ), and distribute its elements equally
among the rows of ¬ã (throw away any leftovers). The set of matrices
¬è¬ç¬é¬é¬ê ¬ë¬í¬ì #O ¬ñ¬ñ¬ñ #√¥¬Æ
... . . . ...
#c  ¬ñ¬ñ¬ñ #c ¬§¬î¬ñt¬ï $# C A ¬ó¬ö¬é¬ô¬é 
where^ ¬¶¬•f  A NP ¬ß isasubsetofA ~¬ä andhassizeAÃÇ c  .
Lemma11. ¬Ä¬ç¬å P]^_¬Ü¬ø AÃÄ CÃß ^
f=¬å PQEÃàc¬¢? Ãà.c5
173


BAXTER
Proof. Observe that for each P , ¬Ä¬ç¬å  P]^_  ¬Ä ¬Å  P9^_ where is the collection of all Boolean
functions on sequences   c  obtained by first choosing P functions #  #Rc from some
C A , and then applying # to the first ^ examples, # > to the second ^ examples and so on. By
thedefinition of f ¬å  PQ , ¬É¬Ç¬Ñ¬Ü¬Ö=¬á¬â¬à  AÃä P f ¬å  PQ ,hencetheresult follows fromLemma9appliedto
.
If one follows the proof of Theorem 4 (in particular the proof of Theorem 18 in Appendix
A) then it is clear that for all ¬© . ¬£ , k  A cb ai3 may be replaced by ¬Ä¬ç¬å  P] AÃÇ ^_ in the Boolean
case. Making this replacement in Theorem 18, and using the choices of d Ea from the discussion
following Theorem 26, we obtain the following bound on the probability of large deviation between empirical and true performance in this Boolean setting.
Theorem12. Let n      c  be P probability distributions on o ¬Ö ¬§¬ò and let \ be an
 P]^_ -samplegeneratedbysampling^ timesfrom¬ù ¬Ö ¬§¬ò accordingtoeach   Ãß . Let A B 
be any permissible Boolean hypothesis space family. For all ¬£% ¬© ¬ø ¬§ ,
0 * \ $¬¨¬´=d C A c $ )*g d  )W*a`d  K ij¬ø EÃÄ¬Ä¬ç¬å P]AÃÇ^_)¬è √ó: ¬©>P9^_NEÃÄ (46)
Corollary 13. Under the conditions of Theorem 12, if the number of examples ^ of each task
satisfies
^! i> AÃÄAÃÇf ¬å PQAÃà¬é√Ü AÃÇiAÃÇ K P¬§ AÃà¬é√Ü EÃÄ1‚ÅÑ4EÃà (47)
then with probability at least ¬§¬ü:1‚ÅÑ4 (over the choice of \ ), any d C A c will satisfy
)*g d %¬ø )W*a`d  K i (48)
Proof. Applying Theorem 12, we require
EÃÄ¬Ä ¬å P]AÃÇ^_)¬è √ó: ¬©>P9^_NEÃÄ¬ü¬ø 1‚ÅÑ4
which is satisfied if
^! ¬©EÃÄ> AÃÄf¬å PQAÃà¬é√ÜaÃÉAÃÇCÃß^
f ¬å PQ K P¬§ AÃà¬é√Ü EÃÄ1‚ÅÑ4 EÃà (49)
where we have used Lemma 11. Now, for all ImM¬§ , if
^  AÃÉ ¬§ K CÃß¬§EÃÇ I AÃà¬é√Ü AÃÉ ¬§AÃäK CÃß¬§EÃÇ I
then^!1‚ÅÑ2I AÃà¬é√Ü ^ .SosettingIL  EÃÄ f ¬å PQN¬òi > ,(49)issatisfiedif
^! i> AÃÄAÃÇf¬å PQAÃà¬é√Ü AÃÇiAÃÇ K P¬§ AÃà¬é√Ü EÃÄ1‚ÅÑ4EÃà 
174


A MODEL OF INDUCTIVE BIAS LEARNING
Corollary 13 shows that any algorithm learning P tasks using the hypothesis space family A
requires no more than
^  F AÃÉ i¬§> AÃÄf=¬å PQAÃà¬é√Ü i¬§ K P¬§ AÃà¬é√Ü 1‚ÅÑ4¬§EÃàREÃÇ (50)
examples of each task to ensure that with high probability the average true error of any P hypotheses
it selects from A c is within i of their average empirical error on the sample \ . We now give a
theorem showing that if the learning algorithm is required to produce P hypotheses whose average
true error is within i of the best possible error (achievable using A c ) for an arbitrary sequence of
distributions    c , then within a AÃà ¬é√Ü  factor the number of examples in equation (50) is also
necessary.
For any sequence n      c  of P probability distributions on  ¬Ö ¬§¬ò , define
¬é¬è=¬êg A c by ¬é¬è¬êg A c $ ¬á¬â√∞R√±
√≥¬å √ª )*g d 
Theorem 14. Let A be a Boolean hypothesis space family such that A contains at least two
functions. For each P3¬û¬§3 AÃÇ ¬ò let V c be any learning algorithm taking as input  P]^_ -samples
\ C ( ¬Ö ¬§¬ò¬ò .c 2 5 andproducingasoutputP hypotheses d S#  #=c  C A c . Forall
¬£%1‚ÅÑ2i%M¬§NEÃÄ and¬£% 1‚ÅÑ4¬§%M¬§NEÃÄ,if
^!% i¬§> AÃÄf¬å PQ
¬§ KM√ó¬§¬ü:¬ªi>P¬§ AÃà¬é√Ü AÃÉ ¬§
1‚ÅÑ4¬∞√ó¬§ : AÃÇ1‚ÅÑ43EÃÇ¬üEÃà
then there exist distributions n      c  such that with probability at least 1‚ÅÑ4 (over the
randomchoiceof\ ), )*g V c J\¬∞ . ¬é¬è=¬êg A c  K i
Proof. See Appendix C
3.4.2 LINEAR THRESHOLD NETWORKS
Theorems 13 and 14 show that within constants and a AÃà ¬é√Ü √ó¬§N¬òi3 factor, the sample complexity of
learning P tasks using the Boolean hypothesis space family A is controlled by the complexity pa
rameter f ¬å  PQ . In this section we derive bounds on f ¬å  PQ for hypothesis space families constructed
as thresholded linear combinations of Boolean feature maps. Specifically, we assume A is of the
form given by (39), (38), (37) and (36), where now the squashing function V is replaced with a hard
threshold: V¬î¬± $  ¬§ if¬Æ ¬£R
:EÃÅ¬§ otherwise
and we don‚Äôt restrict the range of the feature and output layer weights. Note that in this case the
proof of Theorem 8 does not carry through because the constants ¬Å ¬ÅRy in Theorem 7 depend on the
Lipschitz bound on V .
Theorem 15. Let A be a hypothesis space family of the form given in (39), (38), (37) and (36), with
a hard threshold sigmoid function V . Recall that the parameters f , U and J are the input dimension,
number of hidden nodes in the feature map and number of features (output nodes in the feature map)
175


BAXTER
respectively. Let U $  U  f K√¢¬§]K J  U K√¢¬§ (the number of adjustable parameters in the feature
map).Then, f ¬å PQ ¬ø AÃÇ AÃÉ UP K J K¬ö¬§EÃÇ AÃà¬é√Ü > AÃÇCÃß J K U K¬ö¬§z
Proof. Recall that for each P C ¬íTS , M | $ ¬í ¬¢ &(¬í = denotes the feature map with parameters P .
Foreach ¬ã C  .c 2 5 ,let M | ~¬ä denotethematrix
¬ë¬í¬ì M | ¬ô6 ¬ñ¬ñ¬ñ M | ¬ô√¥oÃÉ
... . . . ...
M | c  ¬ñ¬ñ¬ñ M | c ¬î¬ñt¬ï
Note that A ~ ¬ä is the set of all binary P ^ matrices obtainable by composing thresholded linear
functions with the elements of M | ~ ¬ä , with the restriction that the same function must be applied to
each element in a row (but the functions may differ between rows). With a slight abuse of notation,
define ¬Ä¬∞ ÃÑ P]^_ $ ¬à
¬ä√≥¬¨ ¬õ√ª¬û¬ù¬á¬ü¬â¬â~M|~¬ä$aP C ¬íS ¬â¬â
Fix ¬ã C  . c 2  5 . By Sauer‚Äôs Lemma, each node in the first hidden layer of the feature map computes
at most  CÃß ^TPQN f K¬ö¬§ ¬¢¬ì functions on the P9^ input vectors in ¬ã . Thus, there can be at most
 CÃß ^TPQN f K¬ö¬§ b . ¬¢¬ì 5 distinct functions from the input to the output of the first hidden layer on
the P9^ points in ¬ã . Fixing the first hidden layer parameters, each node in the second layer of the
featuremapcomputesatmost  CÃß ^TPQN U K¬ö¬§ b ¬ì functionsonthe imageof ¬ã producedatthe output
of the first hidden layer. Thus the second hidden layer computes no more than  CÃß ^TPQN U K¬ö¬§ = . b ¬ì 5
functions on the output of the first hidden layer on the P9^ points in ¬ã . So, in total,
¬Ä¬∞ ÃÑ P]^_ ¬ø AÃÉ CÃß^TP
f K¬ö¬§REÃÇ b.¬¢¬ì 5 AÃÉ CÃß^TP
UK¬ö¬§EÃÇ =.b¬ì 5
Now, for each possible matrix M | ~ ¬ä , the number of functions computable on each row of M | ~ ¬ä by a
thresholded linear combination ofthe output of thefeature map isatmost  CÃß ^_N J K¬ö¬§ = ¬ì . Hence,
the number of binary sign assignments obtainable by applying linear threshold functions to all the
rowsisatmostCÃß ^_NJ K ¬§ c .= ¬ì 5.Thus,
¬Ä ¬å P]^_¬Ü¬ø AÃÉ CÃß^TP
f K¬ö¬§EÃÇ b.¬¢¬ì 5 AÃÉ CÃß^TP
UK¬ö¬§EÃÇ =.b¬ì 5 AÃÉ CÃß^TP
PAÃäJ K¬ö¬§EÃÇ c.=¬ì 5
q ¬± $¬ö AÃà¬é√Ü  isaconvexfunction,henceforallIG¬± . ¬£ ,
q AÃÉ JIEÃÅK UG¬îKY¬±
J K UK¬ö¬§ EÃÇ ¬ø ¬§
J K UK¬ö¬§ JRq JIK Uq HGK q 2¬±
3 AÃÉ J K UK¬ö¬§
JIoÃÉK UG]Kc¬±EÃÇ = ÃÅ¬ìb¬∂Œº¬ì Ãß¬∑ AÃÉ I¬§EÃÇ =} ÃÅ AÃÉ G¬§EÃÇ b1Œº AÃÉ ¬±¬§EÃÇ ¬∑
SubstitutingI  U K¬ö¬§ ,G¬ü f K¬ö¬§ and¬± ¬óPAÃäJ K¬ö¬§ showsthat
¬Ä¬ç¬å P]^_¬Ü¬ø AÃÉ CÃß^TPAÃäJ K UK¬ö¬§
U K PAÃäJ K¬ö¬§ EÃÇ S ¬ì c.=¬ì 5 (51)
176


A MODEL OF INDUCTIVE BIAS LEARNING
Hence, if
^ . AÃÉ UP K J K ¬§EÃÇ AÃà¬é√Ü> AÃÉ CÃß^TPAÃäJ K UK ¬§
U K PAÃäJ K¬ö¬§ EÃÇ (52)
then¬Ä¬ç¬å P]^_o% AÃÇ c  andsobydefinitionf ¬å PQ¬ø¬ö^ . ForallI . ¬§ ,observethat . I AÃà¬é√Ü > 
ifT AÃÇ I AÃà¬é√Ü > AÃÇ I .SettingT CÃß^TPAÃäJ K U K¬ö¬§NU K PAÃäJ K¬ö¬§ andI  CÃß J K U K¬ö¬§ showsthat
(52)issatisfiedif^  AÃÇ U NP}K J K¬ö¬§ AÃà¬é√Ü > AÃÇCÃß J K U K¬ö¬§.
Theorem 16. Let A be as in Theorem 15 with the following extra restrictions: f AÃÅ , U J and
J ¬ø f.Then f ¬å PQ¬à AÃÇ¬§ AÃÉ ¬°AÃÇUP ¬£ K J K¬ö¬§EÃÇ
Proof. We bound f  A  and f  A  and then apply Lemma 10. In the present setting A contains all
three-layer linear-threshold networks with f input nodes, U hidden nodes in the first hidden layer, J
hidden nodes in the second hidden layer and one output node. From Theorem 13 in Bartlett (1993),
wehave ¬É¬Ç¬Ñ¬Ü¬Ö=¬á¬à A ¬à flU K UJ :1‚ÅÑ2¬§
AÃÇ K¬ö¬§3
which under the restrictions stated above is greater than U N AÃÇ . Hence f  A ¬à U N AÃÇ .
As J ¬ø f and U J we can choose a feature weight assignment so that the feature map is the
identity on J components of the input vector and insensitive to the setting of the reminaing f : J
components. Hence we can generate J K√°¬§ points in  whose image under the feature map is
shattered by the linear threshold output node, and so f  A ] J K¬ö¬§ .
Combining Theorem 15 with Corrolary 13 shows that
^! F AÃÉ i¬§> AÃÄAÃÉ UP K J K¬ö¬§EÃÇ AÃà¬é√Ü i¬§ K P¬§ AÃà¬é√Ü 1‚ÅÑ4¬§EÃàEÃÇ
examples of each task suffice when learning P tasks using a linear threshold hypothesis space family,
while combining Theorem 16 with Theorem 14 shows that if
^ ¬ø1‚ÅÑ4¬ª AÃÉ i¬§> AÃÄAÃÉ UP K J K ¬§EÃÇ K P¬§ AÃà¬é√Ü 1‚ÅÑ4¬§EÃàEÃÇ
then any learning algorithm will fail on some set of P tasks.
4. Conclusion
The problem of inductive bias is one that has broad significance in machine learning. In this paper we have introduced a formal model of inductive bias learning that applies when the learner is able to sample from multiple related tasks. We proved that provided certain covering numbers computed from the set of all hypothesis spaces available to the bias learner are finite, any hypothesis space that contains good solutions to sufficiently many training tasks is likely to contain good solutions to novel tasks drawn from the same environment.
In the specific case of learning a set of features, we showed that the number of examples ^
required of each task in an P -task training set obeys ^ F  J K U NPQ , where J is the number of
177


BAXTER
features and U is a measure of the complexity of the feature class. We showed that this bound is
essentially tight for Boolean feature maps constructed from linear threshold networks. In addition, we proved that the number of tasks required to ensure good performance from the features on novel
tasks is no more than F  U  . We also showed how a good set of features may be found by gradient
descent. The model of this paper represents a first step towards a formal model of hierarchical approaches to learning. By modelling a learner‚Äôs uncertainty concerning its environment in probabilistic terms, we have shown how learning can occur simultaneously at both the base level‚Äîlearn the tasks at hand‚Äîand at the meta-level‚Äîlearn bias that can be transferred to novel tasks. From a technical perspective, it is the assumption that tasks are distributed probabilstically that allows the performance guarantees to be proved. From a practical perspective, there are many problem domains that can be viewed as probabilistically distributed sets of related tasks. For example, speech recognition may be decomposed along many different axes: words, speakers, accents, etc. Face recognition represents a potentially infinite domain of related tasks. Medical diagnosis and prognosis problems using the same pathology tests are yet another example. All of these domains should benefit from being tackled with a bias learning approach. Natural avenues for further enquiry include:
E
Alternative constructions for A . Although widely applicable, the specific example on feature
learning via gradient descent represents just one possible way of generating and searching
the hypothesis space family A . It would be interesting to investigate alternative methods,
including decision tree approaches, approaches from Inductive Logic Programming (Khan et al., 1998), and whether more general learning techniques such as boosting can be applied in a bias learning setting.
E
Algorithms for automatically determining the hypothesis space family A . In our model the
structure of A is fixed apriori and represents the hyper-bias of the bias learner. It would
be interesting to see to what extent this structure can also be learnt.
E
Algorithms for automatically determining task relatedness. In ordinary learning there is usually little doubt whether an individual example belongs to the same learning task or not. The analogous question in bias learning is whether an individual learning task belongs to a given set of related tasks, which in contrast to ordinary learning, does not always have such a clear-cut answer. For most of the examples we have discussed here, such as speech and face recognition, the task-relatedness is not in question, but in other cases such as medical problems it is not so clear. Grouping too large a subset of tasks together as related tasks could clearly have a detrimental impact on bias-learning or multi-task learning, and there is emprical evidence to support this (Caruana, 1997). Thus, algorithms for automatically determining task-relatedness are a potentially useful avenue for further research. In this context, see Silver and Mercer (1996), Thrun and O‚ÄôSullivan (1996). Note that the question of task relatedness
is clearly only meaningful relative to a particular hypothesis space family A (for example, all
possible collections of tasks are related if A contains every possible hypothesis space).
E
Extended hierarchies. For an extension of our two-level approach to arbitrarily deep hierarchies, see Langford (1999). An interesting further question is to what extent the hierarchy can be inferred from data. This is somewhat related to the question of automatic induction of structure in graphical models.
178


A MODEL OF INDUCTIVE BIAS LEARNING
Acknowledgements
This work was supported at various times by an Australian Postgraduate Award, a Shell Australia Postgraduate Fellowship, U.K Engineering and Physical Sciences Research Council grants K70366 and K70373, and an Australian Postdoctoral Fellowship. Along the way, many people have contributed helpful comments and suggestions for improvement including Martin Anthony, Peter Bartlett, Rich Caruana, John Langford, Stuart Russell, John Shawe-Taylor, Sebastian Thrun and several anonymous referees.
Appendix A. Uniform Convergence Results
Theorem 2 provides a bound (uniform over all 1‚ÅÑ2¬ø3‚ÅÑ4AÃÅAÃÄ ) on the probability of large deviation between
AÃÇ?AÃÉAÃà1AÃä 1‚ÅÑ2 √Ü and AÃÇ?CÃßAÃÉEÃÄpAÃä 1‚ÅÑ2 √Ü . To obtain a more general result, we follow Haussler (1992) and introduce the
following parameterized class of metrics on EÃÅAEÃÇ :
EÃà"IÃÄIÃÅIÃÇ√êIÃà_NÃÉ"OÃÄeOÃÅ1OÃÇ OÃÉIÃÇmOÃà√óNÃÉOÃÉ
IÃÇ√ò8NÃÉUÃÄ√òcUÃÅ IÃà
where UÃÅUÃàUÃÇ√ûYÃÅ . Our main theorem will be a uniform bound on the probability of large values of
EÃà"IÃÄ1IÃÅAÃÇ?AÃÉAÃà1AÃä1‚ÅÑ2 √ÜIÃàAÃÇ?AÃÉEÃÄpAÃä1‚ÅÑ2 √ÜOÃÄ,ratherthanOÃÉAÃÇ?AÃÉAÃà1AÃä1‚ÅÑ2 √Ü OÃà AÃÇ?CÃßAÃÉEEÃÄ"AÃä1‚ÅÑ2√ü√Ü OÃÉ.Theorem2willthenfollowasacorollary,as
will better boundsfor the realizable case AÃÇ?CÃßAÃÉEEÃÄ"AÃä 1‚ÅÑ2√ü√Ü OÃÇDYÃÅ (Appendix A.3).
Lemma 17. The following three properties of EÃàpIÃÄ are easily established:
1. For all √† IÃàE√°UÃÄ√¢1‚ÅÑ4YÃÅ , YÃÅaÃÉ¬òEÃàpIÃÄ¬àIÃÅ√† IÃàE√°√§OÃÄ√êaÃÉ√¶aÃä
2.ForallYÃÅnaÃÉ √† aÃÉ1‚ÅÑ4√°aÃÉ√®√ß,EÃà"IÃÄ1IÃÅ√†IÃàE√°?OÃÄ√êaÃÉ1‚ÅÑ4EÃà"IÃÄ1IÃÅ√†IÃà_√ß√©OÃÄandEÃà"IÃÄ IÃÅ√™√°^IÃà_√ß√©OÃÄ¬ÄaÃÉ¬òEÃàpIÃÄ IÃÅ√†IÃà_√ß√©OÃÄ.
3.ForYÃÅLaÃÉ √†IÃàE√°¬§aÃÉ√¶aÃä,√´√¨}√≠√Ø√Æ√´
IÃÄEÃÇ Ãß√∞ aÃÉ¬òEÃà"IÃÄIÃÅ√†IÃàE√°?OÃÄ√êaÃÉ √´√¨√≠√Ø√Æ√´
IÃÄ
For ease of exposition we have up until now been dealing explicitly with hypothesis spaces 1‚ÅÑ2
containingfunctions√± OÃÅQ√≤!√≥¬Ñ√¥ ,andthenconstructinglossfunctions√±QoÃÉ mapping√≤√∑√∂ √¥3√≥√∏IÃÅYÃÅjIÃà√§aÃä}OÃÄ
by√±QoÃÉAÃäIÃÇ√êIÃà_NÃÉ √Ü OÃÅ1OÃÇ√πAÃä√± AÃäIÃÇ √ÜIÃà_NÃÉ √Ü forsomelossfunction√πOÃÅ√∫√¥AÃÅ√∂A√¥3√≥√ªIÃÅYÃÅjIÃà√§aÃä}OÃÄ.However,ingeneralwecanview
√±QoÃÉ just as a function from an abstract set √º (√≤+√∂¬Æ√¥ ) to IÃÅYÃÅjIÃà√§aÃä}OÃÄ and ignore its particular construction
in terms of the loss function √π . So for the remainder of this section, unless otherwise stated, all
hypothesis spaces 1‚ÅÑ2 will be sets of functions mapping √º to IÃÅ YÃÅjIÃà√§aÃä}OÃÄ . It will also be considerably more
convenient to transpose our notation for AÃäCyÃÅ IÃà_√æ √Ü -samples, writing the yÃÅ training sets as columns
insteadofrows: yÃà OÃÇ   
... . . . ...
  
where each 3‚ÅÑ41‚ÅÑ4√º . Recalling the definition of AÃä √≤√∑√∂√¥ √Ü  (Equation 9 and prior discussion),
with this transposition yÃà lives in AÃä √≤ √∂√ü√¥ √Ü    . The following definition now generalizes quantities
likeAÃÇ?CÃßAÃÉ EÃÄ AÃä1‚ÅÑ2 √Ü,AÃÇ?AÃÉ AÃä1‚ÅÑ2√ü√Ü andsoontothisnewsetting.
Definition6. Let 1‚ÅÑ2  IÃà  IÃà 1‚ÅÑ2  be yÃÅ sets of functions mapping √º into IÃÅYÃÅjIÃà√§aÃä}OÃÄ. For any √±  3‚ÅÑ4
1‚ÅÑ2 IÃàIÃà√±  3‚ÅÑ4√ü1‚ÅÑ2  ,let√±  √±  orsimply denotethemap
AÃä√ÜOÃÇ aÃäyÃÅ √± AÃä √Ü
179


BAXTER
forall  OÃÇ AÃä  IÃà  IÃà  √Ü 3‚ÅÑ4UÃà√º  . Let1‚ÅÑ2 !"# 1‚ÅÑ2  denotethesetofallsuchfunctions. Given
53‚ÅÑ4 1‚ÅÑ2 $%& 1‚ÅÑ2  and√æ elementsofAÃä√≤ √∂ √¥ √Ü ,AÃä IÃà IÃà  √Ü (orequivalentlyanelementyÃà of
AÃä √≤ √∂ √¥ √Ü    bywritingthe  asrows),define
AÃÇ?CÃßAÃÉEÃÄ"AÃä√ÜOÃÅ1OÃÇ √æaÃä 'AÃä√Ü
(recall equation (8)). Similarly, for any product probability measure ( OÃÇ*)  √∂  √∂+)  on
AÃä√≤ √∂ √¥ √Ü,define AÃÇ?AÃÉ AÃä√Ü OÃÅ1OÃÇ-,#.0/ AÃä√ÜEÃà( AÃä√Ü
(recallequation(26)).Forany IÃà 21 OÃÅ AÃä√≤ √∂ √¥ √Ü √≥√ªIÃÅYÃÅjIÃà√§aÃä}OÃÄ (notnecessarilyoftheform√± 345 √±  ),
define EÃà AÃäIÃà1√ÜOÃÅ1OÃÇ%,./ OÃÉAÃä√ÜOÃà 1AÃä√ÜOÃÉEÃà( AÃä√Ü
(recallequation(17)). Forany classof functions 1‚ÅÑ2 mapping AÃä √≤√∑√∂√¥ √Ü  to IÃÅYÃÅjIÃà√§aÃä}OÃÄ , define
6 AÃä57IÃà1‚ÅÑ2 √ÜOÃÅ1OÃÇ98;:=<?> AÃä@7IÃà1‚ÅÑ2 IÃàEÃà√Ü
wherethesupremumisoverallproductprobabilitymeasureson AÃä √≤ √∂ √¥ √Ü  and> AÃä7 IÃà 1‚ÅÑ2 IÃàEÃà  √Ü isthe
size of the smallest 7 -cover of 1‚ÅÑ2 under EÃà  (recall Definition 4).
The following theorem is the main result from which the rest of the uniform convergence results in this paper are derived.
Theorem18. Let1‚ÅÑ2BA√®1‚ÅÑ2  C 1‚ÅÑ2  beapermissibleclassoffunctionsmapping AÃä√≤√∑√∂√ü√¥ √Ü  into
IÃÅYÃÅjIÃà√§aÃä}OÃÄ. LetyÃà 3‚ÅÑ4 AÃä√≤√∑√∂ √¥ √Ü    begeneratedby√æ¬É√¢EDF AÃä@G √∞ UÃÅ √Ü independenttrialsfromAÃä√≤ √∂ √¥ √Ü
accordingtosomeproductprobabilitymeasure( OÃÇ9)  √∂  √∂H)  .ForallUÃÅ√üUÃÇ1‚ÅÑ4YÃÅ ,YÃÅJI G I√¶aÃä ,
KAÃÉMLyÃà 3‚ÅÑ4 AÃä√≤ √∂√ü√¥ √ÜOÃÅN8;:O#<EÃàpIÃÄ¬àIÃÅAÃÇ?CÃßAÃÉEÃÄAÃä'√ÜIÃàAÃÇ?AÃÉAÃä'√ÜOÃÄ√êUÃÇ GQPaÃÉ+R6AÃä@GUÃÅSTIÃà1‚ÅÑ2 √ÜAÃÇVU<AÃäOÃàG√∞UÃÅyÃÅ√æWT√Ü (53)
The following immediate corollary will also be of use later.
Corollary 19. Under the same conditions as Theorem 18, if
√æ!√¢YX[ZU]\ G√∞TUÃÅyÃÅH^_&`R6bacdIÃÄIÃà1‚ÅÑ2fe
g IÃàGD√∞UÃÅih IÃà (54)
then KAÃÉLyÃà 3‚ÅÑ4 AÃä√≤√∑√∂ √¥ √Ü OÃÅj8;:O#< EÃàpIÃÄ¬àIÃÅAÃÇ?CÃßAÃÉEÃÄ"AÃä'√ÜIÃàAÃÇ?AÃÉ AÃä'√ÜOÃÄ'UÃÇ G P aÃÉ g (55)
A.1 Proof of Theorem 18
The proof is via a double symmetrization argument of the kind given in chapter 2 of Pollard (1984). I have also borrowed some ideas from the proof of Theorem 3 in Haussler (1992).
180


A MODEL OF INDUCTIVE BIAS LEARNING
A.1.1 FIRST SYMMETRIZATION
Anextrapieceofnotation: forallyÃà 3‚ÅÑ4 AÃä √≤√∑√∂√¥ √Ü √∞    ,letyÃà AÃä aÃä √Ü bethetophalfofyÃà andyÃà AÃä D √Ü bethe
bottomhalf,viz: yÃà AÃäaÃä √Ü OÃÇ   
... . . . ...
k  yÃàAÃäD√ÜOÃÇ EÃÇl  EÃÇ
... . . . ...
√∞l  √∞
The following lemma is the first ‚Äúsymmetrization trick.‚Äù We relate the probability of large deviation between an empirical estimate of the loss and the true loss to the probability of large deviation between two independent empirical estimates of the loss.
Lemma20. Let 1‚ÅÑ2 be a permissible set of functions from AÃä √≤√∑√∂ √¥ √Ü  into IÃÅYÃÅjIÃà√§aÃä}OÃÄ and let ) be a
probabilitymeasureonAÃä√≤√∑√∂√¥ √Ü .ForallUÃÅ UÃÇ¬òYÃÅjIÃàYÃÅmI G I√¶aÃä and√æ!√¢ cF√∞nIÃÄ ,
KAÃÉLyÃà 3‚ÅÑ4 AÃä√≤ √∂√ü√¥ √ÜOÃÅN8;:O#<EÃàpIÃÄ¬àIÃÅAÃÇ?CÃßAÃÉEÃÄAÃä√±√Ø√ÜIÃàAÃÇ?AÃÉpo1AÃä√±¬¨√ÜOÃÄ'UÃÇ GP
aÃÉYDKAÃÉLyÃà 3‚ÅÑ4¬Æ√º √∞OÃÅN8;:O#<EÃàpIÃÄrqAÃÇ?CÃßAÃÉEÃÄ AÃä√±¬¨√ÜIÃàAÃÇ?CÃßAÃÉEÃÄ√∞AÃä√±¬¨√Üts UÃÇ GD P  (56)
Proof. Note first that permissibility of 1‚ÅÑ2 guarantees the measurability of suprema over 1‚ÅÑ2
(Lemma 32 part 5). By the triangle inequality for EÃàpIÃÄ , if EÃà"IÃÄ qAÃÇ?CÃßAÃÉ EÃÄ  AÃä√±√Ø√Ü IÃà AÃÇ?AÃÉuo1AÃä√±√Ø√Üs UÃÇ G and
EÃà"IÃÄ]qAÃÇ?CÃßAÃÉEÃÄ √∞AÃä√±√Ø√ÜIÃàAÃÇ?AÃÉVo AÃä√±√Ø√Üts I GD,thenEÃà"IÃÄrqAÃÇ?CÃßAÃÉEÃÄ AÃä√±√Ø√ÜIÃàAÃÇ?CÃßAÃÉEÃÄ √∞AÃä√±√Ø√Üts UÃÇ GD.Thus,
KAÃÉ&vyÃà 3‚ÅÑ4 AÃä√≤√∑√∂√¥ √Ü√∞OÃÅxw√±3‚ÅÑ4√ü1‚ÅÑ2 OÃÅQEÃà"IÃÄ qAÃÇ?CÃßAÃÉEÃÄAÃä√±√Ø√ÜIÃàAÃÇ?CÃßAÃÉEÃÄ√∞AÃä√±√Ø√ÜsUÃÇ GDzy
√¢ KAÃÉvyÃà 3‚ÅÑ4 AÃä√≤√∑√∂ √¥ √Ü√∞OÃÅ0w√±3‚ÅÑ4¬¢1‚ÅÑ2 OÃÅ"EÃà"IÃÄ qAÃÇ?CÃßAÃÉEÃÄAÃä√±√Ø√ÜIÃàAÃÇ?AÃÉuo1AÃä√±√Ø√Üs UÃÇ G and
EÃà"IÃÄ qAÃÇ?CÃßAÃÉEÃÄ√∞AÃä√±√Ø√ÜIÃàAÃÇ?AÃÉuo1AÃä√±√Ø√Üs I GDy (57)
By Chebyshev‚Äôs inequality, for any fixed √± ,
KAÃÉvyÃà 3‚ÅÑ4 AÃä√≤ √∂ √¥ √ÜOÃÅQEÃàIÃÄIÃÅAÃÇ?CÃßAÃÉEÃÄAÃä√±√Ø√ÜIÃàAÃÇ?AÃÉoAÃä√±√Ø√ÜOÃÄ{I GDy
√¢ KAÃÉLyÃà 3‚ÅÑ4 AÃä√≤ √∂ √¥ √ÜOÃÅOÃÉAÃÇ?CÃßAÃÉEÃÄ"AÃä√±√Ø√ÜOÃà AÃÇ?AÃÉo1AÃä√±√Ø√ÜOÃÉ
UÃÅ I GDP
√¢√¶aÃä¬úOÃà AÃÇ?AÃÉoAÃä√±√Ø√ÜAÃäaÃärOÃà AÃÇ?AÃÉoAÃä√±√Ø√Ü_√Ü
√æUÃÅ G √∞ |R
√¢ DaÃä
as√æ¬Ñ√¢-DF AÃä@G √∞ UÃÅ √Ü andAÃÇ?AÃÉo1AÃä √±¬¨√Ü aÃÉ aÃä . Substitutingthislastexpressionintotherighthandsideof(57)
gives the result.
181


BAXTER
A.1.2 SECOND SYMMETRIZATION
The second symmetrization trick bounds the probability of large deviation between two empirical estimates of the loss (i.e. the right hand side of (56)) by computing the probability of large deviation when elements are randomly permuted between the first and second sample. The following definition introduces the appropriate permutation group for this purpose.
Definition 7. For all integers √æ√óIÃà yÃÅ √¢ aÃä , let } √∞    denote the set of all permutations ~ of the
sequenceofpairsofintegers AÃäaÃä>IÃà√§aÃä√ÜIÃàIÃàAÃäaÃä>IÃàyÃÅ √ÜIÃàIÃàAÃäD√æ√óIÃà√§aÃä√ÜIÃàIÃàAÃäD√æ√óIÃàyÃÅ √Ü¬Ä suchthatforall¬Å,aÃä&aÃÉ
¬Å aÃÉ√æ ,either~ AÃä¬ÅIÃà¬É¬Ç√Ü OÃÇ AÃä√æ √ò ¬ÅIÃà¬É¬Ç√Üand~ AÃä√æ¬ã√ò ¬ÅIÃà¬É¬Ç√Ü OÃÇ AÃä¬ÅIÃà¬É¬Ç√Üor~ AÃä¬ÅIÃà¬É¬Ç√Ü OÃÇ AÃä¬ÅIÃà¬É¬Ç√Üand~ AÃä√æ¬ã√ò ¬ÅIÃà¬É¬Ç√Ü OÃÇ
AÃä√æ √ò ¬ÅIÃà¬É¬Ç√Ü.
ForanyyÃà 3‚ÅÑ4 AÃä√≤√∑√∂√¥ √Ü √∞  andany~√ó3‚ÅÑ4H} √∞ ,let
yÃàF¬Ñ OÃÅ1OÃÇ ¬Ñ l  ¬Ñ 
... . . . ...
¬Ñ√∞l  ¬Ñ√∞
Lemma21. Let 1‚ÅÑ2 OÃÇ 1‚ÅÑ2 ¬Ö"¬Ü 1‚ÅÑ2  be a permissible set of functions mapping AÃä √≤ √∂ √¥ √Ü  into
IÃÅYÃÅjIÃà√§aÃä}OÃÄ (asinthestatementofTheorem18).FixyÃà 3‚ÅÑ4 AÃä√≤√∑√∂√ü√¥ √Ü √∞   andlet1‚ÅÑ2CÃß OÃÅ1OÃÇ ¬á IÃàIÃà¬á3¬àW¬Ä be
anG UÃÅST-coverforAÃä1‚ÅÑ2 IÃàEÃàEÃÄ√Ü,whereEÃà EÃÄpAÃä IÃà 1√Ü OÃÅ1OÃÇ √∞+¬â √∞'  OÃÉ AÃä √Ü OÃà  1AÃä √ÜOÃÉwherethe aretherows
of yÃà . Then,
KAÃÉL~√ó3‚ÅÑ4H} √∞OÃÅj8:O#<EÃà"IÃÄ]qAÃÇ?CÃßAÃÉEÃÄ;¬ä AÃä√ÜIÃàAÃÇ?CÃßAÃÉEÃÄ;¬ä√∞AÃä'√ÜtsUÃÇ GDP
aÃÉ '¬àKAÃÉv~ 3‚ÅÑ4H} √∞OÃÅQEÃàIÃÄ qAÃÇ?CÃßAÃÉEÃÄ¬ä AÃä¬á √ÜIÃàAÃÇ?CÃßAÃÉEÃÄ¬ä √∞AÃä¬á √Üts UÃÇ GR y IÃà (58)
where each ~√ó3‚ÅÑ4H} √∞    ischosenuniformlyatrandom.
Proof.Fix~1‚ÅÑ43‚ÅÑ4¬ã} √∞  andlet3‚ÅÑ481‚ÅÑ2 besuchthatEÃàpIÃÄ¬åqAÃÇ?CÃßAÃÉEÃÄ;¬ä AÃä'√ÜIÃàAÃÇ?CÃßAÃÉEÃÄ;¬ä √∞AÃä√Üts UÃÇ G D (ifthereis
nosuch  forany ~ wearealreadydone). Choose¬á¬§3‚ÅÑ4 1‚ÅÑ2 CÃß suchthatEÃà EÃÄ AÃä  IÃà ¬á>√Ü aÃÉ G UÃÅST . Withoutloss
ofgeneralitywecanassume¬á isoftheform¬á OÃÇ¬é¬ç  ¬è3 ¬ç  .Now,
UÃÅDEÃàEÃÄAÃäIÃà¬á>√ÜOÃÇ ¬â √∞'¬ë¬ê¬ê¬ê¬â u√± AÃä √ÜOÃà¬í¬ç AÃä √Ü¬ê¬ê¬ê
UÃÅj√æ yÃÅ
OÃÇ ¬â √∞'¬ê¬ê¬ê¬â u√± AÃä¬Ñ √ÜOÃà¬ì¬ç AÃä¬Ñ √Ü¬ê¬ê¬ê
UÃÅj√æ yÃÅ
√¢ ¬ê¬ê¬ê¬â '¬â pq√± AÃä¬Ñ √ÜOÃà¬í¬ç AÃä¬Ñ √Üs¬ê¬ê¬ê
UÃÅj√æ yÃÅ √ò ¬â '¬â uq√± AÃä¬Ñ √Ü√ò¬î¬ç AÃä¬Ñ √Üs
√ò ¬ê¬ê¬ê¬â √∞'EÃÇ¬â pq√± AÃä¬Ñ √ÜOÃà¬ì¬ç AÃä¬Ñ √Üts¬ê¬ê¬ê
UÃÅa√æ yÃÅ √ò ¬â √∞'EÃÇ¬â uq√± AÃä¬Ñ √Ü√ò¬î¬ç AÃä¬Ñ √Üts
OÃÇEÃà"IÃÄ qAÃÇ?CÃßAÃÉEÃÄ¬ä AÃä√ÜIÃàAÃÇ?CÃßAÃÉEÃÄ¬ä AÃä¬á√Üs√òcEÃàpIÃÄ qAÃÇ?CÃßAÃÉEÃÄ¬ä√∞AÃä√ÜIÃàAÃÇ?CÃßAÃÉEÃÄ¬ä√∞AÃä¬á√Üs
182


A MODEL OF INDUCTIVE BIAS LEARNING
Hence, by the triangle inequality for EÃàpIÃÄ ,
UÃÅDEÃàEÃÄAÃäIÃà¬á>√Ü√òEÃàIÃÄ qAÃÇ?CÃßAÃÉEÃÄ¬ä AÃä¬á>√ÜIÃàAÃÇ?CÃßAÃÉEÃÄ¬ä√∞AÃä¬á√Üs√¢¬òEÃàIÃÄ qAÃÇ?CÃßAÃÉEÃÄ¬ä AÃä√ÜIÃàAÃÇ?CÃßAÃÉEÃÄ¬ä AÃä¬á√Üs
√òcEÃàIÃÄ qAÃÇ?CÃßAÃÉEÃÄ¬ä√∞AÃä'√ÜIÃàAÃÇ?CÃßAÃÉEÃÄ¬ä√∞AÃä¬á√Üts√òcEÃàIÃÄ qAÃÇ?CÃßAÃÉEÃÄ¬ä AÃä¬á√ÜIÃàAÃÇ?CÃßAÃÉEÃÄ¬ä√∞AÃä¬á√Üts
√¢¬òEÃàpIÃÄ qAÃÇ?CÃßAÃÉEÃÄ;¬ä AÃä'√ÜIÃàAÃÇ?CÃßAÃÉEÃÄ;¬ä √∞AÃä√Üs (59)
ButIÃÄ√∞ EÃà EÃÄpAÃä IÃà¬á>√Ü aÃÉ G |R byconstructionandEÃà"IÃÄ]qAÃÇ?CÃßAÃÉEÃÄ¬ä AÃä√ÜIÃàAÃÇ?CÃßAÃÉEÃÄ¬ä √∞AÃä√Üts UÃÇ G D byassumption,so
(59)impliesEÃà"IÃÄ qAÃÇ?CÃßAÃÉEÃÄ¬ä AÃä¬á>√ÜIÃàAÃÇ?CÃßAÃÉEÃÄ¬ä √∞AÃä¬á>√Üs UÃÇ G |R.Thus,
v~√ó3‚ÅÑ4H} √∞OÃÅxw 3‚ÅÑ4¬¢1‚ÅÑ2 OÃÅ√∫EÃà"IÃÄrqAÃÇ?CÃßAÃÉEÃÄ¬ä AÃä√ÜIÃàAÃÇ?CÃßAÃÉEÃÄ¬ä√∞AÃä'√ÜtsUÃÇ GDy
A v~√ó3‚ÅÑ4H} √∞OÃÅxw¬áUÃÄ3‚ÅÑ4 1‚ÅÑ2CÃßOÃÅ√ØEÃà"IÃÄ qAÃÇ?CÃßAÃÉEÃÄ¬ä AÃä¬á√ÜIÃàAÃÇ?CÃßAÃÉEÃÄ¬ä√∞AÃä¬á√Üs√ÜUÃÇ GR¬ïy IÃà
which gives (58).
Now we bound the probability of each term in the right hand side of (58).
Lemma22. Let ¬á OÃÅ AÃä √≤√∑√∂√¥ √Ü  √≥ IÃÅYÃÅjIÃà√§aÃä}OÃÄ be any function that can be written in the form ¬á OÃÇ
¬ç{¬è3 ¬ç.ForanyyÃà 3‚ÅÑ4 AÃä√≤ √∂ √¥ √Ü √∞ ,
KAÃÉMv~ 3‚ÅÑ4b} √∞OÃÅQEÃà"IÃÄ]qAÃÇ?CÃßAÃÉEÃÄ¬ä AÃä¬á>√ÜIÃàAÃÇ?CÃßAÃÉEÃÄ¬ä√∞AÃä¬á>√ÜtsUÃÇ GRy aÃÉYDAÃÇVU<¬ó¬ñOÃàG√∞UÃÅj√æ yÃÅ
T ¬ò IÃà (60)
where each ~√ó3‚ÅÑ4H} √∞    ischosenuniformlyatrandom.
Proof. Forany~ 3‚ÅÑ4f} √∞  ,
EÃàIÃÄ qAÃÇ?CÃßAÃÉEÃÄ¬ä AÃä¬á√ÜIÃàAÃÇ?CÃßAÃÉEÃÄ¬ä√∞AÃä¬á√ÜtsOÃÇ ¬ê¬ê¬ê¬â ¬â pq¬ô¬ç AÃä¬Ñ √ÜOÃà¬í¬ç AÃä¬ÑEÃÇ √Üts¬ê¬ê¬ê
UÃÅj√æ yÃÅ √ò ¬â √∞¬â u¬ç AÃä √Ü  (61)
To simplify the notation denote ¬ç AÃä √Ü by ¬ö . For each pair ¬Å¬Ç , aÃäYaÃÉ ¬Å aÃÉ √æ , aÃäYaÃÉ¬õ¬ÇDaÃÉ yÃÅ , let
√¥ l be an independent random variable such that √¥ OÃÇ ¬ö OÃà ¬ö  EÃÇ  with probability aÃäD and
√¥ l OÃÇ ¬ö  EÃÇ  OÃà ¬ö withprobabilityaÃäD .From(61),
KAÃÉMv~√ó3‚ÅÑ4H} √∞OÃÅ√ØEÃà"IÃÄ qAÃÇ?CÃßAÃÉEÃÄ¬ä AÃä¬á√ÜIÃàAÃÇ?CÃßAÃÉEÃÄ¬ä√∞AÃä¬á√ÜsUÃÇ GRy
OÃÇ KAÃÉ¬ó¬ùl¬ú¬û~ 3‚ÅÑ4H} √∞OÃÅ ¬ê¬ê¬ê¬ê¬ê¬ê'pq¬ü¬ç AÃä¬Ñ √ÜOÃà¬í¬ç AÃä¬ÑEÃÇ √Üts¬ê¬ê¬ê¬ê¬ê¬êUÃÇ GR¬°¬¢UÃÅa√æ yÃÅ √ò √∞'p¬ö¬£¬§Y¬•¬ßl¬¶
OÃÇ KAÃÉ¬ó¬ù¬ú¬û¬ê¬ê¬ê¬ê¬ê¬ê'u√¥ ¬ê¬ê¬ê¬ê¬ê¬êGR¬°¬¢UÃÅj√æ yÃÅ √ò √∞u¬ö ¬£¬§+¬•¬ß¬¶
For zero-mean independent random variables √¥  IÃà  IÃà√¥0 Ãà with bounded ranges ¬© aÃÉ √¥ aÃÉ¬´a , Ho
effding‚Äôs inequality (Devroye, Gyo Ãàrfi, & Lugosi, 1996) is
KAÃÉ\ ¬ê¬ê¬ê¬ê¬ê' Ãà√¥ ¬ê¬ê¬ê¬ê¬ê√¢¬î¬¨h aÃÉYDAÃÇVU<¬Æ'OÃà D3¬¨√∞
¬â  ÃàAÃäa OÃà ¬© √Ü√∞# ÃÑ 
183


BAXTER
Notingthattherangeofeach√¥ isIÃÅOÃà OÃÉ¬ö OÃà ¬ö EÃÇ   √Ü OÃÉIÃà OÃÉ¬ö OÃà ¬ö EÃÇ   √Ü OÃÉOÃÄ,wehave
KAÃÉ¬ùl¬ú¬û¬ê¬ê¬ê¬ê¬ê¬ê'p√¥ ¬ê¬ê¬ê¬ê¬ê¬êUÃÇ GR¬∞¬¢UÃÅj√æ yÃÅ √ò √∞u¬ö¬£¬§+¬•¬ß¬¶ aÃÉYDAÃÇVU< ¬±¬¢OÃà G√∞32UÃÅj√æ yÃÅ √ò ¬â √∞¬â u¬öV ÃÅ√∞
ŒºD¬â ¬â pAÃä¬ö OÃà ¬ö EÃÇ√Ü√∞¬£¬§¬∂
Let¬∑ OÃÇ ¬â √∞¬â p ¬ö .AsYÃÅaÃÉ ¬ö aÃÉ√¶aÃä,¬â  ¬â u AÃä¬ö OÃà ¬ö EÃÇ √Ü√∞ aÃÉ ¬∑.Hence,
DAÃÇVU< ¬±¬¢OÃà G√∞2UÃÅj√æ yÃÅ √ò ¬â √∞'¬â u¬öl ÃÅ√∞
ŒºD¬â '¬â uAÃä¬ölOÃà ¬ö EÃÇ√Ü√∞¬£¬§¬∂aÃÉYDAÃÇVU< ¬ñOÃà G√∞AÃäUÃÅj√æ yÃÅ √ò ¬∑e√Ü√∞
ŒºD¬∑ ¬ò
AÃäUÃÅj√æ yÃÅ √ò ¬∑e√Ü √∞  ¬∑ isminimizedbysetting¬∑ OÃÇDUÃÅj√æ yÃÅ givingavalueofR"UÃÅj√æ yÃÅ .Hence
KAÃÉv~ 3‚ÅÑ4f} √∞OÃÅ√∫EÃàIÃÄ qAÃÇ?CÃßAÃÉEÃÄ¬ä AÃä¬á√ÜIÃàAÃÇ?CÃßAÃÉEÃÄ¬ä√∞AÃä¬á√ÜtsUÃÇ GRy aÃÉYDAÃÇVU< ¬ñOÃàG√∞UÃÅa√æ yÃÅ
T ¬òIÃà
as required.
A.1.3 PUTTING IT TOGETHER
ForfixedyÃà 3‚ÅÑ4 AÃä √≤ √∂ √¥ √Ü √∞   ,Lemmas21and22give:
KAÃÉL~√ó3‚ÅÑ4H} √∞OÃÅj8:O#<EÃà"IÃÄ]qAÃÇ?CÃßAÃÉEÃÄ;¬ä AÃä√ÜIÃàAÃÇ?CÃßAÃÉEÃÄ;¬ä√∞AÃä'√ÜtsUÃÇ GDP
aÃÉYD> AÃä@GUÃÅSTIÃà1‚ÅÑ2 IÃàEÃàEÃÄ√Ü_√ÜAÃÇVU<W¬ñeOÃà G√∞UÃÅj√æ yÃÅ
T ¬ò
Note that EÃà EÃÄ is simply EÃà  where ( OÃÇ AÃä )  IÃà  IÃà;)  √Ü and each ) is the empirical distribution that
putspointmassaÃäG√æ oneach  IÃà¬É¬Ç¬§OÃÇ aÃä>IÃà  IÃàD√æ (recallDefinition3).Hence,
KAÃÉL~√ó3‚ÅÑ4H} √∞IÃàyÃà 3‚ÅÑ4 AÃä√≤ √∂√¥ √Ü√∞OÃÅN8;:O=<EÃà"IÃÄ qAÃÇ?CÃßAÃÉEÃÄ¬ä AÃä√ÜIÃàAÃÇ?CÃßAÃÉEÃÄ¬ä√∞AÃä√ÜsUÃÇ GDP
aÃÉYD6 AÃä@GUÃÅSTIÃà1‚ÅÑ2 √ÜAÃÇVU<W¬ñeOÃà G√∞UÃÅj√æ yÃÅ
T ¬ò
Now, for a random choice of yÃà , each in yÃà is independently (but not identically) distributed and ~
only ever swaps and EÃÇ   (so that ~ swaps a drawn according to ) with another component
drawn according to the same distribution). Thus we can integrate out with respect to the choice of
~
and write
KAÃÉLyÃà 3‚ÅÑ4 AÃä√≤ √∂√ü√¥ √Ü√∞OÃÅj8;:O#<EÃàpIÃÄ qAÃÇ?CÃßAÃÉEÃÄAÃä√ÜIÃàAÃÇ?CÃßAÃÉEÃÄ√∞AÃä√ÜsUÃÇ GDP
aÃÉYD6 AÃä@GUÃÅSTIÃà1‚ÅÑ2 √ÜAÃÇVU<W¬ñeOÃà G√∞UÃÅj√æ yÃÅ
T ¬ò
Applying Lemma 20 to this expression gives Theorem 18.
184


A MODEL OF INDUCTIVE BIAS LEARNING
A.2 Proof of Theorem 2
Another piece of notation is required for the proof. For any hypothesis space 1‚ÅÑ2 and any probability
measures( OÃÇ AÃä) IÃàIÃà;)  √Ü on√º ,let
AÃÇ?CÃßAÃÉAÃä1‚ÅÑ2 √ÜOÃÅ1OÃÇ yÃÅaÃä '] Ãß'1=o
¬ª&1‚ÅÑ4O AÃÇ?AÃÉo&1‚ÅÑ2AÃä√±¬¨√Ü
Note that we have used AÃÇ?CÃßAÃÉ  AÃä 1‚ÅÑ2 √Ü rather than AÃÇ?AÃÉ  AÃä 1‚ÅÑ2√ü√Ü to indicate that AÃÇ?CÃßAÃÉ  AÃä 1‚ÅÑ2√ü√Ü is another empirical
estimateofAÃÇ?AÃÉAÃà1AÃä1‚ÅÑ2 √Ü.
With the AÃäCyÃÅ IÃà_√æ √Ü -sampling process, in addition to the sample yÃà there is also generated a se
quence of probability measures, ( OÃÇ AÃä )  IÃà  IÃà;)  √Ü although these are not supplied to the learner.
ThisnotionisusedinthefollowingLemma,whereK AÃÉ  AÃäyÃà IÃà (√Ü3‚ÅÑ4 AÃä√≤ √∂√ü√¥ √Ü 3‚ÅÑ4! √∂AÃÄ¬ø  OÃÅxAÃÅ ¬Ä means
‚Äúthe probability of generating a sequence of measures ( from the environment AÃä ¬ønIÃàpAÃÇ √Ü and then an
AÃäCyÃÅ IÃà_√æ √Ü -sample yÃà according to ( such that A holds‚Äù.
Lemma23.K AÃÉIfL AÃäyÃàIÃà(√Ü13‚ÅÑ4 AÃä√≤ √∂ √¥ √Ü3‚ÅÑ4! √∂f¬ø  OÃÅN8:AÃÉ#< EÃà"IÃÄ1IÃÅAÃÇ?CÃßAÃÉEÃÄ"AÃä1‚ÅÑ2 √ÜIÃàAÃÇ?CÃßAÃÉ AÃä1‚ÅÑ2 √ÜOÃÄ√êUÃÇ GD P aÃÉ DgIÃà (62)
and KAÃÉL( 3‚ÅÑ4 ¬ø OÃÅAÃà8;:AÃÉ#< EÃà"IÃÄ IÃÅAÃÇ?CÃßAÃÉ AÃä1‚ÅÑ2 √ÜIÃàAÃÇ?AÃÉ}AÃà1AÃä1‚ÅÑ2 √ÜOÃÄ¬ÄUÃÇ GD P aÃÉ DgIÃà (63)
then KAÃÉLyÃà 3‚ÅÑ4 AÃä√≤ √∂ √¥ √Ü3‚ÅÑ4!OÃÅAÃà8;:AÃÉ#< EÃà"IÃÄ1IÃÅAÃÇ?CÃßAÃÉEÃÄpAÃä1‚ÅÑ2 √ÜIÃàAÃÇ?AÃÉAÃà1AÃä1‚ÅÑ2 √ÜOÃÄ√êUÃÇ GP aÃÉ g
Proof. Follows directly from the triangle inequality for EÃà IÃÄ .
We treat the two inequalities in Lemma 23 separately.
A.2.1 INEQUALITY (62)
In the following Lemma we replace the supremum over 1‚ÅÑ2¬ø3‚ÅÑ4AÃÅAÃÄ in inequality (62) with a supremum
over83‚ÅÑ4AÃÅAÃÄ  .
Lemma 24.
KAÃÉMLAÃäyÃàIÃà(√Ü3‚ÅÑ4 AÃä√≤√∑√∂√¥ √Ü√∂f¬øOÃÅj8;:AÃÉ#<EÃàpIÃÄ¬àIÃÅAÃÇ?CÃßAÃÉEÃÄ"AÃä1‚ÅÑ2√ü√ÜIÃàAÃÇ?CÃßAÃÉAÃä1‚ÅÑ2√ü√ÜOÃÄ√êUÃÇ GQP
aÃÉ KAÃÉ\ AÃäyÃàIÃà(√Ü¬ú3‚ÅÑ4 AÃä√≤√∑√∂√¥ √Ü√∂f¬ø OÃÅN8;AÃÉ:#/AÃä<EÃàpIÃÄIÃÅAÃÇ?CÃßAÃÉEEÃÄpAÃä'√ÜIÃàAÃÇ?AÃÉAÃä'√ÜOÃÄUÃÇ Gh (64)
185


BAXTER
Proof. Supposethat AÃäyÃà IÃà(√Ü aresuchthat8;:#< AÃÉ EÃàpIÃÄ IÃÅAÃÇ?CÃßAÃÉEEÃÄ"AÃä1‚ÅÑ2√ü√ÜIÃàAÃÇ?CÃßAÃÉ AÃä1‚ÅÑ2√ü√ÜOÃÄnUÃÇ G . Let1‚ÅÑ2 satisfythisin
equality. SupposefirstthatAÃÇ?CÃßAÃÉEÃÄ"AÃä1‚ÅÑ2√ü√Ü aÃÉ AÃÇ?CÃßAÃÉ  AÃä1‚ÅÑ2√ü√Ü. BythedefinitionofAÃÇ?CÃßAÃÉEÃÄ"AÃä1‚ÅÑ2√ü√Ü,forall7 UÃÇ YÃÅ there
exists53‚ÅÑ4 1‚ÅÑ2  OÃÅ1OÃÇ 1‚ÅÑ2 -& 1‚ÅÑ2 suchthatAÃÇ?CÃßAÃÉEÃÄ"AÃä√Ü I AÃÇ?CÃßAÃÉEEÃÄ"AÃä1‚ÅÑ2√ü√Ü √ò 7.Hencebyproperty(3)oftheEÃà"IÃÄ
metric,forall7 UÃÇ YÃÅ ,thereexists√¶3‚ÅÑ4Y1‚ÅÑ2  suchthatEÃà"IÃÄ IÃÅAÃÇ?CÃßAÃÉEÃÄ"AÃä√Ü IÃàAÃÇ?CÃßAÃÉEEÃÄ"AÃä1‚ÅÑ2 √ÜOÃÄjI 7 . Pickanarbitrary
satisfyingthisinequality. Bydefinition,AÃÇ?CÃßAÃÉ AÃä1‚ÅÑ2 √Ü aÃÉ AÃÇ?AÃÉ AÃä√Ü,andsoAÃÇ?CÃßAÃÉEEÃÄ"AÃä1‚ÅÑ2√ü√Ü aÃÉ AÃÇ?CÃßAÃÉ AÃä1‚ÅÑ2√ü√Ü aÃÉ AÃÇ?AÃÉ AÃä'√Ü.
AsEÃà IÃÄ IÃÅAÃÇ?CÃßAÃÉ EÃÄ AÃä1‚ÅÑ2√ü√Ü IÃà AÃÇ?CÃßAÃÉu AÃä1‚ÅÑ2√ü√Ü OÃÄ¬àUÃÇ G (byassumption),bythecompatibilityofEÃà IÃÄ withtheorderingonthe
reals,EÃàpIÃÄ1IÃÅAÃÇ?CÃßAÃÉEÃÄ"AÃä1‚ÅÑ2√ü√ÜIÃàAÃÇ?AÃÉ AÃä'√ÜOÃÄ'UÃÇ G OÃÇ G √ò g ,say.BythetriangleinequalityforEÃàpIÃÄ ,
EÃàpIÃÄ1IÃÅAÃÇ?CÃßAÃÉEÃÄpAÃä√ÜIÃàAÃÇ?AÃÉAÃä'√ÜOÃÄQ√òcEÃà"IÃÄIÃÅAÃÇ?CÃßAÃÉEÃÄpAÃä√ÜIÃàAÃÇ?CÃßAÃÉEEÃÄ"AÃä1‚ÅÑ2 √ÜOÃÄ√ê√¢¬òEÃàpIÃÄ1IÃÅAÃÇ?CÃßAÃÉEÃÄ"AÃä1‚ÅÑ2√ü√ÜIÃàAÃÇ?AÃÉAÃä'√ÜOÃÄOÃÇ G √ò g
ThusEÃàpIÃÄ1IÃÅAÃÇ?CÃßAÃÉEÃÄ"AÃä'√Ü IÃàAÃÇ?AÃÉ  AÃä'√ÜOÃÄ¬§UÃÇ G √ò g OÃà 7 andforany7 UÃÇ YÃÅ an satisfyingthisinequalitycanbe
found.Choosing7 OÃÇ g showsthatthereexists 3‚ÅÑ4 1‚ÅÑ2  suchthatEÃà"IÃÄ1IÃÅAÃÇ?CÃßAÃÉEÃÄ"AÃä√Ü IÃàAÃÇ?AÃÉ  AÃä√ÜOÃÄ'UÃÇ G .
If instead, AÃÇ?CÃßAÃÉ  AÃä 1‚ÅÑ2√ü√Ü I AÃÇ?CÃßAÃÉEÃÄ"AÃä 1‚ÅÑ2 √Ü , then an identical argument can be run with the role of yÃà and (
interchanged. Thus in both cases,
8:AÃÉ#<EÃà"IÃÄ1IÃÅAÃÇ?CÃßAÃÉEÃÄpAÃä1‚ÅÑ2 √ÜIÃàAÃÇ?CÃßAÃÉAÃä1‚ÅÑ2 √ÜOÃÄ√êUÃÇ G¬Æ√Ü w83‚ÅÑ4AÃÅAÃÄ oÃÉOÃÅQEÃàpIÃÄ1IÃÅAÃÇ?CÃßAÃÉEÃÄ"AÃä'√ÜIÃàAÃÇ?AÃÉAÃä'√ÜOÃÄUÃÇ GIÃà
which completes the proof of the Lemma.
By the nature of the AÃäCyÃÅ IÃà_√æ √Ü sampling process,
KAÃÉ¬ë\¬∞AÃäyÃàIÃà(√Ü3‚ÅÑ4 AÃä√≤ √∂√¥ √Ü√∂CÃß¬ø8;AÃÉ:#/AÃä<OÃÅ√∫EÃàpIÃÄ¬àIÃÅAÃÇ?CÃßAÃÉEÃÄ"AÃä'√ÜIÃàAÃÇ?AÃÉAÃä'√ÜOÃÄ'UÃÇ Gh
OÃÇ 1‚ÅÑ4,3EÃÄ/KAÃÉ¬Ö\yÃà 3‚ÅÑ4 AÃä√≤√∑√∂√¥ √ÜOÃÅj8;AÃÉ:=/AÃä<EÃàIÃÄIÃÅAÃÇ?CÃßAÃÉEÃÄAÃä√ÜIÃàAÃÇ?AÃÉpAÃä√ÜOÃÄ√êUÃÇ Gh EÃàEÃÅAÃÇ AÃä(√Ü (65)
NowAÃÄ oÃÉ AYEÃÇ ¬óEÃà EÃÇ whereEÃÇ OÃÅ1OÃÇ G√±QoÃÉOÃÅ √±3‚ÅÑ4¬¢1‚ÅÑ2 OÃÅ 1‚ÅÑ2¬ø3‚ÅÑ4AÃÅAÃÄH¬Ä andAÃÄ oÃÉ ispermissiblebytheassumed
permissibility of AÃÄ (Lemma 32, Appendix D). Hence AÃÄ oÃÉ satisfies the conditions of Corollary 19
and so combining Lemma 24, Equation (65) and substituting G D for G and g D for g in Corollary
19 gives the following Lemma on the sample size required to ensure (62) holds.
Lemma25. If √æ!√¢+X[Z U L Œº D
G√∞UÃÅyÃÅf^_&` T6AÃä@GUÃÅSaÃäIÃÄIÃàAÃÄ oÃÉ√Ü
g IÃàGT√∞UÃÅP
then KAÃÉLAÃäyÃàIÃà(√Ü3‚ÅÑ4 AÃä√≤ √∂√¥ √Ü√∂f¬ø OÃÅj8;:AÃÉ#< EÃàpIÃÄ¬àIÃÅAÃÇ?CÃßAÃÉEÃÄ"AÃä1‚ÅÑ2√ü√ÜIÃàAÃÇ?CÃßAÃÉAÃä1‚ÅÑ2√ü√ÜOÃÄ√êUÃÇ GD P aÃÉ Dg
A.2.2 INEQUALITY (63)
NotethatAÃÇ?AÃÉ AÃä1‚ÅÑ2 √Ü OÃÇ  ¬â '  1‚ÅÑ2CÃßIÃÅAÃä) √Ü andAÃÇ?AÃÉAÃà AÃä1‚ÅÑ2 √Ü OÃÇIÃàIÃÇ oNÃÉ√ê AÃà 1‚ÅÑ2CÃßIÃÅAÃä) √Ü,i.etheexpectationof1‚ÅÑ2fIÃÅAÃä) √Ü
where ) is distributed according to AÃÇ . So to bound the left-hand-side of (63) we can apply Corollary
19with yÃÅ OÃÇ aÃä , √æ replacedbyyÃÅ ,1‚ÅÑ2 replacedby AÃÄ4IÃÅ , G and g replacedby G D and g D respectively,
)
replaced by AÃÇ and √º replaced by ¬ø . Note that AÃÄ IÃÅ is permissible whenever AÃÄ is (Lemma 32).
Thus,if yÃÅ √¢+X[ZU L GŒº√∞DUÃÅ ^_&` T6AÃä@GUÃÅSaÃäIÃÄIÃàAÃÄ4IÃÅ?√Ü
g IÃàG T√∞UÃÅ P (66)
186


A MODEL OF INDUCTIVE BIAS LEARNING
then inequality (63) is satisfied. Now, putting together Lemma 23, Lemma 25 and Equation 66, we have proved the following more general version of Theorem 2.
Theorem 26. Let AÃÄ be a permissible hypothesis space family and let yÃà be an AÃäCyÃÅ IÃà_√æ √Ü -sample gen
eratedfromtheenvironment AÃä¬ønIÃàpAÃÇ √Ü .ForallYÃÅ[I G IÃà g I√¶aÃä andUÃÅ√üUÃÇ¬òYÃÅ ,if
yÃÅ √¢YX[ZU LGŒº√∞DUÃÅ ^_&` T6AÃä@GUÃÅSaÃäIÃÄIÃàAÃÄ IÃÅ√Ü
g IÃàGT√∞UÃÅP
and √æ!√¢YX[ZU L ŒºD
G√∞UÃÅyÃÅ ^_&` T6AÃä@GUÃÅ0aÃäIÃÄIÃàAÃÄ oÃÉ√Ü
g IÃàGT√∞UÃÅP IÃà
then KAÃÉLyÃà 3‚ÅÑ4 AÃä√≤√∑√∂ √¥ √Ü3‚ÅÑ4!OÃÅj8;:AÃÉ#<EÃàpIÃÄ1IÃÅAÃÇ?CÃßAÃÉEÃÄ"AÃä1‚ÅÑ2√ü√ÜIÃàAÃÇ?AÃÉAÃà1AÃä1‚ÅÑ2√ü√ÜOÃÄ'UÃÇ GP aÃÉ g
TogetTheorem2,observethatAÃÇ?AÃÉAÃà AÃä1‚ÅÑ2√ü√Ü UÃÇ AÃÇ?CÃßAÃÉEÃÄAÃä1‚ÅÑ2√ü√Ü √ò 7m√Ü EÃàIÃÄ IÃÅAÃÇ?CÃßAÃÉEÃÄAÃä1‚ÅÑ2 √ÜIÃàAÃÇ?AÃÉAÃà AÃä1‚ÅÑ2 √ÜOÃÄ1UÃÇ 7AÃäD{√ò5UÃÅ √Ü.
SettingG OÃÇ 7  AÃäD√òUÃÅ √Ü andmaximizingG √∞ UÃÅ givesUÃÅ OÃÇOÃÄD . SubstitutingG OÃÇ 7 |R andUÃÅ OÃÇED into
Theorem 26 gives Theorem 2.
A.3 The Realizable Case
In Theorem 2 the sample complexity for both √æ and yÃÅ scales as aÃä 7 √∞ . This can be improved to
aÃä7 ifinsteadofrequiringAÃÇ?AÃÉAÃà¬àAÃä1‚ÅÑ2 √Ü aÃÉ AÃÇ?CÃßAÃÉEÃÄ"AÃä1‚ÅÑ2 √Ü √ò 7,werequireonlythatAÃÇ?AÃÉAÃà AÃä1‚ÅÑ2 √Ü aÃÉ¬õOÃÅ AÃÇ?CÃßAÃÉEEÃÄpAÃä1‚ÅÑ2√ü√Ü √ò 7
forsomeOÃÅ1‚ÅÑ4UÃÇ aÃä.Toseethis,observethatAÃÇ?AÃÉAÃà AÃä1‚ÅÑ2√ü√Ü UÃÇ AÃÇ?CÃßAÃÉEÃÄAÃä1‚ÅÑ2 √ÜAÃäaÃä¬ú√ò G √Ü AÃäaÃäOÃà G √Ü √ò G UÃÅS AÃäaÃä OÃà G √Ü √Ü
EÃà"IÃÄ1IÃÅAÃÇ?CÃßAÃÉEÃÄ"AÃä1‚ÅÑ2 √ÜIÃàAÃÇ?AÃÉ}AÃà1AÃä1‚ÅÑ2 √ÜOÃÄ¬àUÃÇ G ,sosettingG UÃÅ0 AÃäaÃäoOÃà G √Ü OÃÇ 7 inTheorem26andtreatingG asaconstant
gives:
Corollary 27. Under the same conditions as Theorem 26, for all 7 UÃÇ¬òYÃÅ and YÃÅJI G IÃà g I√¶aÃä , if
yÃÅ √¢¬îX[ZU L ŒºD
G$AÃäaÃäOÃà G√Ü7^_&` T6AÃä_AÃäaÃä¬úOÃà G√Ü7aÃäIÃÄIÃàAÃÄOÃÇIÃÅ√§√Ü
g IÃàT
G¬àAÃäaÃä¬úOÃà G√Ü7P
and √æ √¢¬îX[ZU L ŒºD
G$AÃäaÃäOÃà G√Ü7¬ûyÃÅ ^_&` T6AÃä_AÃäaÃä¬úOÃà G√Ü7aÃäIÃÄIÃàAÃÄ oÃÉ√Ü
g IÃàT
G$AÃäaÃä¬úOÃà G√Ü7P IÃà
then KAÃÉLyÃà 3‚ÅÑ4 AÃä√≤√∑√∂ √¥ √Ü3‚ÅÑ4!OÃÅN8;:AÃÉ#<AÃÇ?AÃÉAÃà1AÃä1‚ÅÑ2 √Ü√¢ aÃä$√ò G
aÃäOÃà GAÃÇ?CÃßAÃÉEÃÄpAÃä1‚ÅÑ2 √Ü√ò 7P aÃÉ g
Theseboundsareparticularlyusefulifweknowthat AÃÇ?CÃßAÃÉEÃÄpAÃä 1‚ÅÑ2 √Ü OÃÇUÃàYÃÅ ,forthenwecanset G OÃÇ aÃäD
(whichmaximizesG¬àAÃä aÃä OÃà G √Ü ).
Appendix B. Proof of Theorem 6
Recalling Definition 6, for AÃÄ of the form given in (32), AÃÄ oÃÉ can be written
AÃÄ oÃÉ OÃÇ OÃÉOÃà¬ç ¬è3 OÃÉzOÃà¬çrOÃÅOÃÉIÃàIÃàOÃÉ 3‚ÅÑ4b√ó¬¨oÃÉand¬ç 3‚ÅÑ4CÃß√òCÃß¬Ä
To write AÃÄ oÃÉ as a composition of two function classes note that if for each ¬çoOÃÅ√∫√≤ √≥ UÃÄ we define
¬çUÃÅrOÃÅAÃä√≤ √∂ √¥ √Ü √≥ AÃäUÃÄ √∂ √¥ √Ü by
¬çUÃÅAÃäIÃÇIÃà_NÃÉIÃàIÃà_IÃÇIÃà_NÃÉ√ÜOÃÅ1OÃÇ AÃä¬çAÃäIÃÇ√ÜIÃà_NÃÉIÃàIÃà¬çAÃäIÃÇ√ÜIÃà_NÃÉ√Ü
187


BAXTER
thenOÃÉOÃà ¬ç bt OÃÉiOÃà ¬ç√üOÃÇ OÃÉ¬è OÃÉzOÃà ¬çUÃÅ.Thus,setting√óoÃÉ OÃÅ1OÃÇ √ó¬¨oÃÉb¬É √ó√ØoÃÉand√ò OÃÅ1OÃÇ ¬çUÃÅoOÃÅ0¬ç 3‚ÅÑ4
√òCÃß¬Ä, AÃÄ oÃÉ OÃÇ √óoÃÉ OÃà √ò  (67)
The following two Lemmas will enable us to bound 6 AÃä57 IÃà AÃÄ oÃÉ √Ü .
Lemma28.Let1‚ÅÑ2 OÃÅ√Ø√≤√∑√∂ √¥√∑√≥ IÃÅYÃÅjIÃà√§aÃä}OÃÄ beoftheform1‚ÅÑ2 OÃÇ √ó¬¨oÃÉ OÃà √ò where√≤ √∂ √¥ OÃà¬∂√≥UÃÇ UÃÄ √∂ √¥ OÃàOUÃà√≥AÃä
IÃÅYÃÅjIÃà√§aÃä}OÃÄ.Forall7IÃà7√∞ UÃÇ¬òYÃÅ, 6AÃä57√ò 7√∞IÃà1‚ÅÑ2√ü√Ü aÃÉ 6UÃàAÃäAÃä57IÃà√òL√Ü6AÃä57√∞IÃà√ó¬¨oÃÉ:√Ü
Proof. Fix a measure ) on √≤ √∂ √¥ and let YÃÅ be a minimum size 7  -cover for AÃä √ò IÃàEÃà=√ûo UÃà AÃä¬ô√ü√Ü . By
definitionOÃÉYÃÅ OÃÉ aÃÉ 6 UÃà AÃäAÃä57  IÃà√òm√Ü.Foreach¬ç 3‚ÅÑ4bYÃÅ let)$√† bethemeasureonUÃÄ √∂ √¥ definedby)$√† AÃä√° √Ü OÃÇ
) AÃä ¬ç √≠  AÃä√° √Ü_√Ü foranyset √° inthe ~ -algebraon UÃÄ √∂√ó√¥ (¬ç ismeasurableso ¬ç √≠  AÃä√° √Ü ismeasurable).
Let √¢ √† be a minimumsize 7 √∞ -cover for AÃä√ó√ØoÃÉIÃàEÃà oFaÃÉ √Ü. By definitionagain, OÃÉ√¢ √† OÃÉ aÃÉ 6 AÃä57 √∞ IÃà √ó√ØoÃÉ2√Ü. Let
√§ OÃÅ1OÃÇ OÃÉ OÃà ¬çoOÃÅaÃä¬ç 3‚ÅÑ49YÃÅ andOÃÉ1‚ÅÑ43‚ÅÑ4¬é√¢ √†¬Ä.NotethatOÃÉ√§ OÃÉ aÃÉ 6 UÃàAÃäAÃä57IÃà√òm√Ü6 AÃä57√∞IÃà√ó¬¨oÃÉC√Ü sotheLemmawillbe
proved if √§ can be shown to be an 7  √ò 7 √∞ -cover for AÃä 1‚ÅÑ2 IÃàEÃà o √Ü . So, given any OÃÉ OÃà ¬ç 3‚ÅÑ41‚ÅÑ41‚ÅÑ2 choose
¬ç 1 Ãß3‚ÅÑ4HYÃÅ suchthatEÃà √ûoUÃàAÃä√üAÃä¬ç¬¨IÃà¬ç 1√Ü aÃÉ 7 andOÃÉ3‚ÅÑ41 Ãß3‚ÅÑ4AÃÄ√¢ √†V√¶suchthatEÃàoaÃÉ√¶AÃäOÃÉ IÃàOÃÉ3‚ÅÑ41C√Ü aÃÉ 7√∞.Now,
EÃà o1AÃäOÃÉ OÃà ¬ç√êIÃàOÃÉ 1 OÃà ¬ç 1√Ü aÃÉ¬òEÃà o AÃäOÃÉ OÃà ¬ç'IÃàOÃÉ OÃà ¬ç 1√Ü √òYEÃà o AÃäOÃÉ OÃà ¬ç 1IÃàOÃÉ 1 OÃà ¬ç 1√Ü
aÃÉ¬òEÃà √ûo UÃà AÃä√ß√ü AÃä ¬ç¬¨IÃà¬ç 1√Ü √òcEÃà o aÃÉ √¶EAÃäOÃÉ IÃà OÃÉ 1√Ü
aÃÉ7√ò7√∞
where the first line follows from the triangle inequality for EÃà o and the second line follows from
thefacts:EÃào1AÃäOÃÉ OÃà ¬ç1IÃàOÃÉ1OÃà ¬ç1√Ü OÃÇ√∑EÃàoFaÃÉjAÃäOÃÉIÃàOÃÉ3‚ÅÑ41:√Ü andEÃào1AÃäOÃÉ OÃà ¬ç'IÃàOÃÉ OÃà ¬ç1√Ü aÃÉ!EÃà√ûoUÃàAÃä√üAÃä¬ç¬¨IÃà¬ç1√Ü. Thus√§ isan
7  √ò 7 √∞ -coverfor AÃä 1‚ÅÑ2 IÃàEÃà o √Ü andsotheresultfollows.
Recalling the definition of 1‚ÅÑ2 {¬è 1‚ÅÑ2  (Definition 6), we have the following Lemma.
Lemma29. 6 AÃä57IÃà1‚ÅÑ2 M¬è3 1‚ÅÑ2 √Ü aÃÉ √®6 AÃä57IÃà1‚ÅÑ2 √Ü
Proof. Fixaproductprobabilitymeasure( OÃÇ¬õ)  √∂  √∂¬ó)  on AÃä√≤√∑√∂ √¥ √Ü . Let√§  IÃà  IÃà√§  be
7
-coversofAÃä1‚ÅÑ2 IÃàEÃào¬Ü√©√ÜIÃàAÃä1‚ÅÑ2 IÃàEÃào/√Ü.andlet√§ OÃÇ √§  % √§ .Given√± OÃÇ √± % √± 3‚ÅÑ4
1‚ÅÑ2 {¬è& 1‚ÅÑ2 ,chooseOÃÉ93 OÃÉ 3‚ÅÑ4 √§ suchthatEÃào&1‚ÅÑ2AÃä√± IÃàOÃÉ √Ü aÃÉ 7 foreach¬Å OÃÇ aÃä>IÃàIÃàyÃÅ .Now,
EÃàAÃä√±¬è √±IÃàOÃÉ93 OÃÉ√ÜOÃÇ yÃÅaÃä ,./¬ê¬ê¬ê¬ê¬ê'√± AÃä √ÜOÃà 'OÃÉ AÃä √Ü¬ê¬ê¬ê¬ê¬êEÃà( AÃä IÃàIÃà √Ü
aÃÉ yÃÅaÃä 'EÃào&1‚ÅÑ2EAÃä√± IÃàOÃÉ √Ü
aÃÉ7
Thus√§ isan7 -coverfor1‚ÅÑ2 93 1‚ÅÑ2  andasOÃÉ√§ OÃÉ OÃÇ-√™ '  OÃÉ√§ OÃÉ theresultfollows.
188


A MODEL OF INDUCTIVE BIAS LEARNING
B.1 Bounding6 AÃä@7 IÃàAÃÄCÃß√´√¨j√Ü
FromLemma28, 6 a7 √ò 7√∞IÃà√ó¬¨oÃÉ OÃà √ò e aÃÉ 6 AÃä@7IÃà√ó√ØoÃÉ√Ü 6UÃàAÃä/ a7√∞IÃà√ò e (68)
andfromLemma29, 6 AÃä@7 IÃà√ó¬¨oÃÉ √Ü aÃÉ 6 AÃä57 IÃà√ó¬¨oÃÉ:√Ü  (69)
Using similar techniques to those used to prove Lemmas 28 and 29, 6 UÃà AÃä / AÃä57 IÃà √ò¬¢√Ü can be shown to
satisfy 6UÃàAÃä/ AÃä57√∞IÃà√ò √Ü aÃÉ 6UÃàAÃäAÃä7√∞IÃà√òm√Ü  (70)
Equations (67), (68), (69) and (70) together imply inequality (34).
B.2 Bounding√≠¬ó√Æ√ØS√∞^AÃÄCÃß√±√≤
We wish to prove that 6 AÃä57 IÃà AÃÄOÃÇIÃÅ√§√Ü aÃÉ 6 UÃà AÃä AÃä@7 IÃà √òm√Ü when AÃÄ is a hypothesis space family of the form
AÃÄ OÃÇ |√ó¬¨oÃÉ OÃà ¬ç¬úOÃÅx¬ç 3‚ÅÑ4f√ò4¬Ä .Notethateach1‚ÅÑ2fIÃÅo3‚ÅÑ4/AÃÄOÃÇIÃÅ correspondstosome√ó¬¨oÃÉ OÃà ¬ç ,andthat
1‚ÅÑ2 IÃÅAÃä) √ÜOÃÇ  Ãß'1#o
√≥ 1‚ÅÑ4 UÃà AÃä AÃÇ?AÃÉo1AÃäOÃÉ OÃà ¬ç √Ü 
Any probability measure AÃÇ on ¬ø induces a probability measure AÃÇi√¥¬ïoÃÉ¬Ü√∂ on √≤ √∂√ü√¥ , defined by
AÃÇz√¥zoÃÉ¬Ü√∂AÃä√°√ÜOÃÇ-,EÃÄ ) AÃä√°√ÜEÃàEÃÅAÃÇ AÃä) √Ü
for any √° in the ~ -algebra on √≤ √∂√ü√¥ . Note also that if √± IÃà √± 1 are bounded, positive functions on an
arbitrarysetAÃÅ ,then ¬ê¬ê¬ê¬ê  Ãß√∑1#o
√∏1‚ÅÑ43√π√±AÃä¬©j√ÜOÃà  Ãß√∑1#o
√∏ 1‚ÅÑ43√π √± 1AÃä¬©a√Ü ¬ê¬ê¬ê¬ê aÃÉ+8:#<
√∏1‚ÅÑ43√π ¬ê¬ê√±AÃä¬©a√ÜOÃà √±1AÃä¬©a√Ü¬ê¬ê (71)
Let AÃÇ be any probability measure on the space ¬ø of probability measures on √≤ √∂ √¥ . Let 1‚ÅÑ2fIÃÅ IÃà 1‚ÅÑ2CÃß√∞IÃÅ
be twoelements of AÃÄ IÃÅ with corresponding hypothesisspaces √ó¬¨oÃÉ OÃà ¬ç  IÃà √ó¬¨oÃÉ OÃà ¬ç √∞ . Then,
EÃàAÃà1AÃä1‚ÅÑ2 IÃÅIÃà1‚ÅÑ2 √∞IÃÅ√ÜOÃÇ-,EÃÄ ¬ê¬ê¬ê¬ê Ãß'1=o
√≥1‚ÅÑ4UÃàAÃäAÃÇ?AÃÉo1AÃäOÃÉOÃà¬ç√ÜOÃà  Ãß'1#o
√≥1‚ÅÑ4UÃàAÃäAÃÇ?AÃÉo1AÃäOÃÉOÃà¬ç√∞√Ü¬ê¬ê¬ê¬êEÃàEÃÅAÃÇ AÃä) √Ü
aÃÉ,EÃÄ 8;:#<
√≥1‚ÅÑ4UÃàAÃäOÃÉAÃÇ?AÃÉo1AÃäOÃÉ OÃà ¬ç√Ü OÃà AÃÇ?AÃÉo1AÃäOÃÉ OÃà ¬ç√∞√ÜOÃÉEÃàEÃÅAÃÇ AÃä) √Ü (by(71)above)
aÃÉ ,EÃÄ ,√¥¬ïoÃÉ¬Ü√∂ 8:#<
√≥1‚ÅÑ4UÃàAÃäOÃÉOÃÉOÃà¬çAÃäIÃÇ√êIÃà_NÃÉ√ÜOÃà OÃÉOÃà¬ç√∞AÃäIÃÇ¬ÄIÃà_NÃÉ√ÜOÃÉEÃà3‚ÅÑ4) AÃäIÃÇ¬ÄIÃà_NÃÉ√ÜEÃà¬ÜAÃÇ AÃä) √Ü
OÃÇEÃà √ûAÃà√ª√∫yÃÅ√º√æ UÃà AÃä√ß√ü AÃä ¬ç  IÃà¬ç √∞ √Ü 
The measurability of 8;:#< UÃà AÃä OÃÉ OÃà ¬ç is guaranteed by the permissibility of AÃÄ (Lemma 32 part 4, Ap
pendixD).FromEÃàAÃà1AÃä1‚ÅÑ2CÃßIÃÅIÃà1‚ÅÑ2f√∞IÃÅ√Ü aÃÉ¬òEÃà √ûAÃà √∫M√º|√æ UÃàAÃä√üAÃä¬çIÃà¬ç√∞√Ü wehave,
> AÃä57IÃàAÃÄ IÃÅIÃàEÃàAÃà√ÜaÃÉ > a7IÃà√ò IÃàEÃà=√ûAÃà√∫M√º|√æUÃàAÃä√üeIÃà (72)
which gives inequality (35).
189


BAXTER
B.3 Proof of Theorem 7
In order to prove the bounds in Theorem 7 we have to apply Theorem 6 to the neural network hypothesis space family of equation (39). In this case the structure is
EÃÅyÃÅyÃà OÃàw√≥UÃÇ EÃÅ Ãà OÃà√≥UÃà√ªIÃÅYÃÅjIÃà√§aÃä}OÃÄ
where√ó OÃÇ AÃäIÃÇ IÃàIÃà_IÃÇ0 Ãà√Ü√≥ ~ ¬â  Ãà' G IÃÇ √ò G OÃÅ AÃä@GIÃàG IÃàIÃàG  Ãà√Ü 3‚ÅÑ43¬Ä forsomebounded
subset  of EÃÅ  Ãà EÃÇ  and some Lipschitz squashing function ~ . The feature class √ò OÃÅ EÃÅ yÃà √≥ EÃÅ  Ãà
is the set of all one hidden layer neural networks with EÃà inputs, √π hidden nodes, outputs, ~ as
the squashing function and weights 3‚ÅÑ4 where is a bounded subset of EÃÅ . The Lipschitz
restriction on ~ and the bounded restrictions on the weights ensure that √ò and √ó are Lipschitz
classes. HencethereexistsabI suchthatforall¬ç 3‚ÅÑ4¬è√ò andIÃÇ¬ÄIÃà_IÃÇ 1 3‚ÅÑ4EÃÅ yÃà ,  ¬ç AÃäIÃÇ √Ü OÃà¬è¬ç AÃäIÃÇ 1√Ü I
aIÃÇmOÃà/IÃÇ 1 andforallOÃÉm3‚ÅÑ4W√ó andIÃÇ¬ÄIÃà_IÃÇ 1 3‚ÅÑ4 EÃÅ  Ãà,OÃÉOÃÉ AÃäIÃÇ √Ü OÃà OÃÉ AÃäIÃÇ 1√ÜOÃÉ IYaIÃÇmOÃà/IÃÇ 1 where   isthe  norm
in each case. The loss function is squared loss.
Now,OÃÉoÃÉAÃäIÃÇ√êIÃà_NÃÉ √Ü OÃÇ√¶√πAÃäOÃÉ AÃäIÃÇ √ÜIÃà_NÃÉ √Ü OÃÇ AÃäOÃÉ AÃäIÃÇ √Ü OÃà NÃÉ √Ü√∞,henceforallOÃÉ IÃàOÃÉ1√ê3‚ÅÑ4¬ó√ó andallprobabilitymeasures
)
onEÃÅ  Ãà √∂ IÃÅYÃÅjIÃà√§aÃä}OÃÄ (recallthatweassumedtheoutputspace√¥ was IÃÅYÃÅjIÃà√§aÃä}OÃÄ),
EÃàoAÃäOÃÉ>oÃÉIÃàOÃÉoÃÉ1√ÜOÃÇ-,oÃÉ√ûl√ü¬ê¬êAÃäOÃÉAÃä√ÜOÃà√óNÃÉ√Ü√∞OÃà AÃäOÃÉ1AÃä√ÜOÃà√óNÃÉ√Ü√∞¬ê¬êEÃà) AÃäIÃà_NÃÉ√Ü
aÃÉYDyÃÅ, ¬ê¬êOÃÉAÃä√ÜOÃà OÃÉ1AÃä√Ü¬ê¬êEÃà3‚ÅÑ4)AÃä√ÜIÃà (73)
where )   is the marginal distribution on EÃÅ  Ãà derived from ) . Similarly, for all ¬ç¬¨IÃà¬ç 1 3‚ÅÑ4-√ò and
probabilitymeasures) onEÃÅ yÃà √∂ IÃÅYÃÅjIÃà√§aÃä}OÃÄ,
EÃà√ûoUÃàAÃä√üAÃä¬ç¬¨IÃà¬ç1√ÜaÃÉYD&aaÃä,¬çAÃäIÃÇ√ÜOÃà¬ì¬ç1AÃäIÃÇ√ÜEÃà)AÃäIÃÇ√Ü (74)
Define 6 a7IÃà√óIÃà e OÃÅ1OÃÇ98;:o#<> a7IÃà√óIÃà AÃä) √ÜeIÃà
where the supremum is over all probability measures on (the Borel subsets of) EÃÅ  Ãà , and
> a 7 IÃà √ó IÃà   AÃä ) √Ü e isthesizeofthesmallest 7 -cover of √ó underthe   AÃä ) √Ü metric. Similarlyset,
6 a7IÃà√ò IÃàeOÃÅ1OÃÇ98;:o#<> a7IÃà√ò IÃàAÃä) √ÜeIÃà
where now the supremum is over all probability measures on EÃÅ yÃà . Equations (73) and (74) imply
6AÃä57IÃà√ó¬¨oÃÉ2√Ü aÃÉ 6 7DIÃà√ó IÃà  (75)
6UÃàAÃäAÃä@7IÃà√òm√Ü aÃÉ 6 D7&aIÃà√ò IÃà  (76)
Applying Theorem 11 from Haussler (1992), we find
6 D7IÃà√ó√ØoÃÉIÃà aÃÉD7a!√∞ ÃàEÃÇ Ãß√∞
6 D7&aIÃà√ò IÃà aÃÉD7a√∞ √∞" 
Substituting these two expressions into (75) and (76) and applying Theorem 6 yields Theorem 7.
190


A MODEL OF INDUCTIVE BIAS LEARNING
Appendix C. Proof of Theorem 14
This proof follows a similar argument to the one presented in Anthony and Bartlett (1999) for ordinary Boolean function learning. First we need a technical Lemma.
Lemma30. Let G bearandomvariableuniformlydistributed on  aÃäDUÃÄ√ò ¬ö D IÃà√§aÃäDnOÃà ¬ö D ¬Ä , with
YÃÅCÃßI ¬ö I aÃä .Let#  IÃà  IÃà#  bei.i.d. aÃä>IÃà√§OÃàUÃÄaÃä ¬Ä -valuedrandomvariableswithK AÃÉGAÃä# OÃÇ aÃä √Ü OÃÇ G forall
¬Å
.Foranyfunction¬ç mappingaÃä>IÃà√§OÃà{aÃä¬Ä √≥ aÃäDo√ò ¬ö D IÃà√§aÃäDOÃà ¬ö D¬Ä,
KAÃÉ#IÃàIÃà# OÃÅ0¬çAÃä#IÃàIÃà# √Ü%OÃÇ$ G¬Ä UÃÇ RaÃä'&aÃä¬úOÃà'( aÃä1OÃà)√≠+*-,n
√©/.,n10 
Proof. Let√§ AÃä #"√Ü denotethenumberofoccurencesof√ò&aÃä intherandomsequence# OÃÇ AÃä #  IÃà  IÃà #  √Ü .
The function ¬ç can be viewed as a decision rule, i.e. based on the observations # , ¬ç tries to guess
whethertheprobabilityof √ò&aÃä is aÃäDo√ò ¬ö D or aÃäDUÃÄOÃà ¬ö D . TheoptimaldecisionruleistheBayes
estimator:¬ç AÃä#IÃàIÃà# √Ü OÃÇ aÃäD√ò ¬ö D if√§ AÃä#"√Ü √¢√®√æWD,and¬ç AÃä#IÃàIÃà# √Ü OÃÇ aÃäD$OÃà ¬ö D otherwise.
Hence, KAÃÉ¬ÄAÃä¬çAÃä#^√Ü2OÃÇ$ G√Ü √¢ DaÃä KAÃÉ √§ AÃä#^√Ü √¢ √æD ¬ê¬ê¬ê¬êG OÃÇ DaÃä OÃà ¬öD¬ò
√ò DaÃäKAÃÉ√§ AÃä#"√ÜI √æD ¬ê¬ê¬ê¬êG OÃÇ DaÃä √ò ¬öDyÃÅ¬ò
UÃÇ DaÃäKAÃÉ√§ AÃä#^√Ü√¢ √æD ¬ê¬ê¬ê¬êG OÃÇ DaÃä OÃà ¬öD¬ò
which is half the probability that a binomial AÃä √æ√óIÃà√§aÃäD&OÃà ¬ö D √Ü random variable is at least √æWD . By
Slud‚Äôsinequality(Slud,197K7)AÃÉ,√êAÃä¬ç AÃä#"√Ü3OÃÇ$ G √Ü UÃÇ DaÃä K AÃÉ √º √¢ √æ ¬ö √∞
aÃä¬úOÃà ¬ö√∞ ÃÑ
where √º is normal AÃä YÃÅjIÃà√§aÃä √Ü . Tate‚Äôs inequality (Tate, 1953) states that for all IÃÇ¬Æ√¢¬òYÃÅ ,
KAÃÉ¬ÄAÃä√º √¢√®IÃÇ√Ü√¢ DaÃä 2aÃäOÃà'4 aÃä1OÃà)√≠65n ÃÅ
Combining the last two inequalities completes the proof.
Let7 3‚ÅÑ4 √≤ 3‚ÅÑ4! beshatteredby AÃÄ ,with√æ√∑OÃÇ EÃà AÃÉ AÃäCyÃÅ √Ü . Foreachrow¬Å in7 let¬ø bethesetof
allD yÃà distributions) on√≤+√∂ 98 aÃä ¬Ä suchthat) AÃäIÃÇ√êIÃà√§aÃä √Ü OÃÇ¬´) AÃäIÃÇ√êIÃàYÃÅ √Ü OÃÇ3YÃÅ ifIÃÇ isnotcontainedinthe
¬Å
throwof7 ,andforeach¬ÇAÃÅOÃÇ aÃä>IÃàIÃàEÃàAÃÉ AÃäCyÃÅ √Ü,) AÃäIÃÇ IÃà√§aÃä√Ü OÃÇ AÃäaÃä 8¬ö'√ÜAÃäD>EÃàAÃÉ AÃäCyÃÅ √Ü_√Ü and) AÃäIÃÇ IÃà√§OÃàUÃÄaÃä√Ü OÃÇ
AÃäaÃä;: ¬ö√ÜAÃäD>EÃàAÃÉ AÃäCyÃÅ√Ü_√Ü.Let¬ø3OÃÅ1OÃÇ¬è¬ø  √∂ √∂f¬ø.
Notethatfor( OÃÇ AÃä)  IÃà  IÃà;)  √Ü13‚ÅÑ4 ¬ø ,theoptimalerror_ <<  AÃä AÃÄ  √Ü isachievedbyanysequence
 IÃÅ OÃÇ AÃä√±IÃÅIÃàIÃà√±IÃÅ√Ü suchthat√±IÃÅAÃäIÃÇ √Ü OÃÇ√ûaÃä ifandonlyif) AÃäIÃÇ IÃà√§aÃä√Ü OÃÇ AÃäaÃä √ò ¬ö√ÜAÃäD>EÃàAÃÉ AÃäCyÃÅ √Ü_√Ü,andAÃÄ 
always contains such a sequence because AÃÄ shatters 7 . The optimal error is then
_<6<AÃäAÃÄ √ÜOÃÇ AÃÇ?AÃÉAÃäIÃÅ√ÜOÃÇ yÃÅaÃä ') G√±IÃÅAÃäIÃÇ√Ü3OÃÇ$5NÃÉ¬ÄOÃÇ yÃÅaÃä 'yÃà= 
u aÃä1OÃà ¬ö
D>EÃàAÃÉAÃäCyÃÅ√Ü OÃÇ aÃä1OÃàD ¬öIÃà
191


BAXTER
andforany OÃÇ AÃä√± IÃàIÃà√± √Ü 3‚ÅÑ4AÃÅAÃÄ ,
AÃÇ?AÃÉpAÃä'√ÜOÃÇ _<6<AÃäAÃÄ √Ü√ò ¬ö
yÃÅEÃàAÃÉ AÃäCyÃÅ√Ü OÃÉAÃä¬ÅIÃà¬É¬Ç√ÜOÃÅ√± AÃäIÃÇ √Ü3OÃÇ$ √±IÃÅAÃäIÃÇ √Ü¬ÄOÃÉ (77)
For any AÃäCyÃÅ IÃà_√æ √Ü -sample yÃà , let each element √æ in the array
>5AÃäyÃà√ÜOÃÅ1OÃÇ √æ   √æ yÃà?= 
... . . . ...
√æ   √æ yÃà= 
equal the number of occurrences of IÃÇ in yÃà .
Now, if we select ( OÃÇ AÃä)  IÃà  IÃà;)  √Ü uniformly at random from ¬ø , and generate an AÃäCyÃÅ IÃà_√æ √Ü 
sample yÃà using ( , then for  OÃÇA@  AÃä yÃà √Ü (the output of the learning algorithm) we have:
IÃÇ AÃäOÃÉAÃä¬ÅIÃà¬É¬Ç√ÜOÃÅ√± AÃäIÃÇ √Ü2OÃÇ$ √±IÃÅAÃäIÃÇl√Ü¬ÄOÃÉ√ÜOÃÇ CB ) AÃä/> √ÜIÃÇ AÃäOÃÉAÃä¬ÅIÃà¬É¬Ç√ÜOÃÅ√± AÃäIÃÇ √Ü2OÃÇ$ √±IÃÅAÃäIÃÇl√Ü¬ÄOÃÉaOÃÉ> √Ü
OÃÇ B ) AÃä/> √Ü'yÃà= 
u ) AÃä√±AÃäIÃÇ √Ü2OÃÇ$ √±IÃÅAÃäIÃÇ √ÜOÃÉ√æ l√Ü
where ) AÃä/> √Ü is theprobabilityofgenerating aconfiguration > of the IÃÇ underthe AÃäCyÃÅ IÃà_√æ √Ü -sampling
process and the sum is over all possible configurations. From Lemma 30,
) AÃä√±AÃäIÃÇl√Ü2OÃÇ$ √±IÃÅAÃäIÃÇ √ÜOÃÉ√æ √ÜUÃÇ RaÃäEDFaÃä1OÃà'G aÃä¬úOÃà)√≠*1‚ÅÑ2H,n
√©/.,nIJ IÃà
hence
IÃÇ aÃä
yÃÅEÃàAÃÉAÃäCyÃÅ√ÜOÃÉAÃä¬ÅIÃà¬É¬Ç√ÜOÃÅ√± AÃäIÃÇ √Ü3OÃÇ$ √±IÃÅAÃäIÃÇ √Ü¬ÄOÃÉ UÃÇ aÃä
yÃÅEÃàAÃÉAÃäCyÃÅ√ÜB ) AÃä/> √Ü'yÃà?= 
p RaÃä DFaÃä1OÃà G aÃä¬úOÃà)√≠*1‚ÅÑ2H,n
√©/. , n IJ
√¢ RaÃä'&aÃä OÃà ( aÃä1OÃà)√≠ *-,n
=K/MLK√©/.,nL0 (78)
byJensen‚Äôsinequality. Sinceforany IÃÅYÃÅjIÃà√§aÃä}OÃÄ-valuedrandomvariable √º ,K AÃÉGAÃä √º UÃÇ1‚ÅÑ4IÃÇ √Ü √¢YIÃÇ √º OÃà IÃÇ ,(78)
implies: K AÃÉ ¬ñ aÃä
yÃÅEÃàAÃÉAÃäCyÃÅ√ÜOÃÉAÃä¬ÅIÃà¬É¬Ç√ÜOÃÅ√± AÃäIÃÇl√Ü3OÃÇ$ √±IÃÅAÃäIÃÇ √Ü¬ÄOÃÉUÃÇ ¬∑G¬ò UÃÇ AÃäaÃäOÃà ¬∑√ÜG
where G OÃÅ1OÃÇ RaÃäN&aÃä OÃà ( aÃä OÃà)√≠ *-,n
= K/OLK√©/.,nL0 (79)
and¬∑AÃÅ3‚ÅÑ4 IÃÅYÃÅjIÃà√§aÃä}OÃÄ. Pluggingthisinto(77)showsthat
KAÃÉAÃä( IÃàyÃà√ÜOÃÅAÃÇ?AÃÉAÃä@ AÃäyÃà√Ü_√ÜUÃÇ _<6<AÃäAÃÄ √Ü√ò ¬∑G¬öM¬Ä UÃÇ AÃäaÃäOÃà ¬∑√ÜG
192


A MODEL OF INDUCTIVE BIAS LEARNING
Since the inequality holds over the random choice of ( , it must also hold for some specific choice
of ( . Hence for any learning algorithm @  there is some sequence of distributions ( such that
KAÃÉyÃàOÃÅAÃÇ?AÃÉAÃä@ AÃäyÃà√Ü_√ÜUÃÇ _<<AÃäAÃÄ √Ü√ò ¬∑G¬öM¬Ä UÃÇ AÃäaÃäOÃà ¬∑e√ÜG
Setting AÃäaÃä OÃà ¬∑e√ÜG √¢ gIÃà and ¬∑ G ¬ö √¢ 7 IÃà (80)
ensures K AÃÉyÃà OÃÅ AÃÇ?AÃÉ AÃä@ AÃäyÃà√Ü_√Ü UÃÇ _<6< AÃäAÃÄ √Ü √ò 7¬Ä UÃÇ g (81)
Assumingequalityin(80),wegetG OÃÇ aÃä¬úOÃàg ¬∑ IÃà ¬ö OÃÇ g7 aÃä OÃà¬∑ ¬∑ 
Solving (79) for √æ , and substituting the above expressions for G and ¬ö shows that (81) is satisfied
provided √æ!aÃÉ¬òEÃàAÃÉ AÃäCyÃÅ√Ü &¬ñ 7g¬ò √∞ ¬ñ aÃä1OÃà¬∑ ¬∑ ¬ò √∞ OÃà¬òaÃä0 ^_&` AÃäaÃä OÃà ¬∑e√Ü√∞
Tg AÃäaÃä¬úOÃà ¬∑ OÃà¬íDg√Ü (82)
Setting¬∑ OÃÇ aÃä OÃà ¬© g forsome¬© UÃÇ¬´R (¬© UÃÇ¬°R sinceG I√ûaÃä|R andG OÃÇ g  AÃäaÃäUÃÄOÃà ¬∑ √Ü),andassuming
7 IÃàg aÃÉUÃàaÃä AÃäEÃÅ¬©j√Ü forsome UÃÇYD ,(82)becomes
√æ!aÃÉ EÃàAÃÉAÃäCyÃÅ√Ü
¬©√∞ aÃä1OÃà D ^'_&` ¬©√∞
TAÃä¬© OÃà¬íD√Ü (83)
Subject to the constraint ¬© UÃÇOÃÄR , the right hand side of (83) is approximately maximized at ¬© OÃÇ
T QPSR IÃÄ&IÃÄ ,atwhichpointthevalueexceedsEÃà AÃÉ AÃäCyÃÅ √ÜAÃäaÃä¬∞OÃàCDF Q√Ü AÃäD&D>YÃÅ 7 √∞^√Ü.Thus,forall √¢ aÃä,if7 IÃàg aÃÉ
aÃäR and √æ!aÃÉ EÃàAÃÉ AÃäCyÃÅ√ÜaaÃä OÃà  Ãà√∞e
D&D>YÃÅ7√∞ IÃà (84)
then KAÃÉyÃàOÃÅ AÃÇ?AÃÉ AÃä@ AÃäyÃà√Ü_√Ü UÃÇ _<6< AÃäAÃÄ √Ü√ò 7¬Ä UÃÇ g
To obtain the g -dependence in Theorem 14 observe that by assumption AÃÄ  contains at least two
functions√±  IÃà √± √∞ ,hencethereexistsanIÃÇ 3‚ÅÑ4 √≤ suchthat√±  AÃä IÃÇ √Ü3OÃÇ$ √± √∞ AÃä IÃÇ √Ü . Let)UT betwodistributions
concentratedonAÃäIÃÇ√êIÃà√§aÃä√Ü andAÃäIÃÇ√êIÃà√§OÃà{aÃä√Ü suchthat) T AÃäIÃÇ¬ÄIÃà√± AÃäIÃÇ √Ü_√Ü OÃÇ AÃäaÃä 8 7√ÜD and) T AÃäIÃÇ¬ÄIÃà√± √∞AÃäIÃÇ √Ü_√Ü OÃÇ
AÃäaÃä;: 7√ÜD.Let(EÃÇ OÃÅ1OÃÇ9) EÃÇ √∂  √∂b) EÃÇ and( √≠ OÃÅ1OÃÇ-) √≠ √∂  √∂H) √≠ betheproductdistributionson
AÃä√≤ √∂ 98 aÃä¬Ä√Ü generatedby)VT ,and  OÃÅ1OÃÇ AÃä√± IÃàIÃà√± √ÜIÃà √∞ OÃÅ1OÃÇ AÃä√± √∞IÃàIÃà√± √∞√Ü.Notethat  and √∞
are both in AÃÄ  . If ( is one of ( T and the learning algorithm @  chooses the wrong hypothesis  ,
then AÃÇ?AÃÉ AÃä'√ÜOÃà _<6< AÃäAÃÄ √Ü OÃÇ 7
193


BAXTER
Now, if we choose ( uniformly at random from (UÃÄEÃÇ IÃà ( √≠ ¬Ä and generate an AÃäCyÃÅ IÃà_√æ √Ü -sample yÃà ac
cording to ( , Lemma 30 shows that
KAÃÉAÃä( IÃàyÃà√ÜOÃÅ AÃÇ?AÃÉAÃä@ AÃäyÃà√Ü_√Ü√¢ _<<AÃäAÃÄ √Ü√ò 7¬Ä UÃÇ RaÃäN&aÃä1OÃà ( aÃä¬úOÃà)/*XWn
√©/.Wn0 IÃà
whichisatleastg if √æ I aÃä¬úOÃà 7 √∞
7√∞ yÃÅaÃäf^_&` aÃä
TgAÃäaÃärOÃà¬íDg√Ü (85)
provided YÃÅJI g I√¶aÃä|R . Combining the two constraints on √æ : (84) (with OÃÇ P ) and (85), and using
X[ZU IÃÇ IÃà_IÃÇ √∞¬Ä √¢ √∞ AÃäIÃÇ  √òcIÃÇ √∞√Ü finishestheproof.
Appendix D. Measurability
In order for Theorems 2 and 18 to hold in full generality we had to impose a constraint called
‚Äúpermissibility‚Äù on the hypothesis space family AÃÄ . Permissibility was introduced by Pollard (1984)
for ordinary hypothesis classes 1‚ÅÑ2 . His definition is very similar to Dudley‚Äôs ‚Äúimage admissible
Suslin‚Äù (Dudley, 1984). We will be extending this definition to cover hypothesis space families.
Throughout this section we assume all functions √± map from (the complete separable metric
space) √º into IÃÅYÃÅjIÃà√§aÃä}OÃÄ . Let Y AÃä ¬∞√Ü denote the Borel ~ -algebra of any topological space . As in Section
2.2, we view ¬ø , the set of all probability measures on √º , as a topological space by equipping it
with the topology of weak convergence. Y AÃä ¬ø √Ü is then the ~ -algebra generated by this topology. The
following two definitions are taken (with minor modifications) from Pollard (1984).
Definition 8. A set 1‚ÅÑ2 of IÃÅ YÃÅjIÃà√§aÃä}OÃÄ -valued functions on √º is indexed by the set if there exists a function
¬çrOÃÅ√º √∂ √≥√ªIÃÅYÃÅjIÃà√§aÃä}OÃÄsuchthat 1‚ÅÑ2 OÃÇ ¬ç AÃäIÃà_√ß√ÜOÃÅQ√ß 3‚ÅÑ4Z¬ï¬Ä 
Definition 9. The set 1‚ÅÑ2 is permissible if it can be indexed by a set such that
1. is an analytic subset of a Polish7 space , and
2. the function ¬çoOÃÅ √º √∂ √≥ IÃÅYÃÅjIÃà√§aÃä}OÃÄ indexing 1‚ÅÑ2 by is measurable with respect to the product
~
-algebraY AÃä√º¬∞√Ü\[]Y AÃä √Ü.
An analytic subset of a Polish space is simply the continuous image of a Borel subset √≤
of another Polish space √≤ . The analytic subsets of a Polish space include the Borel sets. They
are important because projections of analytic sets are analytic, and can be measured in a complete measure space whereas projections of Borel sets are not necessarily Borel, and hence cannot be measured with a Borel measure. For more details see Dudley (1989), section 13.2.
Lemma31. 1‚ÅÑ2 2| 1‚ÅÑ2  OÃÅ AÃä√≤√∑√∂√¥ √Ü √≥ IÃÅYÃÅjIÃà√§aÃä}OÃÄ ispermissibleif1‚ÅÑ2 IÃàIÃà1‚ÅÑ2  areallpermissible.
Proof. Omitted.
We now define permissibility of hypothesis space families.
7. A topological space is called Polish if it is metrizable such that it is a complete separable metric space.
194


A MODEL OF INDUCTIVE BIAS LEARNING
Definition 10. A hypothesis space family AÃÄ OÃÇ √§1‚ÅÑ2W¬Ä is permissible if there exist sets √° and that
are analytic subsets of Polishspaces √° and respectively, and a function ¬çoOÃÅ √º √∂ √∂ √° √≥ IÃÅYÃÅjIÃà√§aÃä}OÃÄ ,
measurablewithrespectto^_[`Y AÃä¬∞√Ü\[`Y AÃä√° √Ü ,suchthat
AÃÄ OÃÇba¬çAÃäIÃà_√ß}IÃàE√°√ÜOÃÅ√Ø√ß3‚ÅÑ4Z¬ï¬ÄOÃÅ√Ø√° 3‚ÅÑ4 √°dc
Let AÃä √≤IÃàfeoIÃàhg √Ü be a measure space and be an analytic subset of a Polish space. Let @ AÃä √≤ √Ü
denote the analytic subsets of √≤ . The following three facts about analytic sets are taken from
Pollard (1984), appendix C.
(a) IfAÃä√≤¬ÆIÃàfeoIÃàhg √Ü iscompletethen@ AÃä√≤ √ÜA e .
(b) @ AÃä √≤ √∂ ¬∞√Ü containstheproduct~ -algebrae []Y AÃä ¬∞√Ü .
(c) Foranyset√¥ in@ AÃä √≤√∑√∂ √Ü ,theprojectioni √¥ √¥ of√¥ onto√≤ isin@ AÃä √≤ √Ü .
Recall Definition 2 for the definition of AÃÄ4IÃÅ . In the following Lemma we assume that AÃä √º IÃà Y AÃä √º¬∞√Ü_√Ü
has been completed with respect to any probability measure ) , and also that AÃä ¬ønIÃà Y AÃä ¬ø √Ü_√Ü is complete
with respect to the environmental measure AÃÇ .
Lemma 32. For any permissible hypothesis space family AÃÄ ,
1. AÃÄ oÃÉ is permissible.
2. G√±¬Æ3‚ÅÑ4√ü1‚ÅÑ2 OÃÅ 1‚ÅÑ2√û3‚ÅÑ4√óAÃÄf¬Ä ispermissible.
3. 1‚ÅÑ2 is permissible for all 1‚ÅÑ2¬ø3‚ÅÑ4/AÃÄ .
4. 8:#< O and Ãß'1#oO aremeasurableforall1‚ÅÑ2¬ø3‚ÅÑ4/AÃÄ .
5. 1‚ÅÑ2 IÃÅ ismeasurableforall 1‚ÅÑ2√û3‚ÅÑ4/AÃÄ .
6. AÃÄOÃÇIÃÅ is permissible.
Proof. As we have absorbed the loss function into the hypotheses √± , AÃÄ oÃÉ is simply the set of all
yÃÅ
-fold products 1‚ÅÑ2 "¬Ü 1‚ÅÑ2 such that 1‚ÅÑ2 3‚ÅÑ4 AÃÄ . Thus (1) follows from Lemma 31. (2) and (3)
are immediate from the definitions. As 1‚ÅÑ2 is permissible for all 1‚ÅÑ2 3‚ÅÑ4AÃÄ , (4) can be proved by an
identical argument to that used in the ‚ÄúMeasurable Suprema‚Äù section of Pollard (1984), appendix C.
For(5),notethatforanyBorel-measurable √± OÃÅ √º √≥ IÃÅYÃÅjIÃà√§aÃä}OÃÄ,thefunction √± OÃÅ0¬ø √≥ IÃÅYÃÅjIÃà√§aÃä}OÃÄ defined
by √± AÃä ) √Ü OÃÅ1OÃÇkj . √± AÃä √Ü EÃà) AÃä √Ü is Borel measurable Kechris (1995, chapter 17). Now, permissibility of
1‚ÅÑ2
automaticallyimpliespermissibilityof1‚ÅÑ2 OÃÅ1OÃÇ  √± OÃÅ √±/3‚ÅÑ4 1‚ÅÑ2W¬Ä ,and1‚ÅÑ2fIÃÅ OÃÇ  Ãß'1#o O so1‚ÅÑ2fIÃÅ ismeasurable
by (4).
Now let AÃÄ be indexed by ¬çrOÃÅ √º √∂ √∂ √° √≥ IÃÅYÃÅjIÃà√§aÃä}OÃÄ in the appropriate way. To prove (6),
defineOÃÉ OÃÅ√ª¬ø√û√∂ √∂ √° √≥ IÃÅYÃÅjIÃà√§aÃä}OÃÄ byOÃÉ AÃä)1IÃà_√ß}IÃàE√°√Ü OÃÅ1OÃÇlj. ¬ç AÃä IÃà_√ßIÃàE√°√ÜEÃà) AÃä √Ü. ByFubini‚ÄôstheoremOÃÉ isa
Y AÃä¬ø √Ü;[mY AÃä¬∞√Ü;[ Y AÃä√° √Ü-measurablefunction. Let√¢ OÃÅ√ª¬ø √∂ √° √≥ IÃÅYÃÅjIÃà√§aÃä}OÃÄ bedefinedby√¢ AÃä) IÃàE√° √Ü OÃÅ1OÃÇ
 Ãß'1#oon 1‚ÅÑ4qp OÃÉ AÃä )1IÃà_√ß}IÃàE√° √Ü . √¢ indexes AÃÄOÃÇIÃÅ intheappropriateway for AÃÄOÃÇIÃÅ to be permissible, provided it can
be shown that √¢ is Y AÃä ¬ø √Ür[ Y AÃä√° √Ü -measurable. This is where analyticity becomes important. Let
OÃÉ c OÃÅ1OÃÇ  AÃä)1IÃà_√ß}IÃàE√° √Ü OÃÅ OÃÉ AÃä) IÃà_√ßIÃàE√° √Ü UÃÇ G ¬Ä. Byproperty(b)ofanalyticsets,@ AÃä¬ø √∂ √∂ √° √Ü containsOÃÉ c .
Theset√¢ c OÃÅ1OÃÇ  AÃä)1IÃàE√° √Ü OÃÅ √¢ AÃä)1IÃàE√° √Ü UÃÇ G ¬Ä istheprojectionofOÃÉ c onto¬ø √∂ √° ,whichbyproperty(c)is
also analytic. As AÃä ¬ønIÃà Y AÃä ¬ø √Ü IÃàpAÃÇ √Ü is assumed complete, √¢ c is measurable, by property (a). Thus √¢ is
a measurable function and the permissibility of AÃÄ4IÃÅ follows.
195


BAXTER
References
Abu-Mostafa, Y. (1993). A method for learning from hints. In Hanson, S. J., Cowan, J. D., & Giles, C. L. (Eds.), Advances in Neural Information Processing Systems 5, pp. 73‚Äì80 San Mateo, CA. Morgan Kaufmann.
Anthony, M., & Bartlett, P. L. (1999). Neural Network Learning: Theoretical Foundations. Cambridge University Press, Cambridge, UK.
Bartlett, P. L. (1993). Lower bounds on the VC-dimension of multi-layer threshold networks. In Proccedings of the Sixth ACM Conference on Computational Learning Theory, pp. 44‚Äì150 New York. ACM Press. Summary appeared in Neural Computation, 5, no. 3.
Bartlett, P. L. (1998). The sample complexity of pattern classification with neural networks: the size of the weights is more important than the size of the network. IEEE Transactions on Information Theory, 44(2), 525‚Äì536.
Baxter, J. (1995a). Learning Internal Representations. Ph.D. thesis, Department of Mathematics and Statistics, The Flinders University of South Australia. Copy available from
http://wwwsyseng.anu.edu.au/s jon/papers/thesis.ps.gz.
Baxter, J. (1995b). Learning internal representations. In Proceedings of the Eighth International Conference on Computational Learning Theory, pp. 311‚Äì320. ACM Press. Copy available
from http://wwwsyseng.anu.edu.au/s jon/papers/colt95.ps.gz.
Baxter, J. (1997a). A Bayesian/information theoretic model of learning to learn via multiple task sampling. Machine Learning, 28, 7‚Äì40.
Baxter, J. (1997b). The canonical distortion measure for vector quantization and function approximation. In Proceedings of the Fourteenth International Conference on Machine Learning, pp. 39‚Äì47. Morgan Kaufmann.
Baxter, J., & Bartlett, P. L. (1998). The canonical distortion measure in feature space and 1-NN classification. In Advances in Neural Information Processing Systems 10, pp. 245‚Äì251. MIT Press.
Berger, J. O. (1985). Statistical Decision Theory and Bayesian Analysis. Springer-Verlag, New York.
Blumer, A., Ehrenfeucht, A., Haussler, D., & Warmuth, M. K. (1989). Learnability and the vapnikchervonenkis dimension. Journal of the ACM, 36, 929‚Äì965.
Caruana, R. (1997). Multitask learning. Machine Learning, 28, 41‚Äì70.
Devroye, L., Gyo Ãàrfi, L., & Lugosi, G. (1996). A Probabilistic Theory of Pattern Recognition. Springer, New York.
Dudley, R. M. (1984). A Course on Empirical Processes, Vol. 1097 of Lecture Notes in Mathematics, pp. 2‚Äì142. Springer-Verlag.
Dudley, R. M. (1989). Real Analysis and Probability. Wadsworth & Brooks/Cole, California.
196


A MODEL OF INDUCTIVE BIAS LEARNING
Gelman, A., Carlin, J. B., Stern, H. S., & Rubim, D. B. (Eds.). (1995). Bayesian Data Analysis. Chapman and Hall.
Good, I. J. (1980). Some history of the hierarchical Bayesian methodology. In Bernardo, J. M., Groot, M. H. D., Lindley, D. V., & Smith, A. F. M. (Eds.), Bayesian Statistics II. University Press, Valencia.
Haussler, D. (1992). Decision theoretic generalizations of the pac model for neural net and other learning applications. Information and Computation, 100, 78‚Äì150.
Heskes, T. (1998). Solving a huge number of similar tasks: a combination of multi-task learning and a hierarchical Bayesian approach. In Shavlik, J. (Ed.), Proceedings of the 15th International Conference on Machine Learning (ICML ‚Äô98), pp. 233‚Äì241. Morgan Kaufmann.
Intrator, N., & Edelman, S. (1996). How to make a low-dimensional representation suitable for diverse tasks. Connection Science, 8.
Kechris, A. S. (1995). Classical Descriptive Set Theory. Springer-Verlag, New York.
Khan, K., Muggleton, S., & Parson, R. (1998). Repeat learning using predicate invention. In Page, C. D. (Ed.), Proceedings of the 8th International Workshop on Inductive Logic Programming (ILP-98), LNAI 1446, pp. 65‚Äì174. Springer-Verlag.
Langford, J. C. (1999). Staged learning. Tech. rep., CMU, School of Computer Science.
http://www.cs.cmu.edu/s jcl/research/ltol/staged latest.ps.
Mitchell, T. M. (1991). The need for biases in learning generalisations. In Dietterich, T. G., & Shavlik, J. (Eds.), Readings in Machine Learning. Morgan Kaufmann.
Parthasarathy, K. R. (1967). Probabiliity Measures on Metric Spaces. Academic Press, London.
Pollard, D. (1984). Convergence of Stochastic Processes. Springer-Verlag, New York.
Pratt, L. Y. (1992). Discriminability-based transfer between neural networks. In Hanson, S. J., Cowan, J. D., & Giles, C. L. (Eds.), Advances in Neural Information Processing Systems 5, pp. 204‚Äì211. Morgan Kaufmann.
Rendell, L., Seshu, R., & Tcheng, D. (1987). Layered concept learning and dynamically-variable bias management. In Proceedings of the Tenth International Joint Conference on Artificial Intelligence (IJCAI ‚Äô87), pp. 308‚Äì314. IJCAI , Inc.
Ring, M. B. (1995). Continual Learning in Reinforcement Environments. R. Oldenbourg Verlag.
Russell, S. (1989). The Use of Knowledge in Analogy and Induction. Morgan Kaufmann.
Sauer, N. (1972). On the density of families of sets. Journal of Combinatorial Theory A, 13, 145‚Äì168.
Sharkey, N. E., & Sharkey, A. J. C. (1993). Adaptive generalisation and the transfer of knowledge. Artificial Intelligence Review, 7, 313‚Äì328.
197


BAXTER
Silver, D. L., & Mercer, R. E. (1996). The parallel transfer of task knowledge using dynamic learning rates based on a measure of relatedness. Connection Science, 8, 277‚Äì294.
Singh, S. (1992). Transfer of learning by composing solutions of elemental sequential tasks. Machine Learning, 8, 323‚Äì339.
Slud, E. (1977). Distribution inequalities for the binomial law. Annals of Probability, 4, 404‚Äì412.
Suddarth, S. C., & Holden, A. D. C. (1991). Symolic-neural systems and the use of hints in developing complex systems. International Journal of Man-Machine Studies, 35, 291‚Äì311.
Suddarth, S. C., & Kergosien, Y. L. (1990). Rule-injection hints as a means of improving network performance and learning time. In Proceedings of the EURASIP Workshop on Neural Networks Portugal. EURASIP.
Sutton, R. (1992). Adapting bias by gradient descent: An incremental version of delta-bar-delta. In Proceedings of the Tenth National Conference on Artificial Intelligence, pp. 171‚Äì176. MIT Press.
Tate, R. F. (1953). On a double inequality of the normal distribution. Annals of Mathematical Statistics, 24, 132‚Äì134.
Thrun, S. (1996). Is learning the n-th thing any easier than learning the first?. In Advances in Neural Information Processing Systems 8, pp. 640‚Äì646. MIT Press.
Thrun, S., & Mitchell, T. M. (1995). Learning one more thing. In Proceedings of the International Joint Conference on Artificial Intelligence, pp. 1217‚Äì1223. Morgan Kaufmann.
Thrun, S., & O‚ÄôSullivan, J. (1996). Discovering structure in multiple learning tasks: The TC algorithm. In Saitta, L. (Ed.), Proceedings of the 13th International Conference on Machine Learning (ICML ‚Äô96), pp. 489‚Äì497. Morgen Kaufmann.
Thrun, S., & Pratt, L. (Eds.). (1997). Learning to Learn. Kluwer Academic.
Thrun, S., & Schwartz, A. (1995). Finding structure in reinforcement learning. In Tesauro, G., Touretzky, D., & Leen, T. (Eds.), Advances in Neural Information Processing Systems, Vol. 7, pp. 385‚Äì392. MIT Press.
Utgoff, P. E. (1986). Shift of bias for inductive concept learning. In Machine Learning: An Artificial Intelligence Approach, pp. 107‚Äì147. Morgan Kaufmann.
Valiant, L. G. (1984). A theory of the learnable. Comm. ACM, 27, 1134‚Äì1142.
Vapnik, V. N. (1982). Estimation of Dependences Based on Empirical Data. Springer-Verlag, New York.
Vapnik, V. N. (1996). The Nature of Statistical Learning Theory. Springer Verlag, New York.
198