Machine Learning for Catalysis Informatics: Recent Applications and Prospects
Takashi Toyao,†,‡ Zen Maeno,† Satoru Takakusagi,† Takashi Kamachi,‡,§ Ichigaku Takigawa,*,∥,⊥
and Ken-ichi Shimizu*,†,‡
†Institute for Catalysis, Hokkaido University, N-21, W-10, Sapporo 001-0021, Japan
‡Elements Strategy Initiative for Catalysts and Batteries, Kyoto University, Katsura, Kyoto 615-8520, Japan
§Department of Life, Environment and Materials Science, Fukuoka Institute of Technology, 3-30-1Wajiro-Higashi, Higashi-ku, Fukuoka 811-0295, Japan
∥RIKEN Center for Advanced Intelligence Project, 1-4-1 Nihonbashi, Chuo-ku, Tokyo 103-0027, Japan
⊥Institute for Chemical Reaction Design and Discovery (WPI-ICReDD), Hokkaido University, Kita 21 Nishi 10, Kita-ku, Sapporo, Hokkaido 001-0021, Japan
ABSTRACT: The discovery and development of catalysts and catalytic processes are essential components to maintaining an ecological balance in the future. Recent revolutions made in data science could have a great impact on traditional catalysis research in both industry and academia and could accelerate the development of catalysts. Machine learning (ML), a subfield of data science, can play a central role in this paradigm shift away from the use of traditional approaches. In this review, we present a user’s guide for ML that we believe will be helpful for scientists performing research in the field of catalysis and summarize recent progress that has been made in utilizing ML to create homogeneous and heterogeneous catalysts. The focus of the review is on the design, synthesis, and characterization of catalytic materials/compounds as well as their applications to catalyzed processes. The ML technique not only enhances ways to discover catalysts but also serves as a powerful tool to establish a deeper understanding of relationships between the properties of materials/compounds and their catalytic activities, selectivities, and stabilities. This knowledge facilitates the establishment of principles employed to design catalysts and to enhance their efficiencies. Despite such advantages of ML, it is noteworthly that the current ML-assisted development of real catalysts remains in its infancy, mainly because of the complexity of catalysis associated with the fact that catalysis is a timedependent dynamic event. In this review, we discuss how seamless integration of experiment, theory, and data science can be used to accelerate catalyst development and to guide future studies aimed at applications that will impact society’s need to produce energy, materials, and chemicals. Moreover, the limitations and difficulties of ML in catalysis research originating from the complex nature of catalysis are discussed in order to make the catalysis community aware of challenges that need to be addressed for effective and practical use of ML in the field.
KEYWORDS: machine learning, catalysis informatics, high-throughput experiments/computations, data mining, structure−activity relationships
1. INTRODUCTION
Catalysis is a complex, multidimensional, dynamic, and
multiscale method for promoting chemical reactions.1 In particular, heterogeneous catalysis is still a largely empirical science because of the complexity of the surface chemistry
involved.1−3 As depicted in Figure 1, wide length and time scale ranges need to be considered in order to fully understand the dynamic nature of catalytic reactions. Recent experimental and theoretical studies have yielded atomic-level insight into
these processes.4−7 Nevertheless, the discovery of truly novel catalysts and catalytic reactions is still a formidable task, and as a result, many of the advances in this area have arisen from trial-and-error investigations. This empirical approach has uncovered numerous multicomponent catalysts that operate
under a variety of conditions.8,9 Also, fundamental kinetic, characterization, and theoretical studies have been carried out to develop preparation−structure relationships or structure− performance relationships, which are useful in guiding
hypothesis-driven designs of new catalysts.10−12 For example, to create structure−performance relationships, catalyst performance (vertical axis) is plotted as a function of key structural factors (horizontal axis) in order to uncover important features of catalysts that affect their activities, selectivities, and/or stabilities. Unfortunately, the enormous
Received: September 28, 2019 Revised: December 8, 2019 Published: December 16, 2019
Review
pubs.acs.org/acscatalysis
Cite This: ACS Catal. 2020, 10, 2260−2297
© 2019 American Chemical Society 2260 DOI: 10.1021/acscatal.9b04186 ACS Catal. 2020, 10, 2260−2297
Downloaded via UNIV OF MASSACHUSETTS AMHERST on March 21, 2024 at 16:34:16 (UTC).
See https://pubs.acs.org/sharingguidelines for options on how to legitimately share published articles.


amount of experimental data gathered in the study of catalyst preparation−structure−performance relationships have not yet been integrated into readily searchable databases. Although recent advances in theoretical and computational chemistry have enabled descriptions of elementary steps in catalytic processes that have already been discovered, for the most part
they have not focused on strategies to design new catalysts.13 Therefore, the enormous amount of experimental and theoretical data accumulated to date on various aspects of catalysis are not that useful in predicting new catalysts or catalytic reactions. Scaling the relationship between calculated reaction barriers and binding energies of surface intermediates is a promising method employed in data-intensive catalyst
design.13−15 Several studies have demonstrated how this approach can contribute to the design of novel catalysts based on predicted volcano trends in catalytic activity versus
binding energies of surface intermediates.14 However, the accuracy of these models in predicting catalytic performance is limited because of the large number of other factors involved. Consequently, more effective relationships (descriptors) that can be employed to analyze these processes must be devised in order to develop more effective strategies to design novel catalysts for important reactions. Molecular/materials informatics has become a central
paradigm in molecular and materials science.16−29 In the
data-intensive materials design (so-called inverse design)23,24 protocol, the desired function of a new material is identified first, and then a candidate is extracted from a computational or experimental database using machine learning (ML) methods. This new methodology, which is an improved version of “quantitative structure−property relationship (QSPR) model
ing of materials properties”,30 has been shown to be a powerful tool for predicting the properties of substances, including those of unknown molecules/materials. Recent success in utilizing this approach is exemplified by the ML-assisted prediction of physical properties of molecules/materials such as atom
ization31,32 and formation energies,33−35 densities of states,36
band gaps,37−39 vibrational free energies,40 and melting
temperatures.41 Therefore, if a single physical property is dominant in governing the performance of a material, molecular/materials informatics serves as an ideal tool to identify a novel functional material. However, catalyst design does not fit into this category because theoretical models for catalysis, especially heterogeneous catalysis, are not available at this time. In contrast to those involving physical properties, ML-assisted predictions of rates and selectivities of catalytic
reactions are still in their infancy.42 Despite having a 30 year history, the use of artificial intelligence (AI) for catalyst
design43−46 has had only a small impact on the discovery of effective homogeneous or heterogeneous catalysts prepared according to insight from data-intensive methodology. The main barriers to employing data-intensive methods for catalyst design are the lack of universal data sets for catalytic activities and selectivities and the existence of only a few descriptors. In this review, we summarize the current state of investigations aimed at the ML-guided development of homogeneous and heterogeneous catalysts. Recent excellent
reviews42,47−52 have described research studies of ML in
catalysis,49 pioneering investigations of ML-assisted identi
fication of catalysts,46,53 predictions of catalytic properties by the use of density functional theory (DFT) calculations along
with scaling relationships,13−15 and catalysis informatics.47,48 In contrast to others, this comprehensive review covers studies of ML-assisted theoretical and experimental investigations of computer-aided catalyst design that have been reported in the past decade, with a major focus on illustrating how ML, in combination with DFT and experimental data, can be used to identify ideal catalysts. The limitations and difficulties of ML in catalysis research originating from the complex nature of catalysis are also discussed. The review begins with a tutorial overview of applications of ML in catalysis science (section 2). This is followed by a discussion of representative studies in which high-throughput computation and ML have been utilized to design inorganic catalysts such as alloys, complex metal oxides, zeolites, and inorganic−organic hybrid materials (section 3). Representative studies focusing on highthroughput computation to uncover important catalyst properties, including d-band centers, oxygen vacancy formation energies (EOvac), and surface adsorption energies of molecules and atoms, are covered in section 4. A review of ML approaches to predict these functions is given in section 5. These efforts are highly important because describing catalysis as a function of a physical parameter would be necessary for fast and efficient catalyst discovery. Illustrations of the application of ML techniques to the characterization of heterogeneous catalysts are provided in section 6. This would enable more accurate and rapid characterization of the catalysts, and eventually, automated control of these processes in catalysis research would be possible. The discussion in sections 7 and 8 focuses on ML treatments of experimental data aimed at designing new heterogeneous and homogeneous catalysts, respectively. Finally, a summary of the efforts
Figure 1. Description of heterogeneous catalysis from the atomic level to large-scale reactors.
ACS Catalysis Review
DOI: 10.1021/acscatal.9b04186 ACS Catal. 2020, 10, 2260−2297
2261


discussed in the review and future perspectives in the area of ML-guided catalyst development (Figure 2) are given in section 9.
2. A GUIDE TO USING MACHINE LEARNING IN CATALYSIS RESEARCH
ML is an interdisciplinary field of study that concentrates on developing computer algorithms that enable learning from data without being explicitly programmed. ML emerged primarily from the fields of computer science and statistical science, but it now encompasses a broad range of disciplines. The landscape of ML is briefly given Figure 3 in the form of typical ML problems along with some common methods of
supervised and unsupervised learning. The details of each algorithm are covered in many excellent existing reviews.16,51 Thus, rather than just rephrasing these explanations, in this section we highlight from a user perspective the essentials, practices, and pitfalls of using ML in natural sciences and specifically for catalyst development. Particular emphasis will be given to supervised learning, which is the most common setting used not only in catalysis studies but also in other ML applications such as image and speech recognition, machine translation, and medical diagnosis. In supervised learning, a function that maps an input to the desired output is built without explicit modeling by providing many examples of input−output pairs (called
Figure 2. Schematic representation of ML-aided future catalysis research.
Figure 3. ML landscape in the context of a brief overview of machine learning tasks and algorithms.
ACS Catalysis Review
DOI: 10.1021/acscatal.9b04186 ACS Catal. 2020, 10, 2260−2297
2262


training data), and the obtained mapping function is used to make a prediction (an output) for any possible input. One of the main interests of catalysis science is often to gain a better understanding of unclear relationships between inputs (e.g., the properties, compositions, and structures of catalysts) and outputs (e.g., their activities, selectivities, and stabilities). Unfortunately, it is not yet feasible to have an explicit theoretical model that can perfectly describe such complicated relationships. Instead, by the use of supervised learning, an inferred relationship between the inputs and outputs can be learned from given examples without explicitly knowing the underlying principles. As a result, ML can serve as an important tool to investigate and predict phenomena that are difficult to explicitly model mathematically. This can open up a new direction for scientific research on highly complex phenomena with many uncertain intertwined factors, where traditional trial-and-error styles are already reaching the limit.
However, to maximize the capabilities of this new technology, we need to have a careful understanding of what ML-acquired mapping means, what grounds are utilized to obtain a prediction or insight, and what types of results can be misleading and force us to conclude nonexistent cause-andeffect relationships.
2.1. “Data-Driven”: The Quality and Quantity of Data Matter Most. The principle that underpins all of the ML algorithms listed in Figure 3 is that ML is data-driven, which means that ML models are defined only by feeding a given data set (training data) into them. ML prediction models are representative of such given training data. Thus, the quality and quantity of “data” are essential prerequisites to elevate the predictive capability of ML independent of whether a state-ofthe-art or simple ML algorithm is utilized. Realizing that data is more important than algorithms is the first step for building any ML application, and the fact that accurate ML is
Figure 4. Caution of ‘‘garbage in, garbage out’’ in ML studies (section 2.1). Because ML is data-driven, the quality and quantity of data are essential prerequisites for every ML study. Establishing sufficient data quality and quantity should always be prioritized over what ML algorithm is used. If input data are of low quality, flawed, or nonsense, any ML model produces nonsense output or “garbage”.
Figure 5. Theory-driven and data-driven approaches for scientific research. Theory-driven methods try to explicitly model the inner workings of a target phenomenon (e.g., through first-principles simulations), while data-driven methods try to precisely approximate its outer behavior observable as data (section 2.2).
ACS Catalysis Review
DOI: 10.1021/acscatal.9b04186 ACS Catal. 2020, 10, 2260−2297
2263


impossible with inaccurate data is often described as “garbage in, garbage out” (Figure 4). The first questions in every ML-based study would be what types of and how much data ML requires. The most typical form of data is tabular data (e.g., a spreadsheet), where each row has numeric and non-numeric records of variables (columns) from experimental observations, theoretical calculations, and existing databases. However, as this paper showcases existing studies in subsequent sections, diverse types of data are now used in ML-based studies, including time series, images, sensor signals, texts, and structure data such as chemical formulas, steric configurations, three-dimensional (3D) point clouds, and atom mappings. These forms define the information contents that ML can use for predictions, and thus, any forms of data should be used if they characterize the targets under study well. The size of the data set is another major concern in ML-based studies, and it determines the confidence or reliability of ML predictions. Technically, ML can be applied to any small-sized data set, but the prediction made from such a small data set would be less confident and reliable in a statistical sense. Considering the use of any existing data sets can help when the available data sets are very limited.
2.2. Data-Driven and Theory-Driven Approaches. The data-driven principle should also be contrasted with theorydriven (or hypothesis-driven) methods (Figure 5), which are most often used in traditional sciences. Theory-driven and data-driven methods are based on very different principles. Theory-driven methods try to explicitly model the inner workings of a target phenomenon (e.g., through first-principles simulations), while data-driven methods try to precisely approximate its outer behavior observable as data. These two are quite complementary, and data-driven approaches can complement limitations of theory-driven ones such as high computing costs, target/condition/parameter considerations, scalability issues, complexity and uncertainty of real-world systems, and known and unknown imperfections of currently available theories. The exact origins of scientific phenomena are often unknown. As a result, studies aimed at identifying cause-and
effect relationships conventionally start with a hypothesis or theory that arises from past observations and intuition. Then data from carefully designed experiments or computer simulations are collected to determine whether they are in accord with the proposed hypothesis or theory. The theorydriven approach has been employed in the field of catalysis to gain significant insight and an atomic-level understanding of how catalysts operate. In contrast, in the data-driven approach, an existing data set is subjected to an unfixed mathematical function (the ML model) that includes various tuning parameters targeted to produce the desired outcome. Data are used to train the ML model so that the model can produce the defined outcome. Hence, the data-driven approach does not encode domain-specific information, and as a result, it is not cognizant of the underlying phenomenon before ML training begins. Since data are always in accord with the model after the ML training, it is generally hard to confidently assess whether an ML model is valid. The well-known statistician David Hand stated the following in his keynote talk at the ACM SIGKDD Conference on
Knowledge Discovery and Data Mining (KDD ’18):54 “Theory-driven models can be wrong but data-driven models cannot be wrong or right. Data-driven models are not trying to describe an underlying reality but are merely intended to be useful. So, they could be poor or useless, but not wrong.” Fitting ML models to data is purely based on input−output correlations, which do not imply causation. Training data points are finite, and a limitless number of possible mappings having the same goodness of fit can potentially exist. It is even possible to deliberately choose a mapping that is consistent with an expected outcome but is merely subjective and lacks any rational basis. It requires considerable attention to avoid a hypothesizing after the results are known (“HARKing”) conclusion. As David Hand also stated, “If data can speak for themselves, they can also lie for themselves. So, it’s critically important to exercise caution, do not claim too much, understand the data and its quality.”
2.3. Supervised Learning and an Example Workflow. By analysis of training data, supervised learning identifies a target function that best maps input variables X to the desired
Figure 6. (top) Supervised learning (section 2.3). Supervised learning acquires a function mapping inputs to outputs that can be fitted to the training data by using tuning parameters. (bottom) The bias−variance trade-off (section 2.5). Highly complex models often cause overfitting, whereas models that are too simple can cause underfitting.
ACS Catalysis Review
DOI: 10.1021/acscatal.9b04186 ACS Catal. 2020, 10, 2260−2297
2264


output variable Y (Figure 6). The training data consist of many sample input−output pairs, and the trained ML model corresponds to a function that fits the data to reproduce the given input−output pairs. Because the number of input variables can be large, X can be high-dimensional, and thus, the fitting process can be technically nontrivial. For example, supervised learning can be used to create a computer program that recognizes handwritten characters without explicitly knowing any underlying principles. In contrast, it is exceedingly difficult to explicitly program the recognition process to use visual images of handwritten characters (the input) to determine what characters the images represent (the output). When a process that is hard to model explicitly is encountered but a good set of corresponding input−output examples can be collected, it is always worth considering using the supervised learning approach. However, it also should be emphasized that high prediction performance currently available for the handwritten character recognition does not directly mean that we could understand any underlying mechanism by which our brain recognizes characters. It should be noted that the supervised learning setup arises in many subfields of computer science and statistics, where many synonyms are used, including where an input variable is called a feature, descriptor, attribute, independent variable, predictor variable, explanatory variable, or covariate and an output variable is called a dependent, response, or outcome variable. As presented in an excellent publication by Pedro
Domingos,55 the general framework of ML can be understood in terms of “Learning = Representation + Evaluation + Optimization”. The wide variety of ML methods displayed in Figure 3 stem from differences in these three factors. The aspect of representation is about the choice of an ML model function that is tunable by using parameters, where “tunable” means that the shape of the function is changed in various forms by changing the values of the parameters. For example, if we assume a linear input−output relationship, we can use Y = f(X1, ···, Xp) = θ0 + θ1X1 + ... + θpXp with p + 1 parameters (θ0,
···, θp) for a p-dimensional input of X = (X1, ···, Xp). By changes
in the values of the parameters θ0, ..., θp, the function f can represent any hyperplane in the p-dimensional space, but it cannot represent nonlinear hypersurfaces. Moreover, it requires a strong assumption that the input−output mapping
is linear, meaning that Y needs to be a weighted sum of each input variable (no interaction effect is considered). As portrayed in Figure 6, a model with appropriate complexity depending on the given data needs to be chosen or designed. The differences among several ML algorithms in terms of decision boundaries for binary classification in two dimensions are displayed in Figure 7. An intuitive understanding of how each parameter affects the decision boundaries can be gained by viewing an interactive demo dealing with neural networks at https://playground.tensorflow.org/. The aspect of evaluation is about the choice of criteria for a goodness-of-fit test of the chosen ML model function. For example, linear regression analysis usually minimizes the leastsquares error between Y and f(X), but when Y is binary (e.g., −1 or +1), the use of the squared error is not appropriate, and logistic regression is used instead. Lastly, the aspect of optimization is about the choice of a tuning algorithm (the optimization algorithm) that optimizes the evaluation criteria for fitting the ML model function to the given data. For example, in the cases of least-squares regression or several kernel methods, optimal parameters can be obtained in a closed form by using a matrix calculation, but for general ML models such as neural networks, incremental parameter updating with random initialization is often used. Although recent advances made in the development of opensource software such as scikit-learn and tensorflow have provided ready access to numerous high-quality ML methods, nonexperts would still be uncertain about what method to choose from a long list of available algorithms. Below we provide an outline of a typical workflow, practices, and
checkpoints from a user’s viewpoint. Another publication56 gives further details on best practices.
A. Problem and Variable Design. First, the problem under study needs to be defined in an input−output format. Thus, the first but crucial step is to identify or devise a set of relevant input variables that characterize the output variables well (or fully). Traditionally, a small number of dominant factors as input variables is preferred, but this is not a requirement when modern ML is used. Thousands or even millions of potentially related factors beyond human capability can be considered as long as they are observable. For example, each pixel value of an image can be employed as an input variable, and in this case,
Figure 7. Differences in commonly used algorithms for supervised learning (section 2.3). Decision boundaries of each algorithm for classifying the red and blue points in the leftmost plots are visualized. For exactly the same training sets (i.e., the three problems at the far left), each algorithm forms very different decision boundaries (from different inductive biases) to interpolate the interspace for generalization beyond the given training samples.
ACS Catalysis Review
DOI: 10.1021/acscatal.9b04186 ACS Catal. 2020, 10, 2260−2297
2265


10 000 input variables would be considered for an image of 100 × 100 pixels. This approach has not been a common practice in conventional statistics, and regression using many variables has not been recommended. It is often called “kitchen sink regression” because of its high risk of overfitting and capturing spurious correlations. At the current time, we can consider a large number of input variables by using many modern ML methods that can handle extremely high dimensional data with appropriate control of the model complexity. This would bring a practical advantage because if any primary factor is missed, the prediction can suffer from socalled omitted variable bias and potentially yield a spurious correlation. However, it also should be noted that inclusion of unnecessarily many irrelevant factors can deteriorate the prediction capability even for state-of-the-art ML methods such as deep learning.
B. Data Collection, Sanity Check, and Exploratory Data Analysis. ML is purely data-driven, and consequently, the quality and quantity of data are the key determining factors for success. Because ML prediction models are representative of the given training examples, it is crucial that the training data be representative of actual situations we want to treat. However, it is extremely difficult in general to guarantee this natural requirement since truly desirable data are not yet obtained and are literally “unseen”. Collecting available data can often be plagued by unintentional “selection bias” because any collectable data can be easily and strongly biased toward targets that were successful in the past or that are merely easily testable. Furthermore, indiscriminate data collection can be plagued by errors, outliers, and noise. Thus, preliminary exploratory data analysis (EDA) and a sanity check of the training data are always required. EDA is often conducted by investigating data distributions and outliers via descriptive statistics and visualizations such as a histogram, correlation matrix or correlogram, box plot, and various projection methods to two or three dimensions.
C. Data Cleaning and Preprocessing. When a sufficiently large training data set is collected, cleaning and preprocessing are often required. Specifically, one needs to reformat individual data into a single tabular form, remove or correct erroneous or incomparable data points, impute missing values, and normalize and rescale the data in order to stabilize the numerical computation. The outcomes of several ML algorithms such as kernel methods and neural networks can differ according to whether any normalization, standardization, or scaling is performed. It should also be noted that not only input variables but also output variables can be normalized or scaled.
D. Feature Engineering and Selection. The selection of optimal input variables is a formidable step. ML is often used because the underlying principle is so unclear that it cannot be subjected to explicit programming, particularly in the case of scientific data. Also, in many cases it is not certain what the determining factors are. Thus, in practice it is necessary to utilize engineering steps in order to derive new input variables, which then need to be modified, replaced, and combined in a human-understandable manner. In particular, crosstalk between two variables A and B can be taken it into account by adding the product, A × B, as an interaction variable (more generally, polynomial features). Further analysis of cases where ML fails to predict correctly can provide new insight into features that should be added. In more advanced cases, called stacking or stacked generalization, ML outputs can be reused as
new input variables (meta features). For example, out-ofsample prediction values, principal component values, clustering results, and hierarchical features from deep learning models can be used.
E. Choosing, Applying, and Customizing ML Algorithms. After a training set is properly designed and set up, several ML algorithms are applied and evaluated.
• Performance Evaluation Measure (or “Loss Function”). First, an appropriate evaluation measure needs to be selected. Typical choices are the prediction accuracy, F1 score, or area under the receiver operating characteristic curve (ROC-AUC) score for classification tasks and the mean absolute error (MAE), mean square error (MSE), root-mean-square error (RMSE) and rootmean-square logarithmic error (RMSLE) for regression tasks. Special cases like those with imbalanced classes (e.g., 0.1% positive, 99.9% negative) can be properly handled by customizing the evaluation measure (e.g., class-weighted loss or focal loss). Another example is a case with outliers handled by a robust loss function (e.g., Huber loss).
• Preparation of Validation and Test Data: Also, establishing reliable validation strategies for estimating the prediction performance is quite important (but notoriously difficult in general). Standard options are to use cross-validation or to split the data into training, validation, and test sets in order to evaluate a prediction in an out-of-sample way. By definition, the training data cannot be used for model evaluation. Thus, the validation set is utilized to evaluate the hyperparameter tuning, while the test set is used to evaluate the prediction performance. When cross-validation is employed, each subpart of the data needs to be further split into training and validation sets (or perform nested cross-validation, often called double cross-validation), being careful not to have data leakage from the training set into the validation or test set. We will discuss this point more in section 2.4.
• Constant Prediction: Next, a constant prediction model can be applied to obtain a worst-case baseline for the given evaluation measure. For example, scikit-learn contains DummyClassifier and DummyRegressor for this purpose. For regression tasks, the mean target value in the training data set is often used as the constant. R2 scores are relative measures using the MSE against this basic reference. For classification tasks, the most frequent class label is commonly used.
• Linear Prediction: Subsequently, a linear prediction is applied. A common choice is logistic regression for classification tasks and linear regression for regression tasks. Linear prediction causes underfitting when the input−output relationship is not linear, but in many practical cases it can produce quite stable predictions with a sufficient level of performance. It should also be noted that even simple log scaling of the variables breaks linearity. Furthermore, when interaction variables are introduced into the model, linear prediction leads to (partially) polynomial classification or regression considering an interaction effect. When the number of variables is large (in particular, larger than that of training examples), linear regression can be noncomputable or unstable without any regularization
ACS Catalysis Review
DOI: 10.1021/acscatal.9b04186 ACS Catal. 2020, 10, 2260−2297
2266


because of matrix noninvertibility. In this case, a regularized linear regression technique such as LASSO or ridge regression should be used instead. LASSO and ridge regression for regression tasks correspond to L1penalized and L2-penalized linear regression, respectively. Similarly, logistic regression for classification tasks is also commonly used with L1- and L2-penalized regularization (e.g., LogisticRegression in scikit-learn has these options). Other common options in chemoinformatics are partial least-squares (PLS) regression and principal component analysis (PCA) regression, which are linear regression with supervised or unsupervised dimensionality reduction by linear coordinate transformation, respectively.
• First-Choice Nonlinear Prediction: After performing constant and linear predictions, we can test nonlinear predictions. The recommended first choices for this purpose are random forest or extra trees (and possibly knearest neighbors for classification) because both are less hyperparameter-dependent and the critical parameter is often only the number of trees (or k for k-nearest neighbors). For relatively large data sets, the use of extra trees is preferred because it usually exhibits a comparable and sometimes better performance and it requires much less computation time.
• More Complex Nonlinear Prediction: When nonlinear predictions perform better than linear predictions, we can move on to more complicated models such as kernel methods, neural networks, and gradient boosted trees (GBDT/GBRT, including XGBoost and LightGBM). However, these methods are sensitive to hyperparameter tuning and can display significantly worse performance if the hyperparameters are incorrectly set. The best practice is to use systematic hyperparameter tuning based on a grid or a random or more advanced search method (e.g., model-based optimization such as Bayesian optimization, multiarmed bandits, genetic algorithms (GAs), and any AutoML pipelines). We will discuss this point in more detail in section 2.5.
• Deep Learning Applicability: In cases where large data sets of direct measurements such as images, videos, and sensor signals are available, deep neural network (DNN) (i.e., deep learning) models can often perform significantly better than other methods. They can also learn a series of nonlinear feature transformations to convert the inputs to representations that are easier to predict. In particular, for image observations (e.g., arising from microscopy), convolutional network (CNN) methods such as VGG, ResNet, and DenseNet are widely used. Nowadays, many CNN models that are pretrained on quite large data sets of natural images (e.g., the ImageNet database) are available. These pretrained CNN models can be used as handy feature extractors for any natural images (through a series of convolution filter banks). Futhermore, f ine-tuning of these models by reusing the pretrained weights for initialization or remodeling can improve the prediction performance even when only a small number of image observations are available for a given task. • Bespoke ML Models: For many practical cases, it is sufficient to select an off-the-shelf ML method from the available list. However, consideration needs to be given to specific constraints, including imbalanced/skewed
data, missing data, real-time processing, domain adaptations, and dependencies arising from time series or structural variable correlations. When this is the case, a customized or newly developed method is required to meet each specific requirement.
F. Analysis of the Trained ML Models. The main use of trained ML models is to make predictions for the target problem, but they can also provide much additional information. The trained ML models represent possible approximations of the unknown input−output relationship under study. Thus, extracting information on how strongly each variable or each sample contributes to the prediction is quite helpful to gain a better understanding of the problem. Popular methods for this purpose include significance tests on regression coefficients, decision rules extraction, variable importance scores from PLS regression (known as VIP analysis in chemoinformatics), feature importance scores from tree ensemble methods such as random forests, partial dependency plots (such as the sklearn.inspection module of scikit-learn), (global) sensitivity analysis methods, and feature visualization methods for DNNs (such as saliency maps and gradient-based methods such as GradCAM, DeepLift, and SHAP). However, it is noteworthly that forcibly projecting multivariate trends into independent univariate contributions of individual features always entails information loss because of the correlation between features. These “interpretability” or “explainability” aspects of ML algorithms have been a recent hot topic among ML reseachers. For another example, investigating hard-topredict examples in detail would also give some insights into the problem design under study and the input variable design and engineering steps.
G. Evaluating and Maintaining Predictions. Following the attainment of ML predictions, a further engineering effort is sometimes needed to carefully check whether the prediction works in the intended manner. Unfortunately, this step is not simple because ML procedures depend not only on the algorithm but also on the data and possibly random numbers for model initialization. Traditional software engineering techniques are often useless for ML-based software development because of its data and parameter dependencies. Here we need not only code versioning but also proper data versioning. Moreover, in these cases debugging, testing, and requirement definition are often more troublesome, and some data treatments also require data infrastructure and management along with iterative system deployment and maintenance.
2.4. Data Leakage and Data Dredging. The only trustworthy way to estimate the prediction performance of the trained ML model is to test it using completely unseen external data derived from actual situations. In many cases, however, acquiring a completely new data set in a real-world context is costly from both a time and money perspective. Thus, some strategy is required for simulating “unseen” data to test the ML prediction by using available data at hand. A simple approach is to set aside a portion of the data set for model validation and testing by a three-way split of the data into training, validation, and test sets. When the data set is not large, the most standard practice is to use k-fold or leave-k-out cross-validation or repeated random subsampling. However, since the test data are taken from a portion of the already obtained data, the estimated performance can some
times be overly optimistic as a consequence of data leakage,57 which can occur when information on the test set leaks into
ACS Catalysis Review
DOI: 10.1021/acscatal.9b04186 ACS Catal. 2020, 10, 2260−2297
2267


the training or validation sets in a complicated and unintended way. For example, hyperparameter tuning based on the performance for test data can easily cause data leakage. In practice, test data are finite, and as a result, we can even overfit the ML model to the given test data by tweaking the hyperparameters. In this case, the ML prediction exhibits “too good” performance, but in fact it has no real effect. This kind of misuse is often called data dredging. In cases caused by accidents, normalizing or preprocessing the entire data set before splitting can also cause small data leakage. Because data leakage can occur unintentionally, it should always be kept in mind for assuring scientific reproducibility.
2.5. Bias−Variance Trade-Off and Hyperparameter Tuning. An ML model that perfectly predicts the given training data (with zero training error) is seemingly preferable. However, real-world data usually contain irreducible errors that arise from random noise factors or deterministic unpredictability due to the practical impossibility of perfectly sensing all relevant information. ML is not able to precisely predict trends arising from completely random noise. Thus, learning every little detail of the training data can often result in inaccurate prediction for unseen data. In practice, a trade-off between two sources of error, termed the bias−variance trade-of f, should be carefully considered for ML models to make generalizations beyond the training data. Bias is the difference between the prediction of an ML model and the ground-truth value to be predicted for every given training set. A high-bias ML model often cannot capture the
underlying trends and causes underfitting because it contains small degrees of freedom. Variance is the expected variability of the model prediction. A high-variance ML model often has a large degree of freedom and, as a result, it captures every detail of the training data, which then causes overfitting arising from high sensitivity and variability. What is needed is a “just right” model that balances trade-off between high-bias and highvariance models (cf. Figure 6). Complicated nonlinear ML models such as DNNs can sometimes have millions or even billions of parameters (i.e., a tremendously large number of degrees of freedom). As a result, a limitless number of parameter settings exist that have the same goodness of fit to the finite data. In these cases, independent of its size, the training data alone are not sufficient to properly train a given ML model. To remedy this situation, the number of degrees of freedom of the model (i.e., the model complexity) must be restricted by using some inductive bias. Since “unseen” data can take arbitrary values without any additional assumptions, all supervised learning strategies rely on some inductive bias implicitly or explicitly. For example, a penalty can be placed on overly complex models, a perturbation can be applied to stabilize too-variable fitting, or the size of the model components can be explicitly limited, for example, by restricting the number of units and layers in neural networks or the maximum depth (or the number of leaf nodes) of decision trees. This process, termed regularization, is often controlled by using hyperparameter tuning. The hyperpara
Figure 8. Example of the bias−variance trade-off (section 2.5), showing how the decision boundaries of an SVM vary as two main hyperparameters, gamma and C, are changed, in the form of underfitting and overfitting cases.
ACS Catalysis Review
DOI: 10.1021/acscatal.9b04186 ACS Catal. 2020, 10, 2260−2297
2268


meters, such as the strength of the penalty or perturbation and the size, shape, or structure of the model units, should be clearly distinguished from the model parameters that are autotuned in the training process. In contrast, hyperparameters control inductive bias that is not determinable from the training data and need to be explicitly set before the model is trained. The plots in Figure 8 demonstrate the changes in the decision boundaries of support vector machines (SVMs) that occur when two main hyperparameters, the kernel coefficient (gamma) and the penalty parameter (C), are varied. For more practical examples, studies by our group provide detailed explanations about how to tune hyperparameters in a
systematic way.58,59 Regularization is a crucial step when a risk of overfitting exists as a result of the use of a highly complicated nonlinear model, an insufficient number of training samples, or a large number of input variables. The best practice is to systematically test a predefined set of candidate values by using a grid or random search. In recent years, advanced methods such as Bayesian optimization, GA, and model-based optimization for hyperparameter tuning have been developed in the ML community. The recent concept of AutoML attempts to automate this demanding process, and several software packages are available for conducting typical tasks such as hyperparameter optimization (HPO) and neural architecture search (NAS).
2.6. Exploitation−Exploration Trade-Off and Extrapolation. The mechanism of prediction in supervised learning is based on interpolating given training data. When a prediction lies outside the region that the training data cover, it can be quite inaccurate and baseless. The notions of interpolation and extrapolation might be intuitively reasonable (Figure 6), but in practice they are not simple because of high dimensionality. In a high dimension, it is not clear whether a specific input point is interpolative or extrapolative. For example, tree ensemble classifiers such as random forests and extra trees seem to be quite restricted and nonsmooth in Figure 7 when they are compared with other nonlinear methods. However, it is widely known that the tree ensemble classifiers function well in a very high dimensional space (even
up to 100000−700000 features).60,61 Also, decision boundaries of deep neural networks can be counterintuitive in an extremely high dimension (e.g., for images) and have a widely
known problem of adversarial examples to easily fool them.62 We can conclude that prediction would be quite uncertain when no training examples exist around a specified input point where the prediction is made. In the materials and molecular sciences, quantitative structure−activity relationships (QSARs) or QSPRs have been investigated extensively, and problems arising from the potentially huge gap between available and
unseen data have long been discussed.63,64 In particular, the crucial importance of the “applicability domain” (AD) of an ML model has been recognized. A strong goal in catalysis research is the development of genuinely new catalysts that exhibit better performance than currently available catalysts. However, predicting highperformance catalysts would be extrapolative because by definition such catalysts would be dissimilar to any existing catalysts and thus outliers in the training data. Therefore, it would be difficult to predict a novel catalyst simply by using supervised learning that only models an average trend in the given data.
The exploitation−exploration trade-of f is an established guiding principle to learn something novel. To gain essential knowledge and avoid overlooking possible discoveries, it is not sufficient to perform only “exploitation” of knowns by spotting trends seen in currently identified high-performance catalystsit is also important to carry out “exploration” for unknowns by probing potentially novel candidates with almost no information that can be quite different from any existing catalysts. Algorithms for balancing this trade-off include a wide variety of model-based optimization algorithms such as sequential experimental design, active learning, Bayesian optimization, multiarmed bandits, black-box optimization, and reinforcement learning. Applying metaheuristic optimization algorithms, including evolutionary algorithms such as GA, is another popular option. Implementing these search algorithms by both utilizing and questioning current assumptions and biases would be a promising approach for carrying out automated chemical exploration and discovery
using autonomous robotic systems.65 Many practical examples will be covered in subsequent sections and existing reviews, but in section 7.1 (Figure 24) we also introduce an example from our group that is based on balancing this exploitation−
exploration trade-off.66
2.7. Bayesian Inference, Generative Models, and Inverse Design. Up to this point, we have discussed ML in a standard setting. However, for most of the algorithms listed in Figure 3, including neural networks and decision trees, Bayesian versions exist where probabilistic inference is made instead of performing function fitting by pinpointing single
best parameters.23,67 In Bayesian inference, a probability distribution is set for parameters prior to data collection, and it is updated every time new data are obtained. The prior probability distribution, rewritten into the posterior distribution using Bayes’ theorem, represents the degree of certainty of the values of the parameter, which begins with an unbiased distribution and becomes more and more biased as the number of observations increases. When prediction is quite certain, the distribution would be peaked only at the specific parameter value, but otherwise it can be quite broadly distributed over possible values. Standard ML inference relies on optimization for function fitting, but Bayesian inference relies on integration required for normalizing any distribution into a probability distribution so that the integral over its domain is equal to 1. If a prior distribution is set arbitrarily, the corresponding posterior distribution cannot be obtained in closed form as a result of the integration in Bayes’ theorem. As a result of the recent advent of numerical computation methods such as accelerated Markov chain Monte Carlo (MCMC) and automatic variational inference, Bayesian inference now is a quite flexible and practical tool for statistical modeling. In the materials sciences, Bayesian methods are often used
for the inverse design approach.67,68 Apparently, when the aim is to predict possible inputs that give a specific desirable output, inverse design can be executed by simply interchanging inputs and outputs in supervised learning. However, this is not that simple because inputs and outputs usually have a many-toone correspondence. For example, a limitless number of images (inputs) can correspond to the label “dog” (output). Similarly, an infinite number of inputs can potentially exist that give a catalyst with a specific level of performance. However, by the use of Bayesian methods, a probability distribution of candidates that might give a specific level of performance can be produced, and this distribution can be employed to generate
ACS Catalysis Review
DOI: 10.1021/acscatal.9b04186 ACS Catal. 2020, 10, 2260−2297
2269


samples of these catalysts. Also, a hierarchical generative process can be specified in order to explicitly model some latent intermediate variables that cannot be observed directly but can characterize well the data and problem under study. This type of statistical modeling, which is based on generative models, is now called probabilistic programming, for which many software packages such as Stan, PyMC3, and Edward are available.
2.8. Use and Misuse of ML in Catalyst Identification: Correlation and Causality. As implied by the statement “correlation does not imply causation”, it is generally difficult to identify any “causal” relationships on the sole basis of observational data. Any ML-generated result can have a risk of being an artifact arising from a spurious correlation and thus cannot alone be considered to be scientifically conclusive. Interventional studies are needed to more safely ensure that ML-derived trends are real, as suggested by the statement “to find out what happens to a system when you interfere with it
you have to interfere with it (not just passively observe it)”.69 In general, many strong and unrealistic assumptions are required to guarantee that ML algorithms can produce causal information from observational data. For example, formal discussions of causal inference usually assume that all confounders have been identified and included in the model (i.e., that no unidentified but related factors exist). It is widely recognized that “causality” is notoriously difficult to even define, formalize, or quantify, but in practice there are useful guidelines such as the Bradford Hill criteria in epidemiology to carefully evaluate the potential gap between the observed correlation and causality. Although ML is based only on correlation and thus might suffer from the potential risk of being spurious, correlation is clearly a sign of a potential causal connection. Therefore, the result can be quite informative and can be subjected to further investigation using good data to assess whether it is actually “causal”. For example, in chemoinformatics, QSAR/QSPR studies with many descriptors are widely known to have an enhanced risk of exhibiting chance correlations, and the significance of the input−output correlation is often further ensured by using computational methods such as Y-random
ization and random-number pseudodescriptors.70 In Y-randomization, the prediction performance of the original ML model is compared to that of a model built from randomly shuffled Y values (outputs). Also, random-number pseudodescriptors can be used instead of or in addition to the original input variables. The performance score of the original model should be significantly better than the randomized cases when a potential causal connection exists between inputs and outputs. In particular, when a large collection of input variables (descriptors) is utilized in ML models, the risk of producing a spurious correlation should always be assessed.
3. ML PREDICTION OF NEW MATERIALS
The discovery of new heterogeneous catalysts begins with the discovery and structural identification of new materials. Current approaches used to identify novel materials primarily rely on trial-and-error synthesis combined with exhaustive phase diagram analysis. This protocol for materials discovery is far too slow and expensive to meet the demands for development of new heterogeneous catalysts. Instead, a rational and structured method that fully explores chemicalwide space is needed. In data-driven (inverse) design of catalysts of this type, it is required to establish a crystallo
graphic database of known and hypothetical structures
comprising a very large number of inorganic compounds.71 Several materials databases that contain the properties of experimentally observed and hypothetical materials are now available. Examples of such data sets include the Inorganic
Crystal Structure Database (ICSD),72 AtomWork,73 the
Materials Project,74 the Open Quantum Materials Database
(OQMD),75 and the Automatic Flow of Materials Discovery
Library (AFLOWLIB).76 Recent advances made in developing high-throughput DFT calculations and ML techniques have enabled the efficient utilization of these inorganic material databases for crystal structure predictions and the design of
materials (Figure 9).77−82 The new methods even enable rapid
in silico predictions of the structures of hypothetical materials. When the large set of DFT-driven crystallographic data is combined with ML, the search space of unknown compounds is greatly expanded. In this section, we describe typical examples of predictions of structures of catalytically important materials using both high-throughput DFT calculations and ML.
3.1. Alloys (Intermetallics). Intermetallic compounds (intermetallics) are a class of substances that have defined compositions and adopt structures distinct from those of the component elements. Despite their importance in many areas, including catalysis, rules for predicting intermetallics are not well-defined, and as a result, the design of novel intermetallics is challenging. Mar et al. applied various ML methods (e.g., SVM and PLS) to develop a crystal structure predictor for
binary AB intermetallics.83,84 Models were trained and validated by classifiing 706 AB compounds with seven structure types (NaCl, CsCl, CuAu, ZnS, TlI, NiAs, and βFeB) extracted from a crystallographic database. The data were split into a training set and a validation set, and the best descriptors and a better model were selected. SVM was found to be a better model, giving a sensitivity of 94.2%, specificity of 92.7%, and accuracy of 93.2%. The ML method used to obtain quantitative predictions of hypothetical compounds led to the identification of the new compound RhCd, which was predicted by SVM to have a CsCl-type structure (0.918 probability). The authors synthesized RhCd and demonstrated that it has a CsCl-type structure. This finding suggests that the
Figure 9. Schematic representation of ML-aided future materials design. The compound database is filtered to a smaller list of promising catalyst candidates through computational and experimental methods associated with ML approaches.
ACS Catalysis Review
DOI: 10.1021/acscatal.9b04186 ACS Catal. 2020, 10, 2260−2297
2270


ML method can be an accurate predictor of a crystal structure of an intermetallic. 3.2. Metal Oxides. Ceder et al. explored the ternary oxide (AxByOz) chemical space in a search for previously uncharacterized compounds using ML methods along with
high-throughput DFT calculations.85 In this effort, a probabilistic model was built from the ICSD and then used to identify new compositions that would likely to form a ternary oxide. The most likely crystal structure of each composition was predicted using the same probabilistic model. Finally, the stabilities of these substances were determined using DFT. The high efficiency of this method is demonstrated by the observation that 355 new compounds were identified within ca. 55 days following initiation of computing using 400 Intel Xeon 5140 2.33 GHz cores. The ability to identify what structure types result from synthetic routes would be an important tool in the materials sciences. However, finding this type of specific information is difficult because of the fact that different synthetic methods can generate the same types of products. An excellent ML
based method was developed recently by Olivetti and co
workers that overcomes this problem.86,87 In that approach, aggregated synthesis parameters were first computed using data extracted from over 640 000 publications by using natural language processing (NLP) and ML algorithms. Then a set of tabulated and collated synthesis parameters associated with 30 known oxide systems were input into the treatment. An overview of the approaches employed to transform humanreadable publications into machine-readable synthesis planning resources and synthesis parameters is given in Figure 10. Notably, direct human intervention is not involved in implementing this method. Rather, an automated text processing method downloads articles, extracts key synthesis information, codifies this information into a database, and subsequently aggregates the data into material system types. Scientific validation of the scheme was carried out by briefly comparing the aggregated data in the provided data set to known parameters. For example, frequent use of temperatures close to the anatase-to-rutile phase transformation for TiO2 were observed (Figure 10). Additional patterns showed that
Figure 10. (a) Schematic overview of text extraction and database construction. (b) A hierarchical neural network assigns labels (“MATERIAL”) to words one at a time by converting them to embedding and heuristic vector representations and outputting them to a classifier. (c) A grammatical parse of a sentence is used to resolve word-level labels (below the colored bars) into sequential word-chunk-level labels (above the colored bars), followed by resolution into word-chunk relations (curved arcs). (d, e) Calcination and hydrothermal (d) temperature and (e) time kernel density estimates for TiO2. From ref 86. CC BY 4.0.
ACS Catalysis Review
DOI: 10.1021/acscatal.9b04186 ACS Catal. 2020, 10, 2260−2297
2271


hydrothermal reactions occur in the narrow temperature range between 100 and 200 °C, which confirmed that hydrothermal reactions are more likely to occur than calcination when long time periods are utilized. Studies of catalysis by polyoxometalates (POMs) are extremely important in catalysis. The group headed by Cronin,
who is a leader in the field of automated chemical synthesis,88 constructed a workflow for crystallization of the new POM cluster Na6[Mo120Ce6O366H12(H2O)78]·200H2O that pos
sesses a trigonal-ring-type architecture (Figure 11).89 Synthesis and crystallization of this substance were probed by an ML algorithm. The obtained results were compared with those arising from experimentation. The ML-based approach was able to cover approximately 9 times more crystallization space than that of a random search and approximately 6 times more than a search conducted by humans. This expansion increased the crystallization prediction accuracy from 77.1 ± 0.9% for a human search to 82.4 ± 0.7%. Cronin and co-workers suggested that this outcome might be a consequence of the fact that the ML-based method is untied to prior chemical knowledge and is more “adventurous” in that it performs “jumps” in chemical space directly into what are believed to be boundaries between crystals and noncrystals. 3.3. Zeolites. Zeolites are crystalline aluminosilicate materials having a network of linked pores and cavities. For decades, these materials have been used in a large number of industrial catalytic processes, and consequently, a large demand exists for the synthesis of new zeolites that display high catalytic performances. ML algorithms have been used to
discover complex patterns embedded in the large amount of
data accumulated for zeolites.90,91 For example, in pioneering studies of ML applications to zeolite research, Blaisten-Barojas
et al.92−94 developed a knowledge-based model that is able to classify and predict topological types of zeolites with high accuracy using a nine-dimensional feature vector, including topological descriptors obtained by computations, together with some physical and chemical properties of zeolites. Alkaline desilication of zeolites is a conventional method employed to prepare mesoporous zeolites, and the conditions utilized strongly influence important properties of zeolites, such as the micro- and mesopore volumes, Si/Al ratio, and acidity, and their consequent influence on the activities, selectivities, and durabilites of zeolite catalysts. However, it is difficult to define the optimal desilication conditions that should be used to produce a catalyst tailored for a specific application. Blay et al. showed that perturbation theory combined with ML (PTML) is a powerful approach for predicting the effect of desilication conditions on the
properties of ZSM-5 zeolites.95 Accordingly, the PTML models enable prediction of the properties of a query material or compound starting with the properties for a reference and then adding PT operators to measure deviations from the reference. This method can be used to study large data sets with multiple inputs obtained from experiments. In the approach, a PTML model was first constructed using 1019 data sets for various ZSM-5 zeolites (H-ZSM-5, NH4-ZSM-5, Na-ZSM-5, Na,KZSM-5, etc.) collected from the literature. The data set contains information about the effect of preparation and
Figure 11. (a) Schematic representation of self-assembly of the {Mo120Ce6} wheel from basic building blocks in polyhedron mode. (b) Schematic diagram of the three exploration methods used. (c) Explorations of crystallization space using the three methods. The exploration is computed as the volume of the convex envelope of the experiments leading to crystals. (d) Average prediction accuracies between the classes of crystals and noncrystals for the three methods, using a random forest classifier. From ref 89. CC BY 4.0.
ACS Catalysis Review
DOI: 10.1021/acscatal.9b04186 ACS Catal. 2020, 10, 2260−2297
2272


treatment conditions on eight properties, including the BET surface area, mesopore volume, micropore volume, Si/Al molar ratio, etc. The model was found to have a high accuracy (R2 = 0.98) in an external validation series, demonstrating that the PTML method is useful for the rational design of alkalinedesilicated zeolites. In the model, the sizes of the mesopores in the alkaline-treated zeolites (z axis in Figure 12) are described
by the micropore and mesopore volumes before treatment. This map will be helpful for designing rational methods to prepare new zeolites with desired mesopore sizes. The mechanical stabilities (elastic properties) play an essential role in the selection of feasible zeolite structures. However, determination of the elastic properties of crystalline materials using DFT-based energy calculations requires a great
computational cost. Consequently, Evans and Coudert96 developed ML methods to efficiently predict the elastic properties of pure silica zeolites employing a DFT-calculated accurate training set of elastic properties. The ML approach based only on geometric parameters of the zeolites (structure, porosity, and local geometry) is able to predict bulk and shear moduli of zeolites with high accuracies. The methodology was employed to predict elastic responses of 590 448 hypothetical zeolites. The availability of this large database enabled an assessment of stability trends in zeolites. Zeolite BEA is typically synthesized using of a number of organic structure-directing agents (OSDAs). Daeyaert et al.
described a new ML approach to aid the computational design of synthesizable OSDAs for use in the preparation of zeolite
beta (Figure 13).97 Models to predict stabilization energies using a neural network were trained and validated using a data set of 4781 putative BEA zeolite OSDAs. The stabilization energies in BEA were produced through MD calculations. This effort led to the identification of 3062 promising OSDAs, 469 of which were predicted to stabilize the zeolite structure better than known compounds. The use of ML in this case sped up the computation by a factor of 350. Recently, Olivetti and coworkers extended the automatic data extraction approach developed for metal oxides (see above) to prediction of the
crystallization of zeolite structures.98 This method was used to synthesize Ge-containing zeolites to investigate relationships between the synthesis parameters and the resulting topology. 3.4. Inorganic−Organic Hybrid Materials. Inorganic− organic hybrid materials, including organically templated metal oxides and metal−organic frameworks (MOFs), have attracted much attention because they possess characteristics that can be controlled at the molecular level. Such unique features make inorganic−organic hybrids suitable for use as catalysts. Nevertheless, the formation of these materials is not perfectly understood, and as a result, the development of new materials currently relies primarily on the results of exploratory synthetic investigations. However, the ML method developed by Raccuglia et al. allows prediction of the success of reactions between organic and inorganic building blocks by using data
from failed experiments (Figure 14).99 Using this approach, the authors were able to predict reaction outcomes of crystallization of templated vanadium selenites. The training set came from information arising from “dark” reactions, specifically from unsuccessful or failed hydrothermal syntheses. When applied to hydrothermal synthesis with commercially available and previously untested organic building blocks, the ML model outperformed conventional human approaches and successfully predicted experimental conditions for the formation of a new organically templated inorganic compound with a notable success rate (89%).
4. SCALING RELATIONSHIPS FOR REACTIONS ON SURFACES
Describing catalytic activity as a function of a physical parameter without carrying out extensive trial-and-error experimentation has been a general strategy for catalyst design. Important contributions have been made by employing surface
properties related to catalysis such as work function,100,101 d
band center,102 coordination number (CN),103 surface
energy,104 and strain105 as descriptors of catalyst properties. In these efforts, the most widely explored examples involve establishing scaling relationships between the adsorption energies of reactants and intermediates using the d-band model and between activation and reaction energies, called Brønsted−Evans−Polanyi relationships (Figure
15).13−15,104,106−111 On the basis of the set of linear relationships, reactivity trends for a target catalytic reaction can be readily derived from adsorption energies of reactants without having to utilize tedious activation barrier calculations and full analysis of the steps involved in the reaction. By using the scaling relationships strategy, Nørskov and co-workers predicted and experimentally verified that bimetal catalysts such as NiZn would be applicable for selective hydrogenation
of acetylene112 and that NiGa would be applicable to CO2
hydrogenation.113
Figure 12. (a) Schematic workflow used to develop the PTML model. (b) Predicted values of εk(mi, cj)pred = mesopore size for >1000 data points. Reproduced from ref 95. Copyright 2018 American Chemical Society.
ACS Catalysis Review
DOI: 10.1021/acscatal.9b04186 ACS Catal. 2020, 10, 2260−2297
2273


Despite its importance in catalysis, the role played by electronic structures in determining adsorption energies on semiconducting and insulating oxide surfaces is still a matter of debate. Hence, in silico discovery of metal oxide catalysts is quite rare. In silico prediction of new catalysts using computationally low-cost descriptors could be possible in the future if comprehensive data sets containing quantitative descriptors for many reactants on many unknown surfaces were available. This section describes the results of recent studies aimed at determining relationships between electronic properties and adsorption energies on metal oxide surfaces. 4.1. Scaling Relationships between Adsorption Energies. Extensive studies of the adsorption of atoms and
molecules on metal oxide surfaces have shown that scaling relationships exist for adsorption energies despite the structural and electronic complexities of metal oxide surfaces. Fernández et al. performed DFT calculations on the adsorption of AHx intermediates and bare A atoms (A = O, S, N) on various transition metal oxide, nitride, and sulfide surfaces.114 The same linear relationship was found to exist between adsorption energies of AHx and A on surfaces of both metal oxides and pure metals. The trends in adsorption energies can be understood by using a modified version of the d-band model115 and by “Fermi softness”,109 which is defined as the sum of the density of states weighted by the derivative of the Fermi−Dirac distribution function at a certain nonzero
Figure 13. (a) Scatter plots of MD- vs ML-predicted stabilization energies for the OSDAs in the validation set. (b) Top five OSDA substances predicted by model 1b. The scores are ML-determined binding energies in kJ/(mol of Si). From ref 97. CC BY 4.0.
Figure 14. Schematic representation of the three hypotheses generated from the developed model together with representative structures for each hypothesis. The experimental conditions required for the formation of single crystals depend on the properties of the amine. Reproduced with permission from ref 99. Copyright 2016 Springer Nature.
ACS Catalysis Review
DOI: 10.1021/acscatal.9b04186 ACS Catal. 2020, 10, 2260−2297
2274


temperature. Calle-Vallejo et al. reported that the adsorption energies of O, OH, and OOH are linearly related to the number of outer electrons at the adsorption sites of metal,
monoxide, and perovskite surfaces.116 Although this effort found that the number of outer electrons can be a simple and efficient descriptor, van Santen et al. pointed out that experimental data on perovskite LaXO3 compounds do not follow this trend but instead show double-peaked volcano-type behavior for the third-row reducible metal oxides, which is most likely to be due to the high spin-state stabilization of d5
electron systems.5 Recently, scaling relationships were reported to exist between the adsorption energies of various molecules containing atoms bearing lone-pair electrons across a wide
variety of materials.117 Moreover, our group recently investigated the adsorption of a number of molecules on TiO2 surfaces employing DFT calculations together with
statistical approaches.118 We observed linear relationships between the highest occupied molecular orbital (HOMO) levels of the molecules and the adsorption energies. ML-based statistical analysis indicates that the dipole moment of the molecule also plays a role in molecular adsorption. It should be noted that adsorption energies on metal oxide surfaces are significantly affected by the presence of surface vacancies, dopants, and coadsorbed molecules. Therefore, further consideration is required in order to describe more precisely the activities and selectivities of working metal oxide catalysts. 4.2. Oxygen Vacancy Formation Energy as a Descriptor for the Catalytic Behavior of Metal Oxides. Defects play a significant role in governing the properties of catalysts. Various kinds of extended and point defects introduced into structures of catalysts largely govern their physical and chemical properties. In particular, point defects in
metal oxide surfaces such as oxygen vacancies have dominant
effects on the properties of heterogeneous catalysts.119,120 The energies required to form the oxygen defects in metal oxide catalysts are typically used to rationalize and predict the
performance of these catalysts.108 Oxygen vacancy formation in ABO3 perovskites has been extensively investigated using DFT computations because it
controls the electrocatalytic activity.121−123 Using DFT calculations, Chen and Ciucci systematically investigated the dependence of the stability and electronic and ionic
conductivity on substitutions of A and B sites of BaFeO3.124 They found that EOvac is reduced by the presence of Na, K, Ca, Sr, and Pb in the A site and Cu, Ni, Zn, and Ag in the B site. The value of EOvac was found to be linearly correlated with the occupied O p-band center, which is related to the basicity of the oxygen atoms. Emery et al. used high-throughput DFT to search for novel perovskites that promote thermochemical
water splitting (TWS).125 They screened 5329 calculated perovskites on the basis of the stabilities and vacancy formation energies and identified 139 potential candidates for TWS. Kumar et al. studied oxidative coupling reactions of CH4 on
various metal oxide surfaces.108 These reactions begin with abstraction of the H atom from a C−H bond of CH4 by a lattice oxygen atom, which leads to the formation of a CH3 radical. They reported that this process takes place more readily for highly reducible oxides and that the activation energy to cleave the C−H bond is linearly correlated with EOvac. The CH3 radical intermediate is converted to the desired C2 hydrocarbons by radical coupling or to undesired methoxy species by absorption to surface oxygen leading to the eventual formation of CO or CO2. Thus, adsorption of CH3 radical
Figure 15. Schematic representation of volcano plots and scaling relationships for reactions on surfaces.
ACS Catalysis Review
DOI: 10.1021/acscatal.9b04186 ACS Catal. 2020, 10, 2260−2297
2275


regulates the selectivity for C2 hydrocarbon production. The adsorption energy of methyl radical is also linearly correlated with EOvac. Surfaces activating the C−H bond more easily bind methyl radical more strongly. The authors proposed that metal oxides like TbOx that can exist in multiple oxidation states could overcome the intrinsic competitive processes by changing the oxygen atmosphere. Although theoretical studies of the formation of oxygen vacancies on metal oxides have been conducted recently, research on surface defects is still rare, and the number of investigated surfaces remains limited despite the obvious importance of oxygen vacancies for catalytic activity. Therefore, studies that provide EOvac values and reveal the physical factors determining EOvac are highly desirable. In this context, our group recently determined EOvac values of various semiconducting and insulating oxide surfaces using DFT calculations with comparable structure models at the same
computational level.126 A further investigation aimed at providing a deep understanding of the formation of oxygen vacancies found that the band gap, formation energy of the bulk, and electron affinity of a metal oxide are important properties that govern EOvac. The reason why these electronic properties determine EOvac is that electrons enter the defect state(s) after removal of oxygen, which could be in the conduction band for most cases. It is worth mentioning here that use of ML for statistical analysis to assess the physical basis of this relationship would perhaps be more meritorious
than predicting physical property values themselves.127 Although limitations associated with variety of the metal oxide surfaces and computational accuracy exist, the information would be helpful for catalysis researchers.
4.3. Understanding Acid−Base Properties of Metal Oxides. Solid acids and bases have been employed to catalyze various reactions, and the role of the properties of these solids in governing the catalytic performance has been investigated
extensively.128 An early computational study of the acid−base properties of the γ-Al2O3 surface found that the energies of occupied and unoccupied orbitals can be employed to rank
surface Lewis acid and base sites, respectively.129 Jenness et al. computed the adsorption energies of alcohols, diethyl ether, and water and the activation barriers for ethanol dehydration and etherification promoted by several Lewis acid sites on γ
Al2O3 surfaces.130 The results showed that energies of unoccupied s-band centers can be used as descriptors to evaluate the Lewis acidities of the Al3+ sites. These descriptors correlate the adsorption energies with the barriers for ethanol dehydration in a quantitative manner but describe the barrier for ethanol etherification only qualitatively because of the bimolecular nature of the process. Very recently, the occupied p-band center of O and unoccupied s-band center of Al were employed to evaluate the reactivity for C−H bond activation of
CH4 over γ-Al2O3 surfaces.131 In a study of n-butane oxidation over vanadium phosphorus oxides, Wang et al. identified the active site for this reaction
among 15 possible VO and PO sites in total.111 Both V O and PO sites abstract a H atom from n-butane in what can be viewed as a proton-coupled electron transfer process in which V5+ and oxygens serve as electron and proton acceptors, respectively. Thus, the activity of the PO sites is lowered by increasing the distance between V5+ and these sites. The results showed that a linear relationship exists between the centers of the energies of the PO lone-pair bands and the energies for reaction at the PO sites. Accordingly, the study demon
strated that energies of the s- and p-band centers are useful for rapid screening of potential active sites of metal oxide catalysts. Brønsted acid sites (BASs) in zeolite micropores are formed by protonation of oxygen atoms linking neighboring silicon and aluminum atoms for charge balancing. The presence of BASs in the confined environment is a crucial factor governing
the catalytic properties of many zeolite catalysts.132 Pidko and co-workers determined the acid strength of various zeolites using the adsorption energies of probe molecules such as NH3,
CO, pyridine, etc.133 The acid strength obtained by the adsorption energy calculations of NH3 was found to be correlated with the activation barrier of isobutene protonation in FAU zeolites. Matsuoka et al. screened 933 613 structures in a database of hypothetical zeolites to identify chemically
feasible members that have strong Brønsted acidity.134 Density, ring counting, and average ring sizes were used to eliminate unsuitable candidates. To assess the Brønsted acid strength, they introduced a new structural descriptor called b, which is the distance between barycenters of the two triangles connecting O atoms linked to T atoms in the acid site. This parameter can be calculated for pure silica with low computational cost, although the correlation between b and the Brønsted acid strength is weak. They confirmed by using DFT calculations that six out of 12 final candidates contain a strongly acidic Brønsted site. This encouraging result suggests that even nonquantitatively accurate structural descriptors might be sufficient for screening purposes where speed is more important than accuracy.
5. ML PREDICTION OF DFT-DERIVED FUNCTIONS FOR CATALYSIS
As described above, the activity orders of different catalysts are correlated with physical parameters such as adsorption energies and values of d-band centers, which can be determined with less computational cost than activation energies for reactions. Recent efforts focusing on these descriptor-based approaches for analysis of trends across the periodic table and reaction mechanisms as well as recent developments in computer technology have developed effective screening platforms for the discovery of novel catalysts. However, the costs of these approaches, which are normally based on first-principles calculations, are still high. If DFT-derived values were to be predictable using ML with widely available descriptors, it would be possible to quickly predict trends in catalytic activity. The investigations discussed in this section exemplify how fast calculations of catalytically important parameters (e.g., adsorption energies, d-band centers, bond strengths between metals and supports) can be carried out using ML models.
5.1. Adsorption Energies. Several recent reports have described ML predictions of adsorption energies of reactants and surface intermediates. In a pioneering work, Yildirim and co-workers showed that neural network models can be employed to predict the adsorption energies of O2 and CO on Au2 to Au10 clusters using the size and charge of the cluster, the number of unpaired electrons, and the CN as
descriptors.135 ML of DFT-derived adsorption energies on
metal (alloy) surfaces,136−144 low-symmetry Pt nanopar
ticles,145 and metal cation sites in zeolites146 were also determined using different descriptors and ML models. Virtual screening by utilizing the artificial neural network model for the adsorption energy of CO on core−shell alloy surfaces (Cu3B-A@Cu) indentified new catalyst candidates for selective
ACS Catalysis Review
DOI: 10.1021/acscatal.9b04186 ACS Catal. 2020, 10, 2260−2297
2276


CO2 electrochemical reduction to form C2 species.137 The group of Asahi described how adsorption energies of N, O, and NO on Rh1−xAux alloy nanoparticles can be predicted using a Bayesian linear regression model and a multidimensional structural descriptor.147,148 By combining this information with a kinetic model, those researchers were able to predict the rates of NO decomposition by the Rh1−xAux alloy nanoparticles as a function of composition and particle size. Nørskov et al. described a systematic ML-aided discovery approach for identifying NiGa bimetallic catalysts that are active for the electrochemical reduction of CO2 (Figure 16).149 Also, Tran and Ulissi demonstrated how ML-assisted theoretical screening can be used to discover new intermetallic catalysts (Figure 17).150 By screening various alloys, they uncovered 258 candidate surfaces across 102 alloys for inducing H2 evolution and 131 surfaces across 54 alloys for promoting CO2 reduction. For the purpose of experimental validation, the top candidates were used as catalysts for the electrochemical H2 evolution, CO2 reduction, and O2 evolution reactions. Our group also developed a simple ML model for efficient prediction of adsorption energies of CH4-related species, including CH3, CH2, CH, C, and H, on Cu-based alloys
(Figure 18).151 The ML model developed was demonstrated to predict DFT-derived adsorption energies using 12 descriptors that are readily obtained for selected elements. It was also shown that the top three descriptors for doped metals, including melting point, surface energy, and group in the periodic table, can be employed to predict the adsorption energies with comparable accuracies. Moreover, differences between the adsorption energies of CH3 and CH2 (ECH3 −
ECH2) were predicted to make selective catalysts that can
enable the efficient use of CH4.
Ni2P is known to be an effective catalyst for the electrochemical hydrogen evolution reaction (HER). Rappe et al. carried out virtual screening of Ni2P(0001) surfaces
doped at P sites with different concentrations of nonmetal
dopants (B, C, N, O, Si, S, As, Se, and Te).152 This process led to the development of a regularized random forest ML algorithm to quantify the relative importance of DFT-derived descriptors of the surface structure on determining the free energies of H atom adsorption (ΔGH) on the catalyst
candidates. The results showed that the Ni−Ni bond length is the most important descriptor for the HER activity, with shorter Ni−Ni bonds giving higher HER activities. By using DFT, O’Connor et al. were able to calculate energies for adsorption of various early and late transition metals such as V, Mn, Fe, Co, Ni, Cu, Ru, Rh, Pd, Ag Ir, Pt, and Au on several reducible and irreducible oxide supports such as CeO2(111), MgO(100), CeO2(110), ZnO(100),
TbO2(111), α-Al2O3(0001), and TiO2(011).153 DFT together with an ML method based on LASSO regression was employed to identify descriptors that predict interaction strengths between oxide supports and single metal atoms. The results demonstrated that the adsorption energies are correlated with properties of both the metal and the support, namely, the metal oxidation enthalpies, support reducibilities, and enthalpies of metal−metal interactions. 5.2. d-Band Centers. Our group used ML to predict dband centers, which are widely employed as general and versatile descriptors for a variety of reactions occurring over
heterogeneous transition metal catalysts.58,59 The d-band
Figure 16. Combinatorial challenge of identifying surfaces and active sites for bimetallic catalysts. (A) Ni/Ga intermetallic compounds synthesized experimentally and identified as the lower hull by the Materials Project database. (B) 40 identified facets/terminations. (C) 583 adsorption configurations identified as having unique average coordination of bonding metal atoms. (D) High-throughput methods developed to catalog and evaluate necessary thermodynamic quantities. Reproduced from ref 149. Copyright 2017 American Chemical Society.
ACS Catalysis Review
DOI: 10.1021/acscatal.9b04186 ACS Catal. 2020, 10, 2260−2297
2277


model assumes that chemisorption is dominantly governed by d electrons of transition metals.14 The approach involves linear scaling between the adsorption energy of a given adsorbate and the energy of the d-band center relative to the Fermi level. The higher the energies of the d states are relative to the Fermi level, the emptier are the antibonding states and the larger is the adsorption energy of an adsorbed species on a surface. Thus, we demonstrated that the d-band centers for monometallic and bimetallic surfaces having two different structures (overlayers on clean metal surfaces and surface impurities) can be predicted by employing an ML method (gradient boosting regression) (Figure 19). 5.3. Band Gaps. For the most part, experimental databases contain information about crystal structures of materials. It is much more difficult to access information about the electronic structures of compounds. For example, band gaps in the Materials Project database have been calculated using the generalized gradient approximation (GGA) functional by Perdew, Burke, and Ernzerhof (PBE) and GGA PBE+U for some of the compounds. Therefore, the band gaps of semiconductors are underestimated because of the only
approximate description of the exchange−correlation functionals, the missing derivative discontinuity, and the selfinteraction error.154 Although use of the GW approach and hybrid functionals usually gives reasonable results, these methods are often computationally too expensive. It would be desirable to obtain the band gap, which is a key property for the treatment of (photo)catalysts and other relevant applications such as solar absorbers and transparent conductors, with sufficiently high accuracy at a reasonable computational cost. In this regard, Dey and co-workers predicted the band gaps of over 227 new chalcopyrite compounds using the band gaps of 44 chalcopyrites reported in the literature.37 Subsequently, the group headed by Tanaka determined prediction models of G0W0 band gaps for 270 inorganic compounds employing Kohn−Sham band gaps, cohesive energies, crystalline volumes per atom, and other fundamental information about the constituent elements as descriptors.38 As determined using support vector regression, the best model had an RMSE of 0.24 eV, showing that the method is useful for screening a large set of materials. Band gaps of double perovskites have also
Figure 17. CO2 reduction activity map for bimetallics. A visualization of two-component intermetallics with surfaces that have low-coverage CO
adsorption energy (ΔECO) values within the range of −0.77 to −0.57 eV is shown. White shading indicates an absence of enumerated surfaces; gray
shading indicates that all of the ΔECO values are outside the range of −0.77 to −0.57 eV; colored shading indicates possible activity. The ΔECO values used to create the upper half of this map were calculated using DFT, and the values used to create the bottom half were calculated using the surrogate machine learning model. Reproduced with permission from ref 150. Copyright 2018 Springer Nature.
ACS Catalysis Review
DOI: 10.1021/acscatal.9b04186 ACS Catal. 2020, 10, 2260−2297
2278


been predicted using ML methods.39 In addition, ML predictions have recently been made for the band edges of MXenes, which are 2D layered transition metal carbides and nitrides such as graphene and molybdenum disulfide. Determination of accurate positions of the band edges of these novel materials is extremely important because they have promise in catalysis applications, in particular as photocatalysts
and eletrocatalysts. Mishra et al.155 developed an ML model
for determining the band edges with GW level accuracy having a minimum RMSE of 0.12 eV. They also found that electronegativity differences between transition metals and functional groups play a crucial role in tuning the electronic properties and positioning the band edges of MXenes.
5.4. Surface Phase Diagrams. Surface phase diagrams are of great importance to understand the surface chemistry occurring in (electro)catalysis, where various adsorbates and
Figure 18. (a) Representative adsorption model for CH3 on Cu-based alloys. (b) DFT-derived adsorption energies of CH3, CH2, CH, C, and H on Cu-based alloys. (c) Average RMSEs to predict the adsorption energies of CH3 by 100 rounds of random leave-25%-out trials with various ML models. (d) Correlation maps of the 12 descriptors. (e) Feature-importance scores of the descriptors for the extra tree regression prediction of the adsorption energies of CH3. Reproduced from ref 151. Copyright 2018 American Chemical Society.
Figure 19. ML prediction of the d-band center values for 11 metals (Au, Pt, Ir, Ag, Pd, Rh, Ru, Cu, Ni, Co, and Fe) and their pairwise bimetals for two types of structures (overlayer-covered or 1% metal-doped metal surfaces). Reproduced with permission from ref 58. Copyright 2016 Royal Society of Chemistry.
ACS Catalysis Review
DOI: 10.1021/acscatal.9b04186 ACS Catal. 2020, 10, 2260−2297
2279


coverages exist at varying applied potentials. These diagrams are typically made by employing intuition, an approach that has the risk of missing complex configurations and coverages at potentials of interest. Cluster expansion methods showing higher accuracy are often difficult to implement for treatment of new surfaces. The group of Nørskov employed an ML approach to address these issues.156 The free energies of all possible adsorbate surface coverages were predicted for a finite number of adsorption sites using a Gaussian process regression (GPR) model. The results showed that a simple, rational, and systematic approach could be implemented to obtain free energy diagrams at relatively low computational costs. The Pourbaix diagram for the IrO2(110) surface having nine coverages from fully oxygenated to fully hydrogenated can be reconstructed using only 20 electronic structure relaxations, compared to ca. 90 required when typical search approaches are utilized. The authors also extended this method to the MoS2 surface and obtained similar efficiencies.
6. ML PREDICTION FOR CATALYST CHARACTERIZATION
Spectroscopic and microscopic analysis of catalysts requires efforts by experienced experts. If an ML model can be constructed for a large number of catalysts and surface reactions from various types of spectroscopy and microscopy data, rapid identification of active sites, intermediates, and
products would be possible.157 Although various ML-assisted
spectroscopic analysis methods have been described,158−160 the discussion in this section focuses on the current status of ML-assisted analysis of various spectroscopy and microscopy data that are closely related to heterogeneous catalysis. 6.1. XAFS. X-ray absorption fine structure (XAFS) is a widely used technique for determining the local atomic structures of catalytic materials. XAFS is divided into two regimes: X-ray absorption near-edge structure (XANES) and extended X-ray absorption fine structure (EXAFS). XANES gives a fingerprint of coordination chemistry and the oxidation states of X-ray-absorbing atoms of a material, and EXAFS
Figure 20. (a) Workflow scheme of the ELSIE algorithm, which consists of two steps. In the first step, the absorption species is identified and used to narrow the number of candidate computed reference spectra. In the second step, the spectral matching ensemble yields a list of computational spectra rank-ordered by their similarity to the target spectrum. (b) Performance of the ELSIE algorithm on 19 test spectra. From ref 162. CC BY 4.0.
ACS Catalysis Review
DOI: 10.1021/acscatal.9b04186 ACS Catal. 2020, 10, 2260−2297
2280


provides information on the CN of neighboring atoms and their distances. Quantitative XANES analysis is typically difficult to carry out. Moreover, XANES analysis relies mainly on manual comparison of measured and reliable reference spectra. However, existing databases of XAFS spectra are limited in terms of the number of reference spectra, energy
resolution, and signal-to-noise ratio.161 Zheng et al. recently constructed a large database of computed reference XANES (more than 800 000 K-edge spectra for more than 40 000 compounds) and developed an algorithm called EnsembleLearned Spectra Identification (ELSIE) for the automatic identification of matching spectra for any experimental XANES
spectra.162,163 The algorithm combines 33 weak learners composed of a set of preprocessing steps (peak shifting/ alignment, spectra normalization, feature transformation, etc.) and a similarity measure (Figure 20). The approach attained up to 84.2% accuracy in identifying the correct coordination environment and oxidation state of a test set of 19 K-edge XANES spectra covering a variety of materials. The XANES database and ELSIE algorithm have recently been integrated
into the Materials Project database,74 which is available to all materials scientists. Kiyohara et al. developed a data-driven approach based on the clustering and decision tree method to “predict” and “interpret” oxygen K-edge XANES/electron-loss near-edge
structure (ELNES) spectra of oxides.164 The “prediction” proposes candidate spectra for a target oxide from a theoretically calculated spectral database on the basis of geometric and element input information such as bond length, bond angle, and valence state, while the “interpretation” suggests material information for the target spectrum. This methodology operated well in making an actual prediction and interpretation for the target SiO2 polymorph among 32 SiO2 polymorphs. Suzuki et al. showed how to estimate materials parameters (charge, symmetry, the crystal field parameter 10Dq, etc.) for manganese oxide from experimental Mn L2,3
XANES spectra.165 A spectral data set was first prepared by theoretical simulation using various parameters. Then the similarity values between the individual spectra and the reference spectrum were calculated to construct a statistical learning model for estimating the material’s parameters from its spectrum. A discrete value, for example the charge of Mn, is then estimated from the measured spectrum using dimensionality reduction, and its 10Dq (continuous value) is determined using the regression model obtained from the similarity of the spectra. Timoshenko et al. described an approach for determination of the 3D geometry of Pt nanoparticle catalysts (1−3 nm size) supported on γ-Al2O3 that employs a supervised ML method
and an artificial neural network.166 The artificial neural network was trained using theoretically calculated XANES data for Pt nanoparticles having different shapes and sizes, which are represented as the average CNs for the first four coordination shells {C1, C2, C3, C4}. The artificial neural network displayed high performance for predicting correct CN values {C1, C2, C3, C4} for experimental XANES spectra of the supported Pt nanoparticles, and thus, it is useful for obtaining their 3D structures. These researchers also utilized a modified artificial neural network method that included the effect of the bond distance R ({C1, C2, C3, C4, R}) to obtain 3D structures of subnanometer Cu clusters (Cu4, Cu12, C20) deposited on a
ZnO or ZrO2 substrate under a reactive atmosphere.167
Akai et al. applied sparse modeling based on l1 regularization to EXAFS oscillations analysis of Cu foil. In this approach, simplified basis functions based on a single-scattering approximation for the EXAFS oscillation are used instead of
plane-wave basis functions for the Fourier transform (FT).168 Consequently, the radial structure function takes a discrete spectrum and increases its intensity with increasing distance from the X-ray absorbing atom, suggesting the possibility of analysis of the CN at much higher shells. The Debye−Waller factor can also be obtained directly without prior assumptions about the atomic-scale local structure. An ML-based approach that can classify the local coordination environments of the absorbing atom from simulated K-edge XANES spectra was demonstrated recently
by Carbone and co-workers.169 The fidelity and robustness of the developed ML method were demonstrated by high average accuracy (86%) across the wide chemical space of oxides in eight 3d transition metal families. Lamberti et al. also applied ML techniques to simulate XANES spectra in order to investigate molecular adsorption on open metal sites (Ni2+) of
a MOF material.170 It should also be mentioned that automatic oxidation threshold recognition was demonstared by using ML
and experimental XAFS spectra by the group of Takahashi.171 Although several successful examples are available for ML prediction of XAFS spectra, most of the studies used computationally derived (well-behaved) data sets as inputs. This is mainly because proper energy alignments are required for ML modeling of XAFS spectra, and thus, it is difficult to obtain a sufficiently large number of experimental data sets for this purpose. Improvements in the accuracy of theoretical simulations are strongly desired. 6.2. TEM/STEM. It has become increasingly common to record atomically resolved transmission electron microscopy (TEM) and scanning TEM (STEM) images of catalytic materials and to monitor their atomic dynamics during reactions. However, because the amount of TEM/STEM data available has significantly increased recently and their interpretation often requires a great deal of time for nonexperts, it is highly desired to have automated analysis tools that can be utilized to identify and classify the local structures such as atoms (atomic columns), defects, dopants, and phases. Madsen et al. showed that deep convolutional neural networks can be used to directly identify atoms (atomic columns) of Au nanoparticles supported on CeO2 in high
resolution TEM (HRTEM) images.172 In this protocol, the network is trained using simulated TEM images of 500 Au nanoparticles. Because the network should be able to recognize both atomically flat and rough surfaces, the training data set includes both types of nanoparticles. Nanoparticles are initially cut from a regular crystal, keeping random numbers of layers in directions with low Miller indices (the ⟨100⟩, ⟨110⟩, and ⟨111⟩ directions), and then a random number of additional atoms are added to the particle to make it more rough. Subsequently, each particle is aligned into the ⟨110⟩ or ⟨111⟩ zone axis and rotated a random amount around the zone axis. It is finally tilted 0−5° away from the zone axis. Figure 21a shows TEM images of CeO2-supported Au nanoparticles in an oxygen atmosphere and the corresponding analysis using the neural network. As can be seen, the network can confidently identify the atoms in the nanoparticle, and in particular, the surface atoms at the corners of the nanoparticle appear and disappear again. The same CeO2-supported Au nanoparticle in vacuum
ACS Catalysis Review
DOI: 10.1021/acscatal.9b04186 ACS Catal. 2020, 10, 2260−2297
2281


and in an oxygen atmosphere is shown in Figure 21b. In the oxygen atmosphere, many surface and corner atoms are present part of the time, indicating the occurrence of surface diffusion. Ziatdinov et al. used DNN to locate atomic species and
defects in atomically resolved STEM images.173 For this purpose, they developed a “weakly supervised” approach that employs coordinates of all atomic species and types of defects to identify various defects that are not part of the initial training set. This technique was used to interpret atomic and defect transformations, including switching between different coordinations of Si dopants in graphene and the formation of a peculiar Si dimer with mixed threefold and fourfold coordination. Vasudevan et al. used the deep convolutional neural networks technique for automatic determination of the Bravais lattice symmetry seen in atomically resolved STEM and STM
images.174 The deep convolutional neural network was trained to identify this type of lattice symmetry when a 2D fast FT of the input image is given and then applied to sequential STEM images recorded during electron-beam decomposition of Mo
doped WS2. The method allowed tracking and determination of the rate of growth of voids (defects). Belianinov et al. proposed an approach to separate mixed phases, symmetries, and defects that is based on multivariate statistical analysis of the coordination spheres of individual atoms, represented by an array of values that correspond to a variety of metrics (distances, angles, etc.) between an atom and its nearest or
next-nearest neighbors.175 A k-means clustering analysis was performed for the two-phase (M1 and M2) mixed STEM image of Mo−V−Te−Ta oxide. The analysis enabled clear distinction of different areas of the image based on the similarity of the chemical neighborhoods of their constituent atoms and also predictions of the existence of a third phase in addition to the original two phases.
6.3. Nanoscale Elemental Analysis Using STEM-EDX and EELS. Advances in STEM have enabled comprehensive energy-dispersive X-ray (EDX)/electron energy-loss (EELS) spectral data sets from a specified region of interest (ROI) to be obtained. The spectrometers collect a set of spectra, each from a subnanometer area of the sample, by using the subnanometer electron probe scanning over the two-dimensional ROI. However, because of the presence of heterogeneous volumes in which spatial overlap of different phases exist within the beam path, the STEM-EDX signals from different depths in the beam path are mixed. Therefore, they need to be separated to determine the compositions of the individual phases. Rossouw et al. applied a blind source separation method based on PCA and independent component analysis (ICA) to analyze EDX spectral images (SIs) of core−shell nanoparticles in order to determine the number of phases in an
analyzed volume (core, shell, and supporting film).176 Figure 22a,c−e contain HAADF STEM images of FePt@Fe3O4 core− shell nanoparticles supported on carbon and the respective EDX elemental maps. It is clear that the particles consist of Ptrich cores surrounded by Fe oxide shells. However, it is difficult to tell whether the particles contain a monometallic Pt core with a surrounding Fe oxide shell or Fe makes an alloy with Pt to form a bimetallic core. The scree plot in Figure 22b suggests that the sample is composed of three principal phases. The spatial distribution of the independent components IC#0−IC#2 (Figure 22f−h) and the corresponding spectra (Figure 22i) show that IC#2, IC#1, and IC#0 represent the carbon support, Fe oxide shells, and bimetallic FePt cores, respectively. The small Cu peaks in all components likely originate from the Cu mesh support. More recently, Shiga et al. developed a new non-negative matrix factorization (NMF) method for automatic resolution and extraction of constituent
chemical components in STEM-EDX/EELS SI data.177 The method uses an extended NMF model with two penalty terms, namely, a prior automatic relevance determination (ARD) that optimizes the number of components and a soft orthogonal constraint that resolves each spectral component. An assessment of the method employing both phantom and real STEMEDX/EELS SI data sets demonstrated that the prior ARD successfully identified the correct number of physically meaningful components.
7. ML PREDICTION OF EXPERIMENTAL DATA FOR HETEROGENEOUS CATALYSTS
Experimentally produced data (conversion, selectivity, reaction rate) for reactions promoted using different catalyst compositions or different reaction conditions can be utilized to construct ML models for predicting reaction data. Although
Figure 21. (a) Top row: Successive experimental TEM images of a Au particle on CeO2 in a 4.5 Pa O2 atmosphere. Middle row: Output images given by the neural network from the images above. Bottom row: Atoms identified by using the neural network are marked as black circles overlaid on the original image. (b) Surface dynamics of Au nanoparticles on CeO2 influenced by the gaseous atmosphere. The occurrence is the percentage of frames where the neural network identified an atomic column at a possible site. The event is the percentage of frames where a site was previously occupied but is unoccupied in the frame immediately after, or vice versa. Reproduced with permission from ref 172. Copyright 2018 Wiley-VCH Verlag GmbH & Co. KGaA.
ACS Catalysis Review
DOI: 10.1021/acscatal.9b04186 ACS Catal. 2020, 10, 2260−2297
2282


Figure 22. ICA of a cluster of bimetallic FePt nanoparticle seeds coated by Fe3O4 shells. (a) HAADF-STEM image of the nanoparticles. (b) Scree
plot of the first 50 principal components displaying the first three components lying above the noise. (c−e) Element maps of (c) Pt, (d) Fe, and (e) O. (f−h) The IC maps (f) IC#0, (g) IC#1, and (h) IC#2 and (i) the corresponding IC spectra. Reproduced from ref 176. Copyright 2015 American Chemical Society.
Figure 23. Proposed ML method considering elemental features as representative input instead of the catalyst compositions themselves. As elemental descriptors, 11 physical properties that are readily available from chemical handbooks and the periodic table (atomic number, atomic weight, period, group, melting point, atomic radius, electronegativity, boiling point, enthalpy of fusion, density, and ionization energy) were employed for each element. Reproduced with permission from ref 66. Copyright 2019 Wiley-VCH Verlag GmbH & Co. KGaA.
ACS Catalysis Review
DOI: 10.1021/acscatal.9b04186 ACS Catal. 2020, 10, 2260−2297
2283


most of the studies mentioned above focused on building ML models from computationally derived (well-behaved) data sets, developing approaches to use ML with “real world” experimental catalysis data would be more useful because the computational costs to obtain accurate theoretical models for heterogeneous catalysis are currently prohibitively high. The dynamic nature of catalytically active sites/fields makes the modeling even more difficult. Even though excellent efforts have been conducted to create databases of surface reaction
energetics, such as CatApp178 and Catalysis-Hub.org,179 the accuracies and varieties of methods developed to capture the complex phenomena of heterogeneous catalysis are not yet adequate. After a brief overview of previous studies, this section summarizes recent examples of efforts focusing on MLassisted prediction of catalytic reaction data. Hattori et al. described pioneering studies of artificial intelligence approaches to catalyst design that use an expert
system or neural network.43−46 Subsequently, several
groups180−186 reported approaches for investigating and optimizing catalyst compositions using neural network, GA, or SVM methods, which have been summarized in previous reviews.4,30,187,188 Because the concepts and a tutorial overview of this general approach are described in reviews by
Rothenberg,4,188 we only summarize progress made in this area in the past decade. 7.1. CH4 Conversion. Because of the large amount of CH4 that is available from natural sources, it is strongly desired to develop processes for direct and indirect conversion of this substance into value-added products. Among the methods devised for direct conversion of CH4 to value-added chemicals,
oxidative coupling of CH4 (OCM) to produce C2 products such as C2H6 and C2H4 is the most popular. Catalysts for OCM reactions have been analyzed and predicted by several groups using a database consisting of nearly 2000 data sets on catalyst compositions and their performances collected from
diverse published data.189−193 Very recently, our group reported a statistical analysis and a proposal of novel heterogeneous catalysts for OCM using ML treatment of literature data.66 This effort led to the development of a novel ML method considering elemental features as input representations instead of inputting catalyst compositions directly (Figure 23). Effective analysis of literature data by ML methods has the capability to provide valuable information. Nevertheless, utilization of literature data has obstacles such as bias from prior published data, low sample counts for many elements, and lack of composition overlaps. The newly developed method has the potential to guide catalyst design and discovery, including those that promote reactions where limited catalyst composition overlap exists in the given data. The prediction accuracy of this approach is higher than those of conventional methods using catalyst compositions as input (Figure 24). Among various state-of-theart ML models developed, gradient boosting regression with XGBoost displayed the highest level of performance to predict catalytic performance. In order to determine quantitatively the most important input variables for prediction of the catalytic performance, a feature importance score was also obtained. Moreover, a catalyst optimization procedure that uses ML as “surrogate” models identified the top 20 promising catalyst candidates. This investigation provided fundamental knowl
Figure 24. (a) Comparison of 90%/10% training (blue)/test (red) error plots for three representation models of catalyst performance predictions for OCM (C2 yield): conventional ML methods using (i) only catalyst compositions and (ii) catalyst compositions + experimental conditions and (iii) proposed ML method using catalyst compositions + experimental conditions. (b) Top 20 descriptors to predict the C2 yield. (c) Top 20 promising candidate catalysts worth testing next. Reproduced with permission from ref 66. Copyright 2019 Wiley-VCH Verlag GmbH & Co. KGaA.
ACS Catalysis Review
DOI: 10.1021/acscatal.9b04186 ACS Catal. 2020, 10, 2260−2297
2284


edge about catalytic processes. Moreover, it has the potential of being used to identify truly novel heterogeneous catalysts where the reported data are limited and biased because they are very noisy and inconsistent as a consequence of variations arising from the use of different instruments, procedures, and platforms. Currently, CH4 is industrially converted through autothermal or catalytic steam reforming to form synthesis gas (a mixture of H2 and CO), which then is used for large-scale manufacture of methanol and higher-molecular-weight hydrocarbons. Although these processes are already industrially viable, they suffer from harsh reaction conditions. Thus, better catalysts are needed. The Yildirim group constructed 5508 experimental data points for steam reforming of CH4 (SRM)
using 81 publications appearing between 2004 and 2014.194 The database was analyzed using decision trees to extract correlations, heuristics, and trends that are not identifiable using only the naked eye. Analysis of the performance variable showed that Ni, Ru, Rh, and Pt are the most frequently used active metals and that they are normally supported on Al2O3, CeO2, or ZrO2 employing impregnation methods. In addition, the analysis determined the ranges of catalyst preparation and operational conditions employed that lead to high CH4 conversion. More recently, the same group extracted knowledge for the dry reforming of CH4 (DRM) reaction from
literature experimental data employing data mining tools.195 A database having 5521 data points was constructed from 101 papers reported between 2005 and 2014. 7.2. CO Oxidation. Günay and Yildirim performed a systematic analysis of experimental data for CO oxidation reactions reported between 2000 and 2012 using combinations
of various data mining tools.196 The decision tree classification formulated some simple rules needed for high conversion. The same group reported neural network analysis of the results of experimental CO oxidation reactions over Cu- and Au-based
catalysts.197,198 The original data set was collected from publications by different groups. The analysis was successful in the experimental region that contained many data points, whereas the conditions with smaller data sets were not easily generalized.
A database containing 4360 experimental data points on the Pt- or Au-catalyzed water gas shift reaction (WGS), which converts CO and H2O to CO2 and H2, was also constructed by the Yildirim group using data obtained from publications
appearing between 2002 and 2012.199 The database was analyzed using three mining tools to extract key information. Specifically, (1) decision trees were used to determine the empirical rules and conditions that allow for high CO conversion, (2) artificial neural networks were used to provide the relative importance of a variety of experimental variables and their effects on the catalytic activity, and (3) SVMs were used to predict outcomes of reactions performed under unstudied conditions.
7.3. Friedel−Crafts Reaction. Omata devised a method for predicting the activities of heteropolyacid catalysts supported on active carbon to promote a Friedel−Crafts
reaction that utilizes GPR.200 Additives that enhance activity were predicted using the regression model and verified through experimentation. The influence of physicochemical properties on the activity was estimated by employing GPR. The most influential properties were found to be density, atomic weight, and ionic radius of the additive element. It is significant that this approach uncovered the excellent effect of Pt addition on this process.
7.4. Utilization of Biomass. Rothenberg et al. reported experimental data on the hydrogenation of 5-ethoxymethylfurfural, an important intermediate to obtain industrial chemicals from sugars, promoted by different Al2O3-supported
metal catalysts under various conditions.201 The obtained data were compared with the results of studies of 48 bimetallic catalysts and rationalized by an effective model that applied catalyst descriptors based on Slater-type orbitals. In this approach, each metal is described using four parameters: the distance of the orbital peak from the metal atom center, the height of the peak, the peak skewness, and the peak width at half height. The authors then applied these descriptors to modeling of the reaction data using multivariate methods. In spite of the inherent complexity of the reaction pathway, the models developed in this way reasonably described the performances of the catalysts (Figure 25).
Figure 25. Performance of the training and test sets for the model describing the conversion of 5-ethoxymethylfurfural to the corresponding unsaturated alcohol. Reproduced with permission from ref 201. Copyright 2012 Royal Society of Chemistry.
ACS Catalysis Review
DOI: 10.1021/acscatal.9b04186 ACS Catal. 2020, 10, 2260−2297
2285


The Yildirim group conducted a statistical analysis of catalytic transesterification reactions by employing artificial neural network and decision tree techniques. The aims were to estimate important variables affecting conversion of fatty acid
and suitable ranges of these variables.202 For this purpose, a database of 1324 data points was constructed from the experimental results reported in 31 publications. Importantly, artificial neural network analysis showed that the most important variable to obtain high conversion of the fatty acid was the reaction time, followed by the catalyst loading, alcohol/oil molar ratio, reaction temperature, and type of support, each of which have a similar relative importance of about 10%.
7.5. Oxidative Dehydrogenation of Butane. The oxidative dehydrogenation of butane to form butenes and butadiene can also be accurately modeled employing heuristic
descriptor models. Rothenberg et al.203 synthesized and experimentally tested 15 bimetallic mixed oxides supported on Al2O3 in order to construct a descriptor model. The results obtained utilizing data from this study to assess 1711 mixed oxide catalysts in silico led to the prediction of six new bimetallic oxides, which were then experimentally synthesized and tested. The correlation between the predicted and experimental results was excellent, showing the power of
these low-cost predictive models. The wide operational range of the model was demonstrated by its use in uncovering not only catalysts that have expected high performances but also those expected to have low activities. It is important to note that an understandable bias exists for including only “good” results in publications because articles often exclude descriptions of badly performing catalysts. However, models developed to predict the performance of catalysts should be based on a wide range of data, highlighting the importance of including both “good” and “bad” candidates in publications. 7.6. Reduction of CO2. Several new catalysts for CO2 hydrogenation to form higher-molecular-weight hydrocarbons (CO2-based Fischer−Tropsch synthesis) were devised by Baerns and co-workers, who applied an evolutionary strategy
using a GA.204 Among those predicted are Fe-based catalysts modified using K and Zn or Cu, which promote high CO2 conversions combined with high selectivity toward C5−C15 hydrocarbons and low CH4 formation. Moreover, it was demonstrated that TiO2 is required as a support in order to obtain low CH4 selectivities. Experimental data on the electrocatalytic reduction of CO2 (471 data points) were collected and used for statistical
analysis by Günay and co-workers.205 The collected data were first examined by exploratory analysis using box-and-whisker
Figure 26. (a) Loading magnitudes for the 14 descriptors identified using factor analysis. (b) Relative importance of descriptor variables for the penalized regression models (elastic nets, LASSO, LAR). Descriptors are sorted by median (gold bars). The bar color indicates the sign of the coefficient: positive (light gray) and negative (dark gray). (c) Heat map of relative OER activity predictions for ABO3 perovskites using LAR and data obtained from the Materials Project. Reproduced from ref 206. Copyright 2015 American Chemical Society.
ACS Catalysis Review
DOI: 10.1021/acscatal.9b04186 ACS Catal. 2020, 10, 2260−2297
2286


plots. Subsequently, decision tree analysis was carried out to identify the importance of the variables and conditions that lead to higher reduction efficiencies and rates as well as selectivities for product formation. It was found that Cu contents less than 71% are the main requirement to realize high Faradaic efficiency while Cu contents less than 13% are essential for high production rates. The topmost factor determining the selectivity was found to be the Sn content. The most important variables for obtaining high Faradaic efficiency were also identified to be the Cu content, applied potential, TGP-H-60-type diffusion layer, filterpress cell, Nafion 117-type membrane, and KHCO3 in the anolyte and
catholyte. The CO2 flow rate and applied potential were
identified to be the most highly significant input variables to maximize the production rate. Moreover, Cu contents less than 52% and Sn contents higher than 15% were found to be the most important factors for obtaining the highest rate and selectivity for formic acid production.
7.7. Oxygen Evolution Reaction. Hong and co-workers demonstrated how statistical learning approaches can be utilized to investigate ambiguities in the reported descriptors
for oxygen evolution reaction (OER) catalytic performance.206 The authors found through aggregation of 101 observations of 51 perovskites reported in the literature and their own experimental data that 14 descriptors of metal−oxygen bond strengths can be grouped into five basic descriptor families, including electrostatics, metal−oxygen covalency, structure, transition metal electron occupancy, and exchange interactions (Figure 26). Electron occupancy and covalency have the strongest influence on the OER catalytic performance. The charge-transfer energy (covalency) and the number of d
electrons were found to be the most important, while other factors, including the M−O−M bond angle, optimum eg occupancy, and tolerance factor were determined to be secondary descriptors. Figure 26c contains estimates of the relative OER activities made using the best-performing model (least angle regression, LAR) for ABO3 perovskites from the Materials Project. More recently, Palkovits and Palkovits also developed ML models using literature data to forecast OER
catalysts.207 They used a data set consisting of more than 6000 catalysts with four features represented by composition to predict overpotentials at 10 mA/cm2.
7.8. Photocatalytic Water Splitting. ML techniques
could serve as a powerful tool in the field of photocatalysis.208 The Yildirim group constructed and analyzed a database containing 540 cases from 151 published articles on photocatalytic water splitting reacions over perovskites using data
mining.209 Important factors to achieve efficient H2 generation were revealed by association rule mining. Decision tree analysis also identified useful heuristics for future investigations. Moreover, they developed predictive models using random forest regression.
8. ML PREDICTION OF EXPERIMENTAL DATA FOR HOMOGENEOUS CATALYSTS
Homogeneous catalysts, generally organocatalysts and organometallic catalysts, play essential roles in industry, especially for promoting synthetically useful reactions in a highly selective manner. Most organocatalysts and organometallic catalysts have been discovered through serendipity or trial-and-error studies rather than by rational design, which is often too resource intensive and intellectually frustrating. As a result of
Figure 27. Chemoinformatics-guided optimization protocol. (A) Generation of a large in silico library of catalyst candidates. (B) Calculation of robust chemical descriptors. (C) Selection of a universal training set (UTS). (D) Acquisition of experimental selectivity data. (E) Application of ML to use moderate- to low-selectivity reactions to predict high-selectivity reactions. Reproduced with permission from ref 226. Copyright 2019 American Association for the Advancement of Science.
ACS Catalysis Review
DOI: 10.1021/acscatal.9b04186 ACS Catal. 2020, 10, 2260−2297
2287


the drawbacks of these approaches, increasing attention has been given to the development of predictive strategies that can provide insights into the connection between structure and function. To predict reactivity trends (linear free energy relationships) of organic reactions, semiquantitative descriptors have been established that are based on steric and electronic properties of the substituents (i. e., Hammett and related
substituent parameters).210 Because the outcomes of reactions catalyzed by transition metal complexes strongly depend on the nature of the ligands, well-known ligand descriptors such as cone angles and electronic parameters have been estab
lished.211 As discussed in excellent reviews by Fey and co
workers,212−214 modern organometallic chemistry has established DFT-derived ligand descriptors to identify how steric and electronic properties affect the properties of complexes. Because homogeneous catalysts are generally well-defined molecules composed of transition metal centers and ligands (organometallic complexes), DFT calculations of descriptors for homogeneous catalysis are relatively simpler than those for heterogeneous catalysts. Accumulated experimental data derived from ligand screening of organometallic catalysts in combination with calculated ligand descriptors serve as databases for the learning phase of ML-assisted catalyst design.
Sigman,215−219 Fey,212−214 Rothenberg,220−222 and
others223,224 have extensively utilized QSAR to correlate input data (ligand descriptors and reaction conditions) and output data (conversion, yield, selectivity, etc.) using conventional algorithms such as PLS, multivariate linear regression (MLR), PCA, GA, SVM, and artificial neural networks. These authors demonstrated the success of predictive modeling of homogeneous catalysts. Very recent progress has been made in this area as a result of the increasing availability of descriptorcomputation methods and modern ML algorithms. This section discusses several examples of efforts aimed at the
design of homogeneous catalysts using ML models together with DFT or simple computationally derived descriptors. 8.1. Organocatalysis. Enantioselective organocatalysis is a useful synthetic method for the synthesis of enantiomerically pure or enriched chiral compounds. Enantioselectivity in these processes arises from a difference in free energy between competing transition states leading to different enantiomers
(ΔΔG⧧). Various factors, including electronic and steric interactions between the catalyst and substrate, are important
in governing ΔΔG⧧ and thus the level of enantioselectivity.
However, the effect of these factors on ΔΔG⧧ is not yet quantitively predictable and understood, making data-intensive discovery of new enantioselective organocatalysts challenging. Sigman et al. developed MLR models for predicting the enantiomeric excess (% ee) for enantioselective crossdehydrogenative C−N coupling reactions of various amidegroup-containing substrates promoted by various chiral
phosphoric acid derivatives as catalysts.225 Among the large number of steric and vibrational terms initially examined, four were statistically selected as molecular descriptors for which
ΔΔG⧧ predictions were validated experimentally. The results demonstrated the success of a data-intensive method for deriving a mechanistic model for predicting enantioselectivities of organocatalyst-promoted reactions. Zahrt et al. developed averaged steric occupancy (ASO) descriptors of catalyst structures, which include 3D information and are responsible for induction of enantioselectivity
(Figure 27).226 They demonstrated accurate predictive
modeling of enantioselectivities (ΔΔG⧧) in N,S-acetal-forming processes with SVM and deep feed-forward neural networks using ASOs as readily calculable descriptors for large compound libraries. These examples serve to demonstrate the potential of data-driven approaches for optimization of chiral organocatalysts.
Figure 28. (a) General catalytic cycle for C−C cross-coupling reactions. (b) Reference volcano plot for the reaction. Region I corresponds to reductive elimination, region II to transmetalation, and region III to oxidative addition. Good catalyst candidates should fall into the middle region. (c) Database having 25 116 molecular transition metal catalyst candidates. Each complex comprises one out of six transition metals and a combination of two out of 91 ligands. Each ligand was written in SMILES notation, and all possible L1−M−L2 combinations were constructed.
SMILES strings were then converted into Cartesian coordinates. (d) Histogram ranking of the five most identified ligands that appear on the volcano plateau. The histogram is scaled relative to the Pd/oxazole ligand combination. (e) Estimated prices of the catalysts (for 1 mmol in U.S. dollars) in the selected range of −32.1 to −23.0 kcal/mol. From ref 227. CC BY-NC 3.0.
ACS Catalysis Review
DOI: 10.1021/acscatal.9b04186 ACS Catal. 2020, 10, 2260−2297
2288


8.2. Organometallic Catalysis. Rothenberg et al. devised a QSAR approach for selecting catalysts and reaction conditions for promoting Heck cross-coupling reactions.220 Correlations between catalyst precursors, ligands, substrates, and reaction conditions in a data set of 412 Heck crosscoupling reactions based on a set of defined and calculated steric and electronic descriptors were analyzed using various regression methods. Becuase of the complex nature of the Heck cross-coupling reaction, nonlinear methods such as classification trees and neural networks were found to be superior to simple linear regression methods in modeling and predicting the catalytic performance. The models were used to predict the catalytic activities of 60 000 combinations of virtual catalysts as well as reaction conditions. Although volcano plots are frequently used to understand or predict trends in heterogeneous catalysts, their application to homogeneous catalysts is relatively rare. Corminboeuf et al. applied a volcano plot approach to ML-assisted prediction of homogeneous catalysts for C−C cross-coupling reactions (Figure 28).227 The computed energies for the oxidative
addition step, ΔE(Rxn A), were machine-learned using simple molecular descriptors, including SMILES notation of ligands in vast libraries of Pd-, Pt-, Ni-, Cu-, Au-, and Ag-based organometallic catalysts combined with 91 ligands. Figure 28b shows the volcano relationship between the reaction free energy and ΔE(Rxn A), which indicates that good catalysts should fall into the region −32.1 kcal/mol < ΔE(Rxn A) < −23.0 kcal/mol. Out-of-sample ML predictions made using a total of 18 062 compounds led to the identification of 557 catalyst candidates falling into this ideal thermodynamic window. Considering the price estimation of <$10/mmol, the authors recommended 37 catalysts, including earthabundant Cu and less common ligands as well as a large number of Pd−phosphine complexes. Tungstate-catalyzed epoxidation reactions of alkenes with H2O2 are significantly accelerated by phosphonic acid cocatalysts. Yada et al. demonstrated an ML model (LASSO) for predicting the yields of epoxidation of 1-octene using 14 types of phosphonic acids (Figure 29).228 Vibrational and electronic descriptors of phosphonic acids (HOMO−LUMO
Figure 29. Tungsten-catalyzed epoxidation reactions of 1-octene (1) using previously unverified phosphonic acid derivatives as catalysts. (a) Comparison of predicted and experimental yields. (b) Plot of experimental vs predicted yields. Reproduced with permission from ref 228. Copyright 2018 The Chemical Society of Japan.
Figure 30. Flowchart for CatVS. User-defined substrates are merged into a reaction template together with ligands from a predefined library, followed by an automated conformational search using TSFF parameters and Boltzman averaging of the free energies calculated for the ensembles of the diastereomeric transition states. FF, force field. Reproduced with permission from ref 230. Copyright 2018 Springer Nature.
ACS Catalysis Review
DOI: 10.1021/acscatal.9b04186 ACS Catal. 2020, 10, 2260−2297
2289


gaps, NBO charges, and frequencies and intensities of the IR modes, especially [P(O)(OH)2] vibrations) were calculated using DFT. The established model was used to predict yields of reactions promoted by previously unstudied phosphonic acids. The success of the model was verified by comparing predicted and experimental results for eight types of phosphonic acids. The group headed by Doyle used two easily calculable ligand descriptors, percent buried volume and cone angle, to predict yields of Ni-catalyzed Suzuki coupling reactions of acetals with
boronic acids to form benzylic ethers.229 The model suggested a new concept for ligand design in which remote steric hindrance is used to predict the effectiveness of a ligand. Rosales et al. developed an automated method for rapid virtual screening of substrate and ligand libraries for asymmetric
catalyzed processes (Figure 30).230 A quantum-guided molecular mechanics (Q2MM) method was used for automated calculation of transition state force fields, which were then used as descriptors for an ML model to predict the stereoselectivities of organic reactions. Predictive computational ligand selection was shown by using a virtual ligand screen of a library of diphosphine ligands for the Rh-catalyzed asymmetric hydrogenation of enamides. The high selectivities of predicted substrate−ligand combinations were verified experimentally. Predictive modeling was also applied to make predictions about isomerization reactions of alkenes promoted
by zipper Ru catalysts231 and catalytic regioselective difluori
nation reactions of alkenes.232 Recently, Amar et al. developed a new ML-based method for
rational selection of solvents.233 Rational solvent selection has a large impact on the performance of catalytic processes and remains a formidable task in process development. The developed ML method enabled the rapid identification of promising solvents for asymmetric hydrogenation, outperforming those identified by human intuition in terms of diastereomeric excess and conversion. They found optimal operating conditions and successfully explored an idea that uses mixed solvents to attain a range of experimental space not accessible with pure solvents. More recently, Yamaguchi et al. found that a regression technique, molecular field analysis, is highly effective for designing molecules in asymmetric
catalysis.234 The analysis using intermediate structures in an enantiodetermining step allowed for extraction and visualization of important 3D structural information to improve the enantioselectivity. In addition, they experimentally confirmed that the newly designed substrate obtained using their method exhibited improved enantioselectivity.
9. CONCLUSIONS AND FUTURE OUTLOOK
For the most part, discovering and optimizing catalysts/ catalysis are still empirically driven. It is true that ML-assisted development of real catalysts remains in its infancy despite the fact that this approach has had success in molecular and materials science. Nevertheless, little doubt exists that ML will become a valuable addition to the toolkit for generating knowledge about and designing catalysts in the future. Not only first-principles-calculated data but also experimental data for specific catalytic reactions are required in order to use ML for practical discovery of new catalysts. This is especially true for heterogeneous catalysts, for which adequate theoretical models are currently unavailable. Thus, ML-predicted data cannot directly lead to the design of novel catalysts. Although “catalysis informatics” is highly related to materials informatics
and chemoinformatics, it is distinguished by the fact that catalysis is a dynamic event controlled by the structures and chemical nature of catalytically active sites. Moreover, the timedependent nature of catalysis makes data representation and analysis more challenging. It would be beneficial for future investigations in this area to aim at bridging the gap between simplified descriptor-based screening and complex real models in a manner that considers dynamics during catalytic events. Although high-throughput or combinatorial methods, which have been applied successfully to relevant fields including materials synthesis, serve as powerful tools to discover novel
catalysts and catalytic processes,53,136,235−243 at the current time these experiments have not been explored fully. As a consequence, there is a lack of good and refined data to guide ML. Although text- and data-mining approaches also
demonstrate promise to accelerate research in this area,87,188 catalytic reactions are not only highly dependent on specified experimental conditions such as temperature, reactant concentration, and flow rate but also effected by unstated conditions such as the shape and volume of the reactor. Also, approaches tend to be biased toward successful examples reported previously. Direct use of the ML technique could result in discovery of only a narrow range of finely tuned variations of previously studied catalysts because ML builds predictive models that are representative of the given training data. Therefore, published data might not serve as good training sets for ML predictions. In this sense, experimental data need to be generated under the same or at least comparable reaction conditions. Also, coupling data science with theoretical and experimental approaches could lead to new methods for discovering catalysts to ensure “closing the loop”. Another aim of catalysis research is to establish more accurate and lower-computational-cost calculations of transition states for catalyzed reactions. Although calculations of this type are generally performed using first-principles electronic structure methods and as a result are computation
ally expensive, use of ML can significantly reduce costs.244−251 In addition, the artificial-force-induced reaction (AFIR) methodology in the global reaction route mapping strategy can be employed for automatic and unbiased searches of
complex reaction pathways.252,253 The AFIR approach locates local minima and transition states of reaction paths without guessing. Therefore, it can find both unanticipated and anticipated reaction pathways. Ultimately, integration of these methods with existing chemical and physical models should greatly accelerate the automated design, discovery, and optimization of catalysts as well as catalytic processes and lead to the establishment of “catalysis informatics”.
■
AUTHOR INFORMATION
Corresponding Authors
*E-mail: ichigaku.takigawa@riken.jp (I.T.). *E-mail: kshimizu@cat.hokudai.ac.jp (K.S.).
ORCID
Takashi Toyao: 0000-0002-6062-5622 Takashi Kamachi: 0000-0001-9281-0454 Ichigaku Takigawa: 0000-0001-5633-995X Ken-ichi Shimizu: 0000-0003-0501-0294
Notes
The authors declare no competing financial interest.
ACS Catalysis Review
DOI: 10.1021/acscatal.9b04186 ACS Catal. 2020, 10, 2260−2297
2290


■ ACKNOWLEDGMENTS
The preparation of this review and studies described that were carried out by the authors were supported by the Japanese Ministry of Education, Culture, Sports, Science, and Technology (MEXT) within the projects Elements Strategy Initiative To Form Core Research Center and Integrated Research Consortium on Chemical Sciences (IRCCS) and by
JST-CREST Project JPMJCR17J3.
■
REFERENCES
(1) Schlögl, R. Heterogeneous Catalysis. Angew. Chem., Int. Ed. 2015, 54, 3465−3520. (2) Nørskov, J. K.; Bligaard, T.; Rossmeisl, J.; Christensen, C. H. Towards the Computational Design of Solid Catalysts. Nat. Chem. 2009, 1, 37−46. (3) Matera, S.; Schneider, W. F.; Heyden, A.; Savara, A. Progress in Accurate Chemical Kinetic Modeling, Simulations, and Parameter Estimation for Heterogeneous Catalysis. ACS Catal. 2019, 9, 6624− 6647. (4) Ras, E. J.; Rothenberg, G. Heterogeneous Catalyst Discovery Using 21st Century Tools: A Tutorial. RSC Adv. 2014, 4, 5963−5974. (5) van Santen, R. A.; Tranca, I.; Hensen, E. J. M. Theory of Surface Chemistry and Reactivity of Reducible Oxides. Catal. Today 2015, 244, 63−84. (6) Liu, L.; Corma, A. Metal Catalysts for Heterogeneous Catalysis: From Single Atoms to Nanoclusters and Nanoparticles. Chem. Rev. 2018, 118, 4981−5079. (7) Bruix, A.; Margraf, J. T.; Andersen, M.; Reuter, K. FirstPrinciples-Based Multiscale Modelling of Heterogeneous Catalysis. Nat. Catal. 2019, 2, 659−670.
(8) Ishikawa, S.; Zhang, Z.; Ueda, W. Unit Synthesis Approach for Creating High Dimensionally Structured Complex Metal Oxides as Catalysts for Selective Oxidations. ACS Catal. 2018, 8, 2935−2943. (9) Sehested, J. Industrial and Scientific Directions of Methanol Catalyst Development. J. Catal. 2019, 371, 368−375. (10) Pelletier, J. D. A.; Basset, J. M. Catalysis by Design: WellDefined Single-Site Heterogeneous Catalysts. Acc. Chem. Res. 2016, 49, 664−677. (11) Toyao, T.; Hakim Siddiki, S. M. A.; Kon, K.; Shimizu, K. The Catalytic Reduction of Carboxylic Acid Derivatives and CO2 by Metal
Nanoparticles on Lewis-Acidic Supports. Chem. Rec. 2018, 18, 1374− 1393. (12) Grajciar, L.; Heard, C. J.; Bondarenko, A. A.; Polynski, M. V.; Meeprasert, J.; Pidko, E. A.; Nachtigall, P. Towards Operando Computational Modeling in Heterogeneous Catalysis. Chem. Soc. Rev. 2018, 47, 8307−8348. (13) van Santen, R. A.; Neurock, M.; Shetty, S. G. Reactivity Theory of Transition-Metal Surfaces: A Brønsted−Evans−Polanyi Linear Activation Energy−Free-Energy Analysis. Chem. Rev. 2010, 110, 2005−2048. (14) Nørskov, J. K.; Abild-Pedersen, F.; Studt, F.; Bligaard, T. Density Functional Theory in Surface Chemistry and Catalysis. Proc. Natl. Acad. Sci. U. S. A. 2011, 108, 937−943.
(15) Hammer, B.; Nørskov, J. Theoretical Surface Science and Catalysis. Adv. Catal. 2000, 45, 71. (16) Butler, K. T.; Davies, D. W.; Cartwright, H.; Isayev, O.; Walsh, A. Machine Learning for Molecular and Materials Science. Nature 2018, 559, 547−555. (17) Butler, K. T.; Frost, J. M.; Skelton, J. M.; Svane, K. L.; Walsh, A. Computational Materials Design of Crystalline Solids. Chem. Soc. Rev. 2016, 45, 6138−6146. (18) Fujinami, M.; Seino, J.; Nukazawa, T.; Ishida, S.; Iwamoto, T.; Nakai, H. Virtual Reaction Condition Optimization Based on Machine Learning for a Small Number of Experiments in HighDimensional Continuous and Discrete Variables. Chem. Lett. 2019, 48, 961−964. (19) Szymkuć, S.; Gajewska, E. P.; Klucznik, T.; Molga, K.; Dittwald, P.; Startek, M.; Bajczyk, M.; Grzybowski, B. A. Computer-Assisted
Synthetic Planning: The End of the Beginning. Angew. Chem., Int. Ed. 2016, 55, 5904−5937. (20) Segler, M. H. S.; Preuss, M.; Waller, M. P. Planning Chemical Syntheses with Deep Neural Networks and Symbolic AI. Nature 2018, 555, 604−610. (21) Coley, C. W.; Thomas, D. A.; Lummiss, J. A. M.; Jaworski, J. N.; Breen, C. P.; Schultz, V.; Hart, T.; Fishman, J. S.; Rogers, L.; Gao, H.; Hicklin, R. W.; Plehiers, P. P.; Byington, J.; Piotti, J. S.; Green, W. H.; Hart, A. J.; Jamison, T. F.; Jensen, K. F. A Robotic Platform for Flow Synthesis of Organic Compounds Informed by AI Planning. Science 2019, 365, eaax1566.
(22) Tabor, D. P.; Roch, L. M.; Saikin, S. K.; Kreisbeck, C.; Sheberla, D.; Montoya, J. H.; Dwaraknath, S.; Aykol, M.; Ortiz, C.; Tribukait, H.; Amador-Bedolla, C.; Brabec, C. J.; Maruyama, B.; Persson, K. A.; Aspuru-Guzik, A. Accelerating the Discovery of Materials for Clean Energy in the Era of Smart Automation. Nat. Rev. Mater. 2018, 3, 5− 20. (23) Sanchez-Lengeling, B.; Aspuru-Guzik, A. Inverse Molecular Design Using Machine Learning: Generative Models for Matter Engineering. Science 2018, 361, 360−36. (24) Zunger, A. Inverse Design in Search of Materials with Target Functionalities. Nat. Rev. Chem. 2018, 2, 0121. (25) Ward, L.; Agrawal, A.; Choudhary, A.; Wolverton, C. A General-Purpose Machine Learning Framework for Predicting Properties of Inorganic Materials. npj Comput. Mater. 2016, 2, 16028. (26) Ramprasad, R.; Batra, R.; Pilania, G.; Mannodi-Kanakkithodi, A.; Kim, C. Machine Learning in Materials Informatics: Recent Applications and Prospects. npj Comput. Mater. 2017, 3, 54. (27) Rajan, K. Materials Informatics: The Materials “Gene” and Big Data. Annu. Rev. Mater. Res. 2015, 45, 153−169.
(28) Nandy, A.; Duan, C.; Janet, J. P.; Gugler, S.; Kulik, H. J. Strategies and Software for Machine Learning Accelerated Discovery in Transition Metal Chemistry. Ind. Eng. Chem. Res. 2018, 57, 13973− 13986. (29) Duan, C.; Janet, J. P.; Liu, F.; Nandy, A.; Kulik, H. J. Learning from Failure: Predicting Electronic Structure Calculation Outcomes with Machine Learning Models. J. Chem. Theory Comput. 2019, 15, 2331−2345. (30) Le, T.; Epa, V. C.; Burden, F. R.; Winkler, D. A. Quantitative Structure−Property Relationship Modeling of Diverse Materials Properties. Chem. Rev. 2012, 112, 2889−2919. (31) Rupp, M.; Tkatchenko, A.; Müller, K.-R.; von Lilienfeld, O. A. Fast and Accurate Modeling of Molecular Atomization Energies with Machine Learning. Phys. Rev. Lett. 2012, 108, 058301. (32) Pilania, G.; Wang, C.; Jiang, X.; Rajasekaran, S.; Ramprasad, R. Accelerating Materials Property Predictions Using Machine Learning. Sci. Rep. 2013, 3, 2810.
(33) Meredig, B.; Agrawal, A.; Kirklin, S.; Saal, J. E.; Doak, J. W.; Thompson, A.; Zhang, K.; Choudhary, A.; Wolverton, C. Combinatorial Screening for New Materials in Unconstrained Composition Space with Machine Learning. Phys. Rev. B: Condens. Matter Mater. Phys. 2014, 89, 094104.
(34) Faber, F.; Lindmaa, A.; Von Lilienfeld, O. A.; Armiento, R. Crystal Structure Representations for Machine Learning Models of Formation Energies. Int. J. Quantum Chem. 2015, 115, 1094−1101. (35) Ubaru, S.; Miȩdlar, A.; Saad, Y.; Chelikowsky, J. R. Formation Enthalpies for Transition Metal Alloys Using Machine Learning. Phys. Rev. B: Condens. Matter Mater. Phys. 2017, 95, 214102.
(36) Schütt, K. T.; Glawe, H.; Brockherde, F.; Sanna, A.; Müller, K. R.; Gross, E. K. U. How to Represent Crystal Structures for Machine Learning: Towards Fast Prediction of Electronic Properties. Phys. Rev. B: Condens. Matter Mater. Phys. 2014, 89, 205118.
(37) Dey, P.; Bible, J.; Datta, S.; Broderick, S.; Jasinski, J.; Sunkara, M.; Menon, M.; Rajan, K. Informatics-Aided Bandgap Engineering for Solar Materials. Comput. Mater. Sci. 2014, 83, 185−195. (38) Lee, J.; Seko, A.; Shitara, K.; Nakayama, K.; Tanaka, I. Prediction Model of Band Gap for Inorganic Compounds by Combination of Density Functional Theory Calculations and
ACS Catalysis Review
DOI: 10.1021/acscatal.9b04186 ACS Catal. 2020, 10, 2260−2297
2291


Machine Learning Techniques. Phys. Rev. B: Condens. Matter Mater. Phys. 2016, 93, 115104. (39) Pilania, G.; Mannodi-Kanakkithodi, A.; Uberuaga, B. P.; Ramprasad, R.; Gubernatis, J. E.; Lookman, T. Machine Learning Bandgaps of Double Perovskites. Sci. Rep. 2016, 6, 19375. (40) Legrain, F.; Carrete, J.; van Roekeghem, A.; Curtarolo, S.; Mingo, N. How the Chemical Composition Alone Can Predict Vibrational Free Energies and Entropies of Solids. Chem. Mater. 2017, 29, 6220−6227. (41) Seko, A.; Maekawa, T.; Tsuda, K.; Tanaka, I. Machine Learning with Systematic Density-Functional Theory Calculations: Application to Melting Temperatures of Single- and Binary-Component Solids. Phys. Rev. B: Condens. Matter Mater. Phys. 2014, 89, 054303.
(42) Goldsmith, B. R.; Esterhuizen, J.; Bartel, C. J.; Sutton, C.; Liu, J.-X. Machine Learning for Heterogeneous Catalyst Design and Discovery. AIChE J. 2018, 64, 2311−2323. (43) Hattori, T.; Kito, S.; Murakami, Y. Integration of Catalyst Activity Pattern (INCAP) Artificial Intelligence Approach in Catalyst Design. Chem. Lett. 1988, 17, 1269−1272. (44) Hattori, T.; Kito, S. Artificial Intelligence Approach to Catalyst Design. Catal. Today 1991, 10, 213−222. (45) Kito, S.; Hattori, T.; Murakami, Y. Estimation of the Acid Strength of Mixed Oxides by a Neural Network. Ind. Eng. Chem. Res. 1992, 31, 979−981. (46) Hattori, T.; Kito, S. Neural Network as a Tool for Catalyst Development. Catal. Today 1995, 23, 347−355. (47) Medford, A. J.; Kunz, M. R.; Ewing, S. M.; Borders, T.; Fushimi, R. Extracting Knowledge from Data through Catalysis Informatics. ACS Catal. 2018, 8, 7403−7429. (48) Takahashi, K.; Takahashi, L.; Miyazato, I.; Fujima, J.; Tanaka, Y.; Uno, T.; Satoh, H.; Ohno, K.; Nishida, M.; Hirai, K.; Ohyama, J.; Nguyen, T. N.; Nishimura, S.; Taniike, T. The Rise of Catalyst Informatics: Towards Catalyst Genomics. ChemCatChem 2019, 11, 1146−1152. (49) Kitchin, J. R. Machine Learning in Catalysis. Nat. Catal. 2018, 1, 230−232. (50) Li, Z.; Wang, S.; Xin, H. Toward Artificial Intelligence in Catalysis. Nat. Catal. 2018, 1, 641−642. (51) Schlexer Lamoureux, P.; Winther, K.; Garrido Torres, J. A.; Streibel, V.; Zhao, M.; Bajdich, M.; Abild-Pedersen, F.; Bligaard, T. Machine Learning for Computational Heterogeneous Catalysis. ChemCatChem 2019, 11, 3581−3601.
(52) Freeze, J. G.; Kelly, H. R.; Batista, V. S. Search for Catalysts by Inverse Design: Artificial Intelligence, Mountain Climbers, and Alchemists. Chem. Rev. 2019, 119, 6595−6612. (53) Caruthers, J. M.; Lauterbach, J. A.; Thomson, K. T.; Venkatasubramanian, V.; Snively, C. M.; Bhan, A.; Katare, S.; Oskarsdottir, G. Catalyst Design: Knowledge Extraction from HighThroughput Experimentation. J. Catal. 2003, 216, 98−109. (54) Hand, D. J. Data Science for Financial Applications. In Proceedings of the 24th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining (KDD ’18); ACM: New York, 2018. (55) Domingos, P. A Few Useful Things To Know about Machine Learning. Commun. ACM 2012, 55, 78−87. (56) Wujek, B.; Hall, P.; Güneş, F. Best Practices for Machine Learning Applications; SAS Paper SAS2360-2016; SAS Institute: Cary, NC, 2016. https://support.sas.com/resources/papers/ proceedings16/SAS2360-2016.pdf. (57) Kaufman, S.; Rosset, S.; Perlich, C. Leakage in Data Mining: Formulation, Detection, and Avoidance. In Proceedings of the 17th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining (KDD ’11); ACM: New York, 2011; pp 556−563. (58) Takigawa, I.; Shimizu, K.; Tsuda, K.; Takakusagi, S. MachineLearning Prediction of the d-Band Center for Metals and Bimetals. RSC Adv. 2016, 6, 52587−52595. (59) Takigawa, I.; Shimizu, K.; Tsuda, K.; Takakusagi, S. Machine Learning Predictions of Factors Affecting the Activity of Heterogeneous Metal Catalysts. Nanoinformatics 2018, 45−64.
(60) Caruana, R.; Karampatziakis, N.; Yessenalina, A. An Empirical Evaluation of Supervised Learning in High Dimensions. In Proceedings of the 25th International Conference on Machine Learning (ICML ’08); ACM: New York, 2008; pp 96−103. (61) Fernández-Delgado, M.; Cernadas, E.; Barro, S.; Amorim, D. Do We Need Hundreds of Classifiers to Solve Real World Classification Problems? J. Mach. Learn. Res. 2014, 15, 3133−3181. (62) Nguyen, A.; Yosinski, J.; Clune, J. Deep Neural Networks Are Easily Fooled: High Confidence Predictions for Unrecognizable Images. In 2015 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR); IEEE, 2015.
(63) Cherkasov, A.; Muratov, E. N.; Fourches, D.; Varnek, A.; Baskin, I. I.; Cronin, M.; Dearden, J.; Gramatica, P.; Martin, Y. C.; Todeschini, R.; Consonni, V.; Kuz’min, V. E.; Cramer, R.; Benigni, R.; Yang, C.; Rathman, J.; Terfloth, L.; Gasteiger, J.; Richard, A.; Tropsha, A. QSAR Modeling: Where Have You Been? Where Are You Going To? J. Med. Chem. 2014, 57, 4977−5010. (64) Tropsha, A. Best Practices for QSAR Model Development, Validation, and Exploitation. Mol. Inf. 2010, 29, 476−488. (65) Gromski, P. S.; Henson, A. B.; Granda, J. M.; Cronin, L. How to Explore Chemical Space Using Algorithms and Automation. Nat. Rev. Chem. 2019, 3, 119−128.
(66) Suzuki, K.; Toyao, T.; Maeno, Z.; Takakusagi, S.; Shimizu, K.; Takigawa, I. Statistical Analysis and Discovery of Heterogeneous Catalysts Based on Machine Learning from Diverse Published Data. ChemCatChem 2019, 11, 4537−4547.
(67) Ghahramani, Z. Probabilistic Machine Learning and Artificial Intelligence. Nature 2015, 521, 452−459. (68) Noh, J.; Kim, J.; Stein, H. S.; Sanchez-Lengeling, B.; Gregoire, J. M.; Aspuru-Guzik, A.; Jung, Y. Inverse Design of Solid-State Materials via a Continuous Representation. Matter 2019, 1, 1370−1384. (69) Box, G. E. P. Use and Abuse of Regression. Technometrics 1966, 8, 625−629. (70) Rücker, C.; Rücker, G.; Meringer, M. Y-Randomization and Its Variants in QSPR/QSAR. J. Chem. Inf. Model. 2007, 47, 2345−2357. (71) Hill, J.; Mulholland, G.; Persson, K.; Seshadri, R.; Wolverton, C.; Meredig, B. Materials Science with Large-Scale Data and Informatics: Unlocking New Opportunities. MRS Bull. 2016, 41, 399−409. (72) Belsky, A.; Hellenbrandt, M.; Karen, V. L.; Luksch, P. New Developments in the Inorganic Crystal Structure Database (ICSD): Accessibility in Support of Materials Research and Design. Acta Crystallogr., Sect. B: Struct. Sci. 2002, 58, 364−369.
(73) Xu, Y.; Yamazaki, M.; Villars, P. Inorganic Materials Database for Exploring the Nature of Material. Jpn. J. Appl. Phys. 2011, 50, 11RH02. (74) Jain, A.; Ong, S. P.; Hautier, G.; Chen, W.; Richards, W. D.; Dacek, S.; Cholia, S.; Gunter, D.; Skinner, D.; Ceder, G.; Persson, K. A. Commentary: The Materials Project: A Materials Genome Approach to Accelerating Materials Innovation. APL Mater. 2013, 1, 011002. (75) Saal, J. E.; Kirklin, S.; Aykol, M.; Meredig, B.; Wolverton, C. Materials Design and Discovery with High-Throughput Density Functional Theory: The Open Quantum Materials Database (OQMD). JOM 2013, 65, 1501−1509. (76) Curtarolo, S.; Setyawan, W.; Wang, S.; Xue, J.; Yang, K.; Taylor, R. H.; Nelson, L. J.; Hart, G. L. W.; Sanvito, S.; Buongiorno-Nardelli, M.; Mingo, N.; Levy, O. AFLOWLIB.ORG: A Distributed Materials Properties Repository from High-Throughput Ab Initio Calculations. Comput. Mater. Sci. 2012, 58, 227−235.
(77) Wicker, J. G. P.; Cooper, R. I. Will It Crystallise? Predicting Crystallinity of Molecular Materials. CrystEngComm 2015, 17, 1927− 1934. (78) Bassman, L.; Rajak, P.; Kalia, R. K.; Nakano, A.; Sha, F.; Sun, J.; Singh, D. J.; Aykol, M.; Huck, P.; Persson, K.; Vashishta, P. Active Learning for Accelerated Design of Layered Materials. npj Comput. Mater. 2018, 4, 74.
ACS Catalysis Review
DOI: 10.1021/acscatal.9b04186 ACS Catal. 2020, 10, 2260−2297
2292


(79) Graser, J.; Kauwe, S. K.; Sparks, T. D. Machine Learning and Energy Minimization Approaches for Crystal Structure Predictions: A Review and New Horizons. Chem. Mater. 2018, 30, 3601−3612. (80) Jha, D.; Ward, L.; Paul, A.; Liao, W.-k.; Choudhary, A.; Wolverton, C.; Agrawal, A. ElemNet: Deep Learning the Chemistry of Materials From Only Elemental Composition. Sci. Rep. 2018, 8, 17593. (81) Aykol, M.; Hegde, V. I.; Hung, L.; Suram, S.; Herring, P.; Wolverton, C.; Hummelshøj, J. S. Network Analysis of Synthesizable Materials Discovery. Nat. Commun. 2019, 10, 2018. (82) Braham, E. J.; Cho, J.; Forlano, K. M.; Watson, D. F.; Arròyave, R.; Banerjee, S. Machine Learning-Directed Navigation of Synthetic Design Space: A Statistical Learning Approach to Controlling the Synthesis of Perovskite Halide Nanoplatelets in the QuantumConfined Regime. Chem. Mater. 2019, 31, 3281−3292. (83) Oliynyk, A. O.; Mar, A. Discovery of Intermetallic Compounds from Traditional to Machine-Learning Approaches. Acc. Chem. Res. 2018, 51, 59−68. (84) Oliynyk, A. O.; Adutwum, L. A.; Harynuk, J. J.; Mar, A. Classifying Crystal Structures of Binary Compounds AB through Cluster Resolution Feature Selection and Support Vector Machine Analysis. Chem. Mater. 2016, 28, 6672−6681. (85) Hautier, G.; Fischer, C. C.; Jain, A.; Mueller, T.; Ceder, G. Finding Natures Missing Ternary Oxide Compounds Using Machine Learning and Density Functional Theory. Chem. Mater. 2010, 22, 3762−3767. (86) Kim, E.; Huang, K.; Tomala, A.; Matthews, S.; Strubell, E.; Saunders, A.; McCallum, A.; Olivetti, E. Machine-Learned and Codified Synthesis Parameters of Oxide Materials. Sci. Data 2017, 4, 170127. (87) Kim, E.; Huang, K.; Saunders, A.; McCallum, A.; Ceder, G.; Olivetti, E. Materials Synthesis Insights from Scientific Literature via Text Extraction and Machine Learning. Chem. Mater. 2017, 29, 9436−9444. (88) Caramelli, D.; Salley, D.; Henson, A.; Camarasa, G. A.; Sharabi, S.; Keenan, G.; Cronin, L. Networking Chemical Robots for Reaction Multitasking. Nat. Commun. 2018, 9, 3406. (89) Duros, V.; Grizou, J.; Xuan, W.; Hosni, Z.; Long, D. L.; Miras, H. N.; Cronin, L. Human versus Robots in the Discovery and Crystallization of Gigantic Polyoxometalates. Angew. Chem., Int. Ed. 2017, 56, 10815−10820. (90) Moliner, M.; Román-Leshkov, Y.; Corma, A. Machine Learning Applied to Zeolite Synthesis: The Missing Link for Realizing HighThroughput Discovery. Acc. Chem. Res. 2019, 52, 2971−2980. (91) Muraoka, K.; Sada, Y.; Miyazaki, D.; Chaikittisilp, W.; Okubo, T. Linking Synthesis and Structure Descriptors from a Large Collection of Synthetic Records of Zeolite Materials. Nat. Commun. 2019, 10, 4459. (92) Yang, S.; Lach-hab, M.; Vaisman, I. I.; Blaisten-Barojas, E. Identifying Zeolite Frameworks with a Machine Learning Approach. J. Phys. Chem. C 2009, 113, 21721−21725.
(93) Carr, D. A.; Lach-hab, M.; Yang, S.; Vaisman, I. I.; BlaistenBarojas, E. Machine Learning Approach for Structure-Based Zeolite Classification. Microporous Mesoporous Mater. 2009, 117, 339−349. (94) Lach-hab, M.; Yang, S.; Vaisman, I. I.; Blaisten-Barojas, E. Novel Approach for Clustering Zeolite Crystal Structures. Mol. Inf. 2010, 29, 297−301. (95) Blay, V.; Yokoi, T.; González-Díaz, H. Perturbation Theory− Machine Learning Study of Zeolite Materials Desilication. J. Chem. Inf. Model. 2018, 58, 2414−2419.
(96) Evans, J. D.; Coudert, F. X. Predicting the Mechanical Properties of Zeolite Frameworks by Machine Learning. Chem. Mater. 2017, 29, 7833−7839. (97) Daeyaert, F.; Ye, F.; Deem, M. W. Machine-Learning Approach to the Design of OSDAs for Zeolite Beta. Proc. Natl. Acad. Sci. U. S. A. 2019, 116, 3413−3418. (98) Jensen, Z.; Kim, E.; Kwon, S.; Gani, T. Z. H.; Román-Leshkov, Y.; Moliner, M.; Corma, A.; Olivetti, E. A Machine Learning
Approach to Zeolite Synthesis Enabled by Automatic Literature Data Extraction. ACS Cent. Sci. 2019, 5, 892−899. (99) Raccuglia, P.; Elbert, K. C.; Adler, P. D. F.; Falk, C.; Wenny, M. B.; Mollo, A.; Zeller, M.; Friedler, S. A.; Schrier, J.; Norquist, A. J. Machine-Learning-Assisted Materials Discovery Using Failed Experiments. Nature 2016, 533, 73−76. (100) Vayenas, C. G.; Bebelis, S.; Ladas, S. Dependence of Catalytic Rates on Catalyst Work Function. Nature 1990, 343, 625−627. (101) Shen, X.; Pan, Y.; Liu, B.; Yang, J.; Zeng, J.; Peng, Z. More Accurate Depiction of Adsorption Energy on Transition Metals Using Work Function as One Additional Descriptor. Phys. Chem. Chem. Phys. 2017, 19, 12628−12632. (102) Ruban, A.; Hammer, B.; Stoltze, P.; Skriver, H. L.; Nørskov, J. K. Surface Electronic Structure and Reactivity of Transition and Noble Metals. J. Mol. Catal. A: Chem. 1997, 115, 421−429.
(103) Calle-Vallejo, F.; Tymoczko, J.; Colic, V.; Vu, Q. H.; Pohl, M. D.; Morgenstern, K.; Loffreda, D.; Sautet, P.; Schuhmann, W.; Bandarenka, A. S. Finding Optimal Surface Sites on Heterogeneous Catalysts by Counting Nearest Neighbors. Science 2015, 350, 185− 189. (104) Zhuang, H.; Tkalych, A. J.; Carter, E. A. Surface Energy as a Descriptor of Catalytic Activity. J. Phys. Chem. C 2016, 120, 23698− 23706. (105) Kitchin, J. R.; Nørskov, J. K.; Barteau, M. A.; Chen, J. G. Role of Strain and Ligand Effects in the Modification of the Electronic and Chemical Properties of Bimetallic Surfaces. Phys. Rev. Lett. 2004, 93, 156801. (106) Greeley, J. Theoretical Heterogeneous Catalysis: Scaling Relationships and Computational Catalyst Design. Annu. Rev. Chem. Biomol. Eng. 2016, 7, 605−635.
(107) Calle-Vallejo, F.; Loffreda, D.; Koper, M. T. M.; Sautet, P. Introducing Structural Sensitivity into Adsorption−Energy Scaling Relations by Means of Coordination Numbers. Nat. Chem. 2015, 7, 403−410. (108) Kumar, G.; Lau, S. L. J.; Krcha, M. D.; Janik, M. J. Correlation of Methane Activation and Oxide Catalyst Reducibility and Its Implications for Oxidative Coupling. ACS Catal. 2016, 6, 1812−1821. (109) Huang, B.; Xiao, L.; Lu, J.; Zhuang, L. Spatially Resolved Quantification of the Surface Reactivity of Solid Catalysts. Angew. Chem., Int. Ed. 2016, 55, 6239−6243.
(110) Capdevila-Cortada, M.; Vilé, G.; Teschner, D.; Pérez-Ramírez, J.; López, N. Reactivity Descriptors for Ceria in Catalysis. Appl. Catal., B 2016, 197, 299−312. (111) Wang, P.; Fu, G.; Wan, H. How High Valence Transition Metal Spreads Its Activity over Nonmetal Oxoes: A Proof-of-Concept Study. ACS Catal. 2017, 7, 5544−5548. (112) Studt, F.; Abild-Pedersen, F.; Bligaard, T.; Sørensen, R. Z.; Christensen, C. H.; Nørskov, J. K. Identification of Non-Precious Metal Alloy Catalysts for Selective Hydrogenation of Acetylene. Science 2008, 320, 1320−1322.
(113) Studt, F.; Sharafutdinov, I.; Abild-Pedersen, F.; Elkjær, C. F.; Hummelshøj, J. S.; Dahl, S.; Chorkendorff, I.; Nørskov, J. K. Discovery of a Ni-Ga Catalyst for Carbon Dioxide Reduction to Methanol. Nat. Chem. 2014, 6, 320−324. (114) Fernández, E. M.; Moses, P. G.; Toftelund, A.; Hansen, H. A.; Martínez, J. I.; Abild-Pedersen, F.; Kleis, J.; Hinnemann, B.; Rossmeisl, J.; Bligaard, T.; Nørskov, J. K. Scaling Relationships for Adsorption Energies on Transition Metal Oxide, Sulfide, and Nitride Surfaces. Angew. Chem., Int. Ed. 2008, 47, 4683−4686.
(115) Vojvodic, A.; Hellman, A.; Ruberto, C.; Lundqvist, B. I. From Electronic Structure to Catalytic Activity: A Single Descriptor for Adsorption and Reactivity on Transition-Metal Carbides. Phys. Rev. Lett. 2009, 103, 146103.
(116) Calle-Vallejo, F.; Inoglu, N. G.; Su, H. Y.; Martínez, J. I.; Man, I. C.; Koper, M. T. M.; Kitchin, J. R.; Rossmeisl, J. Number of Outer Electrons as Descriptor for Adsorption Processes on Transition Metals and Their Oxides. Chem. Sci. 2013, 4, 1245−1249. (117) Kakekhani, A.; Roling, L. T.; Kulkarni, A.; Latimer, A. A.; Abroshan, H.; Schumann, J.; Aljama, H.; Siahrostami, S.; Ismail-Beigi,
ACS Catalysis Review
DOI: 10.1021/acscatal.9b04186 ACS Catal. 2020, 10, 2260−2297
2293


S.; Abild-Pedersen, F.; Nørskov, J. K. Nature of Lone-Pair-Surface Bonds and Their Scaling Relations. Inorg. Chem. 2018, 57, 7222− 7238. (118) Kamachi, T.; Tatsumi, T.; Toyao, T.; Hinuma, Y.; Maeno, Z.; Takakusagi, S.; Furukawa, S.; Takigawa, I.; Shimizu, K. Linear Correlations between Adsorption Energies and HOMO Levels for the Adsorption of Small Molecules on TiO2 Surfaces. J. Phys. Chem. C 2019, 123, 20988−20997. (119) Ruiz Puigdollers, A.; Schlexer, P.; Tosoni, S.; Pacchioni, G. Increasing Oxide Reducibility: The Role of Metal/Oxide Interfaces in the Formation of Oxygen Vacancies. ACS Catal. 2017, 7, 6493−6513. (120) Jia, J.; Qian, C.; Dong, Y.; Li, Y. F.; Wang, H.; Ghoussoub, M.; Butler, K. T.; Walsh, A.; Ozin, G. A. Heterogeneous Catalytic Hydrogenation of CO2 by Metal Oxides: Defect Engineering − Perfecting Imperfection. Chem. Soc. Rev. 2017, 46, 4631−4644. (121) Lee, Y.-L.; Kleis, J.; Rossmeisl, J.; Yang, S.-H.; Morgan, D. Prediction of Solid Oxide Fuel Cell Cathode Activity with FirstPrinciples Descriptors. Energy Environ. Sci. 2011, 4, 3966−3970. (122) Curnan, M. T.; Kitchin, J. R. Effects of Concentration, Crystal Structure, Magnetism, and Electronic Structure Method on FirstPrinciples Oxygen Vacancy Formation Energy Trends in Perovskites. J. Phys. Chem. C 2014, 118, 28776−28790.
(123) Staykov, A.; Téllez, H.; Akbay, T.; Druce, J.; Ishihara, T.; Kilner, J. Oxygen Activation and Dissociation on Transition Metal Free Perovskite Surfaces. Chem. Mater. 2015, 27, 8273−8281. (124) Chen, C.; Ciucci, F. Designing Fe-Based Oxygen Catalysts by Density Functional Theory Calculations. Chem. Mater. 2016, 28, 7058−7065. (125) Emery, A. A.; Saal, J. E.; Kirklin, S.; Hegde, V. I.; Wolverton, C. High-Throughput Computational Screening of Perovskites for Thermochemical Water Splitting Applications. Chem. Mater. 2016, 28, 5621−5634. (126) Hinuma, Y.; Toyao, T.; Kamachi, T.; Maeno, Z.; Takakusagi, S.; Furukawa, S.; Takigawa, I.; Shimizu, K. Density Functional Theory Calculations of Oxygen Vacancy Formation and Subsequent Molecular Adsorption on Oxide Surfaces. J. Phys. Chem. C 2018, 122, 29435−29444. (127) Pankajakshan, P.; Sanyal, S.; De Noord, O. E.; Bhattacharya, I.; Bhattacharyya, A.; Waghmare, U. Machine Learning and Statistical Analysis for Materials Science: Stability and Transferability of Fingerprint Descriptors and Chemical Insights. Chem. Mater. 2017, 29, 4190−4201. (128) Tanabe, K.; Hölderich, W. F. Industrial Application of Solid Acid-Base Catalysts. Appl. Catal., A 1999, 181, 399−434. (129) Digne, M.; Sautet, P.; Raybaud, P.; Euzen, P.; Toulhoat, H. Use of DFT to Achieve a Rational Understanding of Acid-Basic Properties of γ-Alumina Surfaces. J. Catal. 2004, 226, 54−68. (130) Jenness, G. R.; Christiansen, M. A.; Caratzoulas, S.; Vlachos, D. G.; Gorte, R. J. Site-Dependent Lewis Acidity of γ-Al2O3 and Its Impact on Ethanol Dehydration and Etherification. J. Phys. Chem. C 2014, 118, 12899−12907. (131) Cholewinski, M. C.; Dixit, M.; Mpourmpakis, G. Computational Study of Methane Activation on γ-Al2O3. ACS Omega 2018, 3, 18242−18250. (132) Bhan, A.; Iglesia, E. A Link between Reactivity and Local Structure in Acid Catalysis on Zeolites. Acc. Chem. Res. 2008, 41, 559−567. (133) Liu, C.; Tranca, I.; van Santen, R. A.; Hensen, E. J. M.; Pidko, E. A. Scaling Relations for Acidity and Reactivity of Zeolites. J. Phys. Chem. C 2017, 121, 23520−23530. (134) Matsuoka, T.; Baumes, L.; Katada, N.; Chatterjee, A.; Sastre, G. Selecting Strong Brønsted Acid Zeolites through Screening from a Database of Hypothetical Frameworks. Phys. Chem. Chem. Phys. 2017, 19, 14702−14707. (135) Davran-Candan, T.; Günay, M. E.; Yildirim, R. Structure and Activity Relationship for CO and O2 Adsorption over Gold Nanoparticles Using Density Functional Theory and Artificial Neural Networks. J. Chem. Phys. 2010, 132, 174113.
(136) Li, Z.; Wang, S.; Chin, W. S.; Achenie, L. E.; Xin, H. HighThroughput Screening of Bimetallic Catalysts Enabled by Machine Learning. J. Mater. Chem. A 2017, 5, 24131−24138. (137) Ma, X.; Li, Z.; Achenie, L. E. K.; Xin, H. Machine-LearningAugmented Chemisorption Model for CO2 Electroreduction Catalyst
Screening. J. Phys. Chem. Lett. 2015, 6, 3528−3533. (138) Noh, J.; Back, S.; Kim, J.; Jung, Y. Active Learning with NonAb Initio Input Features toward Efficient CO2 Reduction Catalysts.
Chem. Sci. 2018, 9, 5152−5159.
(139) Andersen, M.; Levchenko, S. V.; Scheffler, M.; Reuter, K. Beyond Scaling Relations for the Description of Catalytic Materials. ACS Catal. 2019, 9, 2752−2759.
(140) Jäger, M. O. J.; Morooka, E. V.; Federici Canova, F.; Himanen, L.; Foster, A. S. Machine Learning Hydrogen Adsorption on Nanoclusters through Structural Descriptors. npj Comput. Mater. 2018, 4, 37.
(141) Back, S.; Yoon, J.; Tian, N.; Zhong, W.; Tran, K.; Ulissi, Z. W. Convolutional Neural Network of Atomic Surface Structures to Predict Binding Energies for High-Throughput Screening of Catalysts. J. Phys. Chem. Lett. 2019, 10, 4401−4408.
(142) Chowdhury, A. J.; Yang, W.; Walker, E.; Mamun, O.; Heyden, A.; Terejanu, G. A. Prediction of Adsorption Energies for Chemical Species on Metal Catalyst Surfaces Using Machine Learning. J. Phys. Chem. C 2018, 122, 28142−28150. (143) Hoyt, R. A.; Montemore, M. M.; Fampiou, I.; Chen, W.; Tritsaris, G.; Kaxiras, E. Machine Learning Prediction of H Adsorption Energies on Ag Alloys. J. Chem. Inf. Model. 2019, 59, 1357−1365. (144) García-Muelas, R.; López, N. Statistical Learning Goes beyond the D-Band Model Providing the Thermochemistry of Adsorbates on Transition Metals. Nat. Commun. 2019, 10, 4687. (145) Gasper, R.; Shi, H.; Ramasubramaniam, A. Adsorption of CO on Low-Energy, Low-Symmetry Pt Nanoparticles: Energy Decomposition Analysis and Prediction via Machine-Learning Models. J. Phys. Chem. C 2017, 121, 5612−5619.
(146) Göltl, F.; Müller, P.; Uchupalanun, P.; Sautet, P.; Hermans, I. Developing a Descriptor-Based Approach for CO and NO Adsorption Strength to Transition Metal Sites in Zeolites. Chem. Mater. 2017, 29, 6434−6444. (147) Jinnouchi, R.; Asahi, R. Predicting Catalytic Activity of Nanoparticles by a DFT-Aided Machine-Learning Algorithm. J. Phys. Chem. Lett. 2017, 8, 4279−4283.
(148) Jinnouchi, R.; Hirata, H.; Asahi, R. Extrapolating Energetics on Clusters and Single-Crystal Surfaces to Nanoparticles by MachineLearning Scheme. J. Phys. Chem. C 2017, 121, 26397−26405. (149) Ulissi, Z. W.; Tang, M. T.; Xiao, J.; Liu, X.; Torelli, D. A.; Karamad, M.; Cummins, K.; Hahn, C.; Lewis, N. S.; Jaramillo, T. F.; Chan, K.; Nørskov, J. K. Machine-Learning Methods Enable Exhaustive Searches for Active Bimetallic Facets and Reveal Active Site Motifs for CO2 Reduction. ACS Catal. 2017, 7, 6600−6608. (150) Tran, K.; Ulissi, Z. W. Active Learning across Intermetallics To Guide Discovery of Electrocatalysts for CO2 Reduction and H2
Evolution. Nat. Catal. 2018, 1, 696−703. (151) Toyao, T.; Suzuki, K.; Kikuchi, S.; Takakusagi, S.; Shimizu, K.; Takigawa, I. Toward Effective Utilization of Methane: Machine Learning Prediction of Adsorption Energies on Metal Alloys. J. Phys. Chem. C 2018, 122, 8315−8326. (152) Wexler, R. B.; Martirez, J. M. P.; Rappe, A. M. Chemical Pressure-Driven Enhancement of the Hydrogen Evolving Activity of Ni2P from Nonmetal Surface Doping Interpreted via Machine
Learning. J. Am. Chem. Soc. 2018, 140, 4678−4683. (153) O’Connor, N. J.; Jonayat, A. S. M.; Janik, M. J.; Senftle, T. P. Interaction Trends between Single Metal Atoms and Oxide Supports Identified with Density Functional Theory and Statistical Learning. Nat. Catal. 2018, 1, 531−539.
(154) Castelli, I. E.; Hüser, F.; Pandey, M.; Li, H.; Thygesen, K. S.; Seger, B.; Jain, A.; Persson, K. A.; Ceder, G.; Jacobsen, K. W. New Light-Harvesting Materials Using Accurate and Efficient Bandgap Calculations. Adv. Energy Mater. 2015, 5, 1400915.
ACS Catalysis Review
DOI: 10.1021/acscatal.9b04186 ACS Catal. 2020, 10, 2260−2297
2294


(155) Mishra, A.; Satsangi, S.; Rajan, A. C.; Mizuseki, H.; Lee, K. R.; Singh, A. K. Accelerated Data-Driven Accurate Positioning of the Band Edges of MXenes. J. Phys. Chem. Lett. 2019, 10, 780−785. (156) Ulissi, Z. W.; Singh, A. R.; Tsai, C.; Nørskov, J. K. Automated Discovery and Construction of Surface Phase Diagrams Using Machine Learning. J. Phys. Chem. Lett. 2016, 7, 3931−3935. (157) Timoshenko, J.; Frenkel, A. I. ”Inverting” X-ray Absorption Spectra of Catalysts by Machine Learning in Search for Activity Descriptors. ACS Catal. 2019, 9, 10192−10211. (158) Liu, J.; Osadchy, M.; Ashton, L.; Foster, M.; Solomon, C. J.; Gibson, S. J. Deep Convolutional Neural Networks for Raman Spectrum Recognition: A Unified Solution. Analyst 2017, 142, 4067− 4074. (159) Ito, K.; Obuchi, Y.; Chikayama, E.; Date, Y.; Kikuchi, J. Exploratory Machine-Learned Theoretical Chemical Shifts Can Closely Predict Metabolic Mixture Signals. Chem. Sci. 2018, 9, 8213−8220. (160) Ghosh, K.; Stuke, A.; Todorović, M.; Jørgensen, P. B.; Schmidt, M. N.; Vehtari, A.; Rinke, P. Deep Learning Spectroscopy: Neural Networks for Molecular Excitation Spectra. Adv. Sci. 2019, 6, 1801367. (161) Asakura, K.; Abe, H.; Kimura, M. The Challenge of Constructing an International XAFS Database. J. Synchrotron Radiat. 2018, 25, 967−971. (162) Zheng, C.; Mathew, K.; Chen, C.; Chen, Y.; Tang, H.; Dozier, A.; Kas, J. J.; Vila, F. D.; Rehr, J. J.; Piper, L. F. J.; Persson, K. A.; Ong, S. P. Automated Generation and Ensemble-Learned Matching of Xray Absorption Spectra. npj Comput. Mater. 2018, 4, 12. (163) Mathew, K.; Zheng, C.; Winston, D.; Chen, C.; Dozier, A.; Rehr, J. J.; Ong, S. P.; Persson, K. A. Data Descriptor: HighThroughput Computational X-ray Absorption Spectroscopy. Sci. Data 2018, 5, 180151. (164) Kiyohara, S.; Miyata, T.; Tsuda, K.; Mizoguchi, T. DataDriven Approach for the Prediction and Interpretation of CoreElectron Loss Spectroscopy. Sci. Rep. 2018, 8, 13548. (165) Suzuki, Y.; Hino, H.; Kotsugi, M.; Ono, K. Automated Estimation of Materials Parameter from X-ray Absorption and Electron Energy-Loss Spectra with Similarity Measures. npj Comput. Mater. 2019, 5, 39.
(166) Timoshenko, J.; Lu, D.; Lin, Y.; Frenkel, A. I. Supervised Machine-Learning-Based Determination of Three-Dimensional Structure of Metallic Nanoparticles. J. Phys. Chem. Lett. 2017, 8, 5091− 5098. (167) Timoshenko, J.; Halder, A.; Yang, B.; Seifert, S.; Pellin, M. J.; Vajda, S.; Frenkel, A. I. Subnanometer Substructures in Nanoassemblies Formed from Clusters under a Reactive Atmosphere Revealed Using Machine Learning. J. Phys. Chem. C 2018, 122, 21686−21693. (168) Akai, I.; Iwamitsu, K.; Igarashi, Y.; Okada, M.; Setoyama, H.; Okajima, T.; Hirai, Y. Sparse Modeling of an Extended X-ray Absorption Fine-Structure Spectrum Based on a Single-Scattering Formalism. J. Phys. Soc. Jpn. 2018, 87, 074003. (169) Carbone, M. R.; Yoo, S.; Topsakal, M.; Lu, D. Classification of Local Chemical Environments from X-ray Absorption Spectra Using Supervised Machine Learning. Phys. Rev. Mater. 2019, 3, 033604. (170) Guda, A. A.; Guda, S. A.; Lomachenko, K. A.; Soldatov, M. A.; Pankin, I. A.; Soldatov, A. V.; Braglia, L.; Bugaev, A. L.; Martini, A.; Signorile, M.; Groppo, E.; Piovano, A.; Borfecchia, E.; Lamberti, C. Quantitative Structural Determination of Active Sites from In Situ and Operando XANES Spectra: From Standard Ab Initio Simulations to Chemometric and Machine Learning Approaches. Catal. Today 2019, 336, 3−21. (171) Miyazato, I.; Takahashi, L.; Takahashi, K. Automatic Oxidation Threshold Recognition of XAFS Data Using Supervised Machine Learning. Mol. Syst. Des. Eng. 2019, 4, 1014−1018. (172) Madsen, J.; Liu, P.; Kling, J.; Wagner, J. B.; Hansen, T. W.; Winther, O.; Schiøtz, J. A Deep Learning Approach to Identify Local Structures in Atomic-Resolution Transmission Electron Microscopy Images. Adv. Theory Simul. 2018, 1, 1800037.
(173) Ziatdinov, M.; Dyck, O.; Maksov, A.; Li, X.; Sang, X.; Xiao, K.; Unocic, R. R.; Vasudevan, R.; Jesse, S.; Kalinin, S. V. Deep Learning of Atomically Resolved Scanning Transmission Electron Microscopy Images: Chemical Identification and Tracking Local Transformations. ACS Nano 2017, 11, 12742−12752. (174) Vasudevan, R. K.; Laanait, N.; Ferragut, E. M.; Wang, K.; Geohegan, D. B.; Xiao, K.; Ziatdinov, M.; Jesse, S.; Dyck, O.; Kalinin, S. V. Mapping Mesoscopic Phase Evolution during E-Beam Induced Transformations via Deep Learning of Atomically Resolved Images. npj Comput. Mater. 2018, 4, 30.
(175) Belianinov, A.; He, Q.; Kravchenko, M.; Jesse, S.; Borisevich, A.; Kalinin, S. V. Identification of Phases, Symmetries and Defects through Local Crystallography. Nat. Commun. 2015, 6, 7801. (176) Rossouw, D.; Burdet, P.; De La Peña, F.; Ducati, C.; Knappett, B. R.; Wheatley, A. E. H.; Midgley, P. A. Multicomponent Signal Unmixing from Nanoheterostructures: Overcoming the Traditional Challenges of Nanoscale X-ray Analysis via Machine Learning. Nano Lett. 2015, 15, 2716−2720. (177) Shiga, M.; Tatsumi, K.; Muto, S.; Tsuda, K.; Yamamoto, Y.; Mori, T.; Tanji, T. Sparse Modeling of EELS and EDX Spectral Imaging Data by Nonnegative Matrix Factorization. Ultramicroscopy 2016, 170, 43−59. (178) Hummelshøj, J. S.; Abild-Pedersen, F.; Studt, F.; Bligaard, T.; Nørskov, J. K. CatApp: A Web Application for Surface Chemistry and Heterogeneous Catalysis. Angew. Chem., Int. Ed. 2012, 51, 272−274. (179) Winther, K. T.; Hoffmann, M. J.; Boes, J. R.; Mamun, O.; Bajdich, M.; Bligaard, T. Catalysis-Hub.Org, an Open Electronic Structure Database for Surface Reactions. Sci. Data 2019, 6, 75. (180) Holeňa, M.; Baerns, M. Feedforward Neural Networks in Catalysis: A Tool for the Approximation of the Dependency of Yield on Catalyst Composition, and for Knowledge Extraction. Catal. Today 2003, 81, 485−494. (181) Serra, J. M.; Corma, A.; Chica, A.; Argente, E.; Botti, V. Can Artificial Neural Networks Help the Experimentation in Catalysis? Catal. Today 2003, 81, 393−403.
(182) Huang, K.; Zhan, X. L.; Chen, F. Q.; Lü, D. W. Catalyst Design for Methane Oxidative Coupling by Using Artificial Neural Network and Hybrid Genetic Algorithm. Chem. Eng. Sci. 2003, 58, 81−87. (183) Umegaki, T.; Watanabe, Y.; Nukui, N.; Omata, K.; Yamada, M. Optimization of Catalyst for Methanol Synthesis by a Combinatorial Approach Using a Parallel Activity Test and Genetic Algorithm Assisted by a Neural Network. Energy Fuels 2003, 17, 850− 856. (184) Omata, K.; Watanabe, Y.; Hashimoto, M.; Umegaki, T.; Yamada, M. Simultaneous Optimization of Preparation Conditions and Composition of the Methanol Synthesis Catalyst by an AllEncompassing Calculation on an Artificial Neural Network. Ind. Eng. Chem. Res. 2004, 43, 3282−3288.
(185) Corma, A.; Serra, J. M.; Serna, P.; Valero, S.; Argente, E.; Botti, V. Optimisation of Olefin Epoxidation Catalysts with the Application of High-Throughput and Genetic Algorithms Assisted by Artificial Neural Networks (Softcomputing Techniques). J. Catal. 2005, 229, 513−524. (186) Baumes, L. A.; Serra, J. M.; Serna, P.; Corma, A. Support Vector Machines for Predictive Modeling in Heterogeneous Catalysis: A Comprehensive Introduction and Overfitting Investigation Based on Two Real Applications. J. Comb. Chem. 2006, 8, 583−596. (187) Le, T. C.; Winkler, D. A. Discovery and Optimization of Materials Using Evolutionary Approaches. Chem. Rev. 2016, 116, 6107−6132. (188) Rothenberg, G. Data Mining in Catalysis: Separating Knowledge from Garbage. Catal. Today 2008, 137, 2−10. (189) Zavyalova, U.; Holena, M.; Schlögl, R.; Baerns, M. Statistical Analysis of Past Catalytic Data on Oxidative Methane Coupling for New Insights into the Composition of High-Performance Catalysts. ChemCatChem 2011, 3, 1935−1947.
(190) Kondratenko, E. V.; Schlüter, M.; Baerns, M.; Linke, D.; Holena, M. Developing Catalytic Materials for the Oxidative
ACS Catalysis Review
DOI: 10.1021/acscatal.9b04186 ACS Catal. 2020, 10, 2260−2297
2295


Coupling of Methane through Statistical Analysis of Literature Data. Catal. Sci. Technol. 2015, 5, 1668−1677.
(191) Takahashi, K.; Miyazato, I.; Nishimura, S.; Ohyama, J. Unveiling Hidden Catalysts for the Oxidative Coupling of Methane Based on Combining Machine Learning with Literature Data. ChemCatChem 2018, 10, 3223−3228.
(192) Schmack, R.; Friedrich, A.; Kondratenko, E. V.; Polte, J.; Werwatz, A.; Kraehnert, R. A Meta-Analysis of Catalytic Literature Data Reveals Property-Performance Correlations for the OCM Reaction. Nat. Commun. 2019, 10, 441. (193) Ohyama, J.; Nishimura, S.; Takahashi, K. Data Driven Determination of Reaction Conditions in Oxidative Coupling of Methane via Machine Learning. ChemCatChem 2019, 11, 4307−4313. (194) Baysal, M.; Günay, M. E.; Yıldırım, R. Decision Tree Analysis of Past Publications on Catalytic Steam Reforming to Develop Heuristics for High Performance: A Statistical Review. Int. J. Hydrogen Energy 2017, 42, 243−254.
(195) Şener, A. N.; Günay, M. E.; Leba, A.; Yıldırım, R. Statistical Review of Dry Reforming of Methane Literature Using Decision Tree and Artificial Neural Network Analysis. Catal. Today 2018, 299, 289− 302. (196) Günay, M. E.; Yildirim, R. Knowledge Extraction from Catalysis of the Past: A Case of Selective CO Oxidation over Noble Metal Catalysts between 2000 and 2012. ChemCatChem 2013, 5, 1395−1406. (197) Günay, M. E.; Yildirim, R. Neural Network Analysis of Selective CO Oxidation over Copper-Based Catalysts for Knowledge Extraction from Published Data in the Literature. Ind. Eng. Chem. Res. 2011, 50, 12488−12500. (198) Günay, M. E.; Yildirim, R. Developing Global Reaction Rate Model for CO Oxidation over Au Catalysts from Past Data in Literature Using Artificial Neural Networks. Appl. Catal., A 2013, 468, 395−402. (199) Odabaşi, Ç .; Günay, M. E.; Yildirim, R. Knowledge Extraction for Water Gas Shift Reaction over Noble Metal Catalysts from Publications in the Literature between 2002 and 2012. Int. J. Hydrogen Energy 2014, 39, 5733−5746. (200) Omata, K. Screening of New Additives of Active-CarbonSupported Heteropoly Acid Catalyst for Friedel−Crafts Reaction by Gaussian Process Regression. Ind. Eng. Chem. Res. 2011, 50, 10948− 10954. (201) Ras, E. J.; Louwerse, M. J.; Rothenberg, G. New Tricks by Very Old Dogs: Predicting the Catalytic Hydrogenation of HMF Derivatives Using Slater-Type Orbitals. Catal. Sci. Technol. 2012, 2, 2456−2464. (202) Alper Tapan, N.; Yıldırım, R.; Günay, M. E. Analysis of Past Experimental Data in Literature to Determine Conditions for High Performance in Biodiesel Production. Biofuels, Bioprod. Biorefin. 2016, 10, 422−434. (203) Madaan, N.; Shiju, N. R.; Rothenberg, G. Predicting the Performance of Oxidation Catalysts Using Descriptor Models. Catal. Sci. Technol. 2016, 6, 125−133.
(204) Rodemerck, U.; Holeňa, M.; Wagner, E.; Smejkal, Q.; Barkschat, A.; Baerns, M. Catalyst Development for CO2 Hydro
genation to Fuels. ChemCatChem 2013, 5, 1948−1955. (205) Günay, M. E.; Türker, L.; Tapan, N. A. Decision Tree Analysis for Efficient CO2 Utilization in Electrochemical Systems. J. CO2 Util.
2018, 28, 83−95. (206) Hong, W. T.; Welsch, R. E.; Shao-Horn, Y. Descriptors of Oxygen-Evolution Activity for Oxides: A Statistical Evaluation. J. Phys. Chem. C 2016, 120, 78−86.
(207) Palkovits, R.; Palkovits, S. Using Artificial Intelligence To Forecast Water Oxidation Catalysts. ACS Catal. 2019, 9, 8383−8387. (208) Masood, H.; Toe, C. Y.; Teoh, W. Y.; Sethu, V.; Amal, R. Machine Learning for Accelerated Discovery of Solar Photocatalysts. ACS Catal. 2019, 9, 11774−11787. (209) Can, E.; Yildirim, R. Data Mining in Photocatalytic Water Splitting over Perovskites Literature for Higher Hydrogen Production. Appl. Catal., B 2019, 242, 267−283.
(210) Hansch, C.; Leo, A.; Taft, R. W. A Survey of Hammett Substituent Constants and Resonance and Field Parameters. Chem. Rev. 1991, 91, 165−195. (211) Tolman, C. A. Steric Effects of Phosphorus Ligands in Organometallic Chemistry and Homogeneous Catalysis. Chem. Rev. 1977, 77, 313−348. (212) Fey, N.; Orpen, A. G.; Harvey, J. N. Building Ligand Knowledge Bases for Organometallic Chemistry: Computational Description of Phosphorus(III)-Donor Ligands and the MetalPhosphorus Bond. Coord. Chem. Rev. 2009, 253, 704−722. (213) Fey, N. The Contribution of Computational Studies to Organometallic Catalysis: Descriptors, Mechanisms and Models. Dalton Trans. 2010, 39, 296−310.
(214) Jover, J.; Fey, N. The Computational Road to Better Catalysts. Chem. - Asian J. 2014, 9, 1714−1723.
(215) Milo, A.; Neel, A. J.; Toste, F. D.; Sigman, M. S. A DataIntensive Approach to Mechanistic Elucidation Applied to Chiral Anion Catalysis. Science 2015, 347, 737−743. (216) Sigman, M. S.; Harper, K. C.; Bess, E. N.; Milo, A. The Development of Multidimensional Analysis Tools for Asymmetric Catalysis and Beyond. Acc. Chem. Res. 2016, 49, 1292−1301. (217) Reid, J. P.; Sigman, M. S. Comparing Quantitative Prediction Methods for the Discovery of Small-Molecule Chiral Catalysts. Nat. Rev. Chem. 2018, 2, 290−305.
(218) Santiago, C. B.; Guo, J. Y.; Sigman, M. S. Predictive and Mechanistic Multivariate Linear Regression Models for Reaction Development. Chem. Sci. 2018, 9, 2398−2412. (219) Bess, E. N.; Bischoff, A. J.; Sigman, M. S. Designer Substrate Library for Quantitative, Predictive Modeling of Reaction Performance. Proc. Natl. Acad. Sci. U. S. A. 2014, 111, 14698−14703.
(220) Burello, E.; Farrusseng, D.; Rothenberg, G. Combinatorial Explosion in Homogeneous Catalysis: Screening 60,000 CrossCoupling Reactions. Adv. Synth. Catal. 2004, 346, 1844−1853. (221) Hageman, J. A.; Westerhuis, J. A.; Frühauf, H. W.; Rothenberg, G. Design and Assembly of Virtual Homogeneous Catalyst Libraries - Towards In Silico Catalyst Optimisation. Adv. Synth. Catal. 2006, 348, 361−369.
(222) Maldonado, A. G.; Rothenberg, G. Predictive Modeling in Homogeneous Catalysis: A Tutorial. Chem. Soc. Rev. 2010, 39, 1891− 1902. (223) Kreutz, J. E.; Shukhaev, A.; Du, W.; Druskin, S.; Daugulis, O.; Ismagilov, R. F. Evolution of Catalysts Directed by Genetic Algorithms in a Plug-Based Microfluidic Device Tested with Oxidation of Methane by Oxygen. J. Am. Chem. Soc. 2010, 132, 3128−3132. (224) Occhipinti, G.; Bjørsvik, H. R.; Jensen, V. R. Quantitative Structure-Activity Relationships of Ruthenium Catalysts for Olefin Metathesis. J. Am. Chem. Soc. 2006, 128, 6952−6964. (225) Milo, A.; Neel, A. J.; Toste, F. D.; Sigman, M. S. A DataIntensive Approach to Mechanistic Elucidation Applied to Chiral Anion Catalysis. Science 2015, 347, 737−743. (226) Zahrt, A. F.; Henle, J. J.; Rose, B. T.; Wang, Y.; Darrow, W. T.; Denmark, S. E. Prediction of Higher-Selectivity Catalysts by Computer-Driven Workflow and Machine Learning. Science 2019, 363, eaau5631. (227) Meyer, B.; Sawatlon, B.; Heinen, S.; Von Lilienfeld, O. A.; Corminboeuf, C. Machine Learning Meets Volcano Plots: Computational Discovery of Cross-Coupling Catalysts. Chem. Sci. 2018, 9, 7069−7077. (228) Yada, A.; Nagata, K.; Ando, Y.; Matsumura, T.; Ichinoseki, S.; Sato, K. Machine Learning Approach for Prediction of Reaction Yield with Simulated Catalyst Parameters. Chem. Lett. 2018, 47, 284−287. (229) Wu, K.; Doyle, A. G. Parameterization of Phosphine Ligands Demonstrates Enhancement of Nickel Catalysis via Remote Steric Effects. Nat. Chem. 2017, 9, 779−784. (230) Rosales, A. R.; Wahlers, J.; Limé, E.; Meadows, R. E.; Leslie, K. W.; Savin, R.; Bell, F.; Hansen, E.; Helquist, P.; Munday, R. H.; Wiest, O.; Norrby, P. O. Rapid Virtual Screening of Enantioselective Catalysts Using CatVS. Nat. Catal. 2019, 2, 41−45.
ACS Catalysis Review
DOI: 10.1021/acscatal.9b04186 ACS Catal. 2020, 10, 2260−2297
2296


(231) Landman, I. R.; Paulson, E. R.; Rheingold, A. L.; Grotjahn, D. B.; Rothenberg, G. Designing Bifunctional Alkene Isomerization Catalysts Using Predictive Modelling. Catal. Sci. Technol. 2017, 7, 4842−4851. (232) Banerjee, S.; Sreenithya, A.; Sunoj, R. B. Machine Learning for Predicting Product Distributions in Catalytic Regioselective Reactions. Phys. Chem. Chem. Phys. 2018, 20, 18311−18318.
(233) Amar, Y.; Schweidtmann, A. M.; Deutsch, P.; Cao, L.; Lapkin, A. Machine Learning and Molecular Descriptors Enable Rational Solvent Selection in Asymmetric Catalysis. Chem. Sci. 2019, 10, 6697−6706. (234) Yamaguchi, S.; Sodeoka, M. Molecular Field Analysis Using Intermediates in Enantio-Determining Steps Can Extract Information for Data-Driven Molecular Design in Asymmetric Catalysis. Bull. Chem. Soc. Jpn. 2019, 92, 1701−1706.
(235) Sasmaz, E.; Mingle, K.; Lauterbach, J. High-Throughput Screening Using Fourier-Transform Infrared Imaging. Engineering 2015, 1, 234−242. (236) Katare, S.; Caruthers, J. M.; Delgass, W. N.; Venkatasubramanian, V. An Intelligent System for Reaction Kinetic Modeling and Catalyst Design. Ind. Eng. Chem. Res. 2004, 43, 3484− 3512. (237) Yamada, Y.; Kobayashi, T. Utilization of Combinatorial Method and High Throughput Experimentation for Development of Heterogeneous Catalysts. J. Jpn. Pet. Inst. 2006, 49, 157−167. (238) Diamond, G. M.; Hall, K. A.; Lapointe, A. M.; Leclerc, M. K.; Longmire, J.; Shoemaker, J. A. W.; Sun, P. High-Throughput Discovery and Optimization of Hafnium Heteroaryl-Amido Catalysts for the Isospecific Polymerization of Propylene. ACS Catal. 2011, 1, 887−900. (239) Kondratyuk, P.; Gumuslu, G.; Shukla, S.; Miller, J. B.; Morreale, B. D.; Gellman, A. J. A Microreactor Array for Spatially Resolved Measurement of Catalytic Activity for High-Throughput Catalysis Science. J. Catal. 2013, 300, 55−62. (240) Gumuslu, G.; Kondratyuk, P.; Boes, J. R.; Morreale, B.; Miller, J. B.; Kitchin, J. R.; Gellman, A. J. Correlation of Electronic Structure with Catalytic Activity: H2−D2 Exchange across CuxPd1−x Composition Space. ACS Catal. 2015, 5, 3137−3147. (241) Kitchin, J. R.; Gellman, A. J. High-Throughput Methods Using Composition and Structure Spread Libraries. AIChE J. 2016, 62, 3826−3835. (242) Renom-Carrasco, M.; Lefort, L. Ligand Libraries for High Throughput Screening of Homogeneous Catalysts. Chem. Soc. Rev. 2018, 47, 5038−5060. (243) Isbrandt, E. S.; Sullivan, R. J.; Newman, S. G. High Throughput Strategies for the Discovery and Optimization of Catalytic Reactions. Angew. Chem., Int. Ed. 2019, 58, 7180−7191. (244) Wellendorff, J.; Lundgaard, K. T.; Møgelhøj, A.; Petzold, V.; Landis, D. D.; Nørskov, J. K.; Bligaard, T.; Jacobsen, K. W. Density Functionals for Surface Science: Exchange-Correlation Model Development with Bayesian Error Estimation. Phys. Rev. B: Condens. Matter Mater. Phys. 2012, 85, 235149.
(245) Snyder, J. C.; Rupp, M.; Hansen, K.; Müller, K. R.; Burke, K. Finding Density Functionals with Machine Learning. Phys. Rev. Lett. 2012, 108, 253002. (246) Pozun, Z. D.; Hansen, K.; Sheppard, D.; Rupp, M.; Müller, K. R.; Henkelman, G. Optimizing Transition States via Kernel-Based Machine Learning. J. Chem. Phys. 2012, 136, 174101. (247) Peterson, A. A. Acceleration of Saddle-Point Searches with Machine Learning. J. Chem. Phys. 2016, 145, 074106. (248) Ulissi, Z. W.; Medford, A. J.; Bligaard, T.; Nørskov, J. K. To Address Surface Reaction Network Complexity Using Scaling Relations Machine Learning and DFT Calculations. Nat. Commun. 2017, 8, 14621.
(249) Koistinen, O. P.; Dagbjartsdóttir, F. B.; Á sgeirsson, V.; Vehtari, A.; Jónsson, H. Nudged Elastic Band Calculations Accelerated with Gaussian Process Regression. J. Chem. Phys. 2017, 147, 152720.
(250) Takahashi, K.; Miyazato, I. Rapid Estimation of Activation Energy in Heterogeneous Catalytic Reactions via Machine Learning. J. Comput. Chem. 2018, 39, 2405−2408.
(251) Garrido Torres, J. A.; Jennings, P. C.; Hansen, M. H.; Boes, J. R.; Bligaard, T. Low-Scaling Algorithm for Nudged Elastic Band Calculations Using a Surrogate Machine Learning Model. Phys. Rev. Lett. 2019, 122, 156001.
(252) Sameera, W. M. C.; Kumar Sharma, A.; Maeda, S.; Morokuma, K. Artificial Force Induced Reaction Method for Systematic Determination of Complex Reaction Mechanisms. Chem. Rec. 2016, 16, 2349−2363. (253) Sugiyama, K.; Sumiya, Y.; Takagi, M.; Saita, K.; Maeda, S. Understanding CO Oxidation on the Pt(111) Surface Based on a Reaction Route Network. Phys. Chem. Chem. Phys. 2019, 21, 14366− 14375.
ACS Catalysis Review
DOI: 10.1021/acscatal.9b04186 ACS Catal. 2020, 10, 2260−2297
2297